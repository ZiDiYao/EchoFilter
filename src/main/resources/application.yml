llm:
  models:
    GPT_4: gpt-4o
    DEEPSEEK: deepseek-chat
    GEMINI: gemini-1.5-pro


openai:
  api-url: https://api.openai.com/v1/chat/completions
  api-key: ${OPENAI_API_KEY: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}
  model: gpt-4
  temperature: 0.0

deepseek:
  api-url: https://api.deepseek.com/chat/completions
  api-key: ${DEEPSEEK_API_KEY:sk-5edbfb6f77bf4bd2bb79037ebaac30c0}
  model: DEEPSEEK
  temperature: 0.0

echofilter:
  logging:
    enabled: true                 # 总开关：false 则切面完全不生效
    always-log-summary: true      # 即便未采样也打印 IN/OUT 摘要；设为 false 仅采样时打印
    args:
      max-chars: 2000             # 入参字符串最大长度（超出会截断）
    result:
      max-chars: 2000             # 返回值字符串最大长度（超出会截断）

  tracing:
    sample-rate: 0.10             # TraceContextFilter 确定性采样率（0~1），示例 10%

logging:
  level:
    # 建议先用 INFO；排查问题时可临时升到 DEBUG
    com.echofilter.commons.utils.aop.logging.aspect.HttpApiLoggingAspect: INFO

LOG_DIR: /var/log/echofilter

spring:
  data:
    redis:
      host: 81.70.198.98
      port: 6379
      password: 787887Robert
      database: 0

  kafka:
    bootstrap-servers: 81.70.198.98:9092
    admin:
      fail-fast: true
