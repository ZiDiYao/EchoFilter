2025-10-13 20:24:59.453 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 97924 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 20:24:59.457 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 20:24:59.492 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 20:24:59.492 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 20:25:00.707 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 20:25:00.709 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 20:25:00.753 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 29 ms. Found 0 Redis repository interfaces.
2025-10-13 20:25:01.425 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 20:25:01.436 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 20:25:01.438 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 20:25:01.438 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 20:25:01.477 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 20:25:01.477 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1984 ms
2025-10-13 20:25:02.263 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 20:25:02.579 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 20:25:02.631 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 20:25:02.694 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:25:02.695 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:25:02.695 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760401502693
2025-10-13 20:25:05.267 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 20:25:05.270 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:25:05.270 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:25:05.270 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:25:05.274 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 20:25:05.279 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 20:25:05.298 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 20:25:05.330 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 20:25:05.367 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:25:05.367 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:25:05.367 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760401505367
2025-10-13 20:25:05.368 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 20:25:05.382 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 6.43 seconds (process running for 7.368)
2025-10-13 20:25:06.391 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:25:06.519 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 20:25:06.521 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:25:07.731 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100
2025-10-13 20:25:07.732 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:25:11.096 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100', protocol='range'}
2025-10-13 20:25:11.102 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 1: {consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 20:25:11.515 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100', protocol='range'}
2025-10-13 20:25:11.516 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 20:25:11.518 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:25:11.802 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-1
2025-10-13 20:25:11.802 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-0
2025-10-13 20:25:11.802 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-11
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-10
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-7
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-6
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-9
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-8
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-3
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-2
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-5
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-4
2025-10-13 20:25:12.055 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-1
2025-10-13 20:25:12.055 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-0
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-11
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-10
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-7
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-6
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-9
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-8
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-3
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-2
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-5
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-4
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-1 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-0 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-10 to position FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-7 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-6 to position FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-9 to position FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-8 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-3 to position FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-2 to position FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-5 to position FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.417 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:25:49.759 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 20:25:49.759 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 20:25:49.760 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 1 ms
2025-10-13 20:25:49.880 [tomcat-handler-1] INFO  o.a.k.c.producer.ProducerConfig - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 20:25:49.881 [tomcat-handler-1] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= initializing Kafka metrics collector
2025-10-13 20:25:49.889 [tomcat-handler-1] INFO  o.a.k.clients.producer.KafkaProducer - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 20:25:49.900 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= Kafka version: 3.9.1
2025-10-13 20:25:49.901 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:25:49.901 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= Kafka startTimeMs: 1760401549900
2025-10-13 20:25:50.891 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:25:50.920 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=1143 handler=SendToKafkaController.batch
2025-10-13 20:25:51.003 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1003 with epoch 0
2025-10-13 20:26:00.815 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:26:00.815 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:26:00.816 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100 sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 20:26:00.816 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:26:00.816 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:26:00.817 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 20:26:00.818 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:26:00.818 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:26:01.548 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 20:26:01.548 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 20:26:01.550 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 20:26:01.559 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 20:26:01.567 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:26:01.570 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.producer for producer-1 unregistered
2025-10-13 20:47:59.196 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 101028 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 20:47:59.197 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 20:47:59.228 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 20:47:59.229 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 20:47:59.731 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 20:47:59.733 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 20:47:59.769 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 27 ms. Found 0 Redis repository interfaces.
2025-10-13 20:48:00.318 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 20:48:00.326 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 20:48:00.327 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 20:48:00.327 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 20:48:00.364 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 20:48:00.364 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1135 ms
2025-10-13 20:48:01.018 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 20:48:01.314 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 20:48:01.360 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 20:48:01.408 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:48:01.409 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:48:01.409 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402881407
2025-10-13 20:48:04.214 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 20:48:04.217 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:48:04.217 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:48:04.217 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:48:04.222 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 20:48:04.227 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 20:48:04.244 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 20:48:04.269 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 20:48:04.302 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:48:04.302 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:48:04.302 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402884302
2025-10-13 20:48:04.303 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 20:48:04.316 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 5.551 seconds (process running for 6.021)
2025-10-13 20:48:05.300 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:48:05.302 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 20:48:05.303 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:48:06.304 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024
2025-10-13 20:48:06.304 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:48:09.549 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024', protocol='range'}
2025-10-13 20:48:09.555 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 3: {consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 20:48:09.800 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024', protocol='range'}
2025-10-13 20:48:09.801 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 20:48:09.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-1 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-10 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-7 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-6 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-9 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-8 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-3 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-5 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.411 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:48:15.000 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 20:48:15.000 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 20:48:15.001 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 1 ms
2025-10-13 20:48:15.070 [tomcat-handler-1] INFO  o.a.k.c.producer.ProducerConfig - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 20:48:15.072 [tomcat-handler-1] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= initializing Kafka metrics collector
2025-10-13 20:48:15.079 [tomcat-handler-1] INFO  o.a.k.clients.producer.KafkaProducer - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 20:48:15.089 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= Kafka version: 3.9.1
2025-10-13 20:48:15.089 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:48:15.089 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= Kafka startTimeMs: 1760402895089
2025-10-13 20:48:15.290 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4dc6ead6-2cb2-4afd-85c8-f464a7d30aab","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:16.076 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:48:16.076 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1004 with epoch 0
2025-10-13 20:48:16.098 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=1079 handler=SendToKafkaController.batch
2025-10-13 20:48:18.532 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"da2212e4-ed9f-4f17-82a0-1b69cd45765c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:21.774 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"61b3c210-c723-4389-8038-7bf748e40e05","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:25.022 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f181b28b-8a10-4774-8787-ee79f313fad5","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:28.269 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7ba9f5ce-1f6d-49a3-ba31-23372147ad97","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:31.524 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f1288b5f-fa60-4a01-90e5-2565f61b5818","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:34.767 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"37d7b13d-e050-4aff-a518-ce84a923ea75","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:38.004 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4695c4c6-b423-491b-afc0-5be05cce2fd4","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:41.323 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f8dcf824-e498-4d57-a76d-6bb2b1afd12e","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:44.606 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"250ef572-bc17-45b0-bb69-360ed89eabae","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:47.852 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1388b658-fd2b-4247-b69c-ef60d6e8db10","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:51.096 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"06f5109d-82a7-4369-b58f-98a3d649352c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"这视频标题党，一点干货没有。","context":"视频：如何一周学会XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:54.343 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b1144e25-6719-4033-8aaf-480c52f6f2ce","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"牛！讲得非常清楚。","context":"教程：Java 虚拟线程","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:57.591 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5bfcdeb0-a769-4367-b97c-246b93d05f7f","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:00.839 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ef4fd9bd-95ba-4526-b39a-476dc5744ca1","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:04.108 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fe63aac6-691c-491d-b8c0-95d1127e31fb","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:07.348 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5378bb8e-d8a7-4e8e-9283-f00b65b18379","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:10.595 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5daf1b98-5c0e-4241-b726-eb0f8de11553","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:13.842 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d8f2d461-c7ee-4561-901d-bcedb8621054","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:17.097 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b78b17d5-c989-421b-a821-2ce0aa97c132","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:20.410 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eebe88a0-bc43-4e6c-a31d-ba32d208ecce","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:23.661 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fb4f6a9c-c2bf-4433-8d8e-f3c130f89001","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:26.921 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"90215d04-bb6d-464e-acb1-0e7b9e58e77c","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:30.171 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"abfc3123-8a55-4c55-9eff-e18dc70e06e5","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:33.422 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9dde89df-8b52-434d-ad6d-77bfd32b7e8b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"这视频标题党，一点干货没有。","context":"视频：如何一周学会XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:36.668 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1879c3a6-0377-4b25-9515-3403c15577af","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:39.951 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a1f0ce6b-6771-4b92-aeb4-61e1c9adeb1d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"牛！讲得非常清楚。","context":"教程：Java 虚拟线程","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:41.695 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:49:41.695 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024 sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 20:49:41.697 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:49:41.697 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:49:42.309 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 20:49:42.309 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 20:49:42.310 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 20:49:42.320 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 20:49:43.206 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"944b0f79-8615-4875-91ed-df56654baaf7","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:50.417 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 101528 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 20:49:50.418 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 20:49:50.450 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 20:49:50.450 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 20:49:50.983 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 20:49:50.985 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 20:49:51.026 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 30 ms. Found 0 Redis repository interfaces.
2025-10-13 20:49:51.592 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 20:49:51.599 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 20:49:51.600 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 20:49:51.600 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 20:49:51.637 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 20:49:51.637 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1187 ms
2025-10-13 20:49:52.288 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 20:49:52.618 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 20:49:52.664 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 20:49:52.711 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:49:52.711 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:49:52.711 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402992710
2025-10-13 20:49:55.205 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 20:49:55.208 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:49:55.208 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:49:55.208 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:49:55.212 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 20:49:55.218 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 20:49:55.237 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 20:49:55.264 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 20:49:55.299 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:49:55.299 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:49:55.299 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402995299
2025-10-13 20:49:55.300 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 20:49:55.317 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 5.31 seconds (process running for 5.773)
2025-10-13 20:49:56.298 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:49:56.298 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 20:49:56.300 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:49:57.326 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da
2025-10-13 20:49:57.326 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:50:00.583 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=5, memberId='consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da', protocol='range'}
2025-10-13 20:50:00.588 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 5: {consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 20:50:00.847 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=5, memberId='consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da', protocol='range'}
2025-10-13 20:50:00.847 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 20:50:00.850 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:50:01.367 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-1 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-10 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-7 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-6 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-9 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-8 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-3 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-5 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.475 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"37d7b13d-e050-4aff-a518-ce84a923ea75","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"90215d04-bb6d-464e-acb1-0e7b9e58e77c","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f8dcf824-e498-4d57-a76d-6bb2b1afd12e","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d8f2d461-c7ee-4561-901d-bcedb8621054","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"61b3c210-c723-4389-8038-7bf748e40e05","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7226e493-13b5-4ec9-8298-6519b92783db","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"944b0f79-8615-4875-91ed-df56654baaf7","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"abfc3123-8a55-4c55-9eff-e18dc70e06e5","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fb4f6a9c-c2bf-4433-8d8e-f3c130f89001","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ef4fd9bd-95ba-4526-b39a-476dc5744ca1","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b78b17d5-c989-421b-a821-2ce0aa97c132","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"bb0c720a-eddc-4566-a38c-c6497c82f3ff","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b552efad-91d0-4653-8967-fd7e32170ac0","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eab2df4d-223c-43f0-8100-ed3ad7e49d2b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"368748a5-d7d5-4cb1-8bb7-f832e2d97356","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1c13c745-28c1-4a5e-af9d-f6321b1fbac1","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"250ef572-bc17-45b0-bb69-360ed89eabae","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4695c4c6-b423-491b-afc0-5be05cce2fd4","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fe63aac6-691c-491d-b8c0-95d1127e31fb","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"25c48b7b-5407-438a-a97b-00adbc88b71b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f1288b5f-fa60-4a01-90e5-2565f61b5818","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5bfcdeb0-a769-4367-b97c-246b93d05f7f","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"da2212e4-ed9f-4f17-82a0-1b69cd45765c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5378bb8e-d8a7-4e8e-9283-f00b65b18379","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a6144b46-9905-4fbe-9c0c-ec993db2b954","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.792 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eebe88a0-bc43-4e6c-a31d-ba32d208ecce","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f181b28b-8a10-4774-8787-ee79f313fad5","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9dde89df-8b52-434d-ad6d-77bfd32b7e8b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"这视频标题党，一点干货没有。","context":"视频：如何一周学会XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7ba9f5ce-1f6d-49a3-ba31-23372147ad97","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"36b77cb6-1873-4b23-af79-0eba9dd47d73","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"06f5109d-82a7-4369-b58f-98a3d649352c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"这视频标题党，一点干货没有。","context":"视频：如何一周学会XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4dc6ead6-2cb2-4afd-85c8-f464a7d30aab","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1388b658-fd2b-4247-b69c-ef60d6e8db10","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5daf1b98-5c0e-4241-b726-eb0f8de11553","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b1144e25-6719-4033-8aaf-480c52f6f2ce","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"牛！讲得非常清楚。","context":"教程：Java 虚拟线程","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49181ded-eb9b-492c-a75a-13e6de16f1ef","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a1f0ce6b-6771-4b92-aeb4-61e1c9adeb1d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"牛！讲得非常清楚。","context":"教程：Java 虚拟线程","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1879c3a6-0377-4b25-9515-3403c15577af","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c656f110-fc25-4134-80e8-e0d115eaa18d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eaa5fb18-89a1-491e-a4b8-a5629715ba46","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:14.318 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 20:50:14.318 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 20:50:14.318 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 0 ms
2025-10-13 20:50:14.377 [tomcat-handler-1] INFO  o.a.k.c.producer.ProducerConfig - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 20:50:14.378 [tomcat-handler-1] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= initializing Kafka metrics collector
2025-10-13 20:50:14.390 [tomcat-handler-1] INFO  o.a.k.clients.producer.KafkaProducer - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 20:50:14.412 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= Kafka version: 3.9.1
2025-10-13 20:50:14.413 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:50:14.413 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= Kafka startTimeMs: 1760403014412
2025-10-13 20:50:15.396 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:50:15.397 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1005 with epoch 0
2025-10-13 20:50:15.417 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=1083 handler=SendToKafkaController.batch
2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2b9c0a71-5a6f-4260-b5c6-9c06d544d3d6","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"27114458-856a-41a3-a417-5d47ddaa391e","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c8e3a661-5803-492d-8edd-0f56d0263023","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7067b14-d740-47be-813f-812f7c7a68cb","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"8200c528-d3d8-4600-915e-480795f6e0d1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f6e76aa1-5c48-47aa-9a7e-36b78e3e59a4","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f07ed24b-006e-495f-aa26-c3feb5819971","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4a6234ca-633f-48b5-ab34-a646ed8a2d59","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5d519dd8-9235-4abf-9115-9f43d1169b34","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"这视频标题党，一点干货没有。","context":"视频：如何一周学会XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ca7745b9-7066-47c6-be88-89cd366254f5","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"3929a0bc-388a-4e18-bec9-1e16d5a6f755","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"44ee5d32-69e4-444b-84a4-efbc3a3d2df1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b4dba9a1-24d8-4ad3-9cac-387149d1711a","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cce4ba6c-742a-42aa-93fc-d49aa5fda649","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"牛！讲得非常清楚。","context":"教程：Java 虚拟线程","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"31803d28-539a-45d4-ae39-26269e133726","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b5fc141e-750f-4dfc-ac48-2b800e138788","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f5e1db9-3263-4b71-a4c3-a1c9582ea77c","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2ac9067a-e6cd-40b4-923c-e7ea96e23f17","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4c5791e6-f63f-49df-86e1-544099abe1aa","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9ac39178-b084-4862-99b3-447680d3c9ae","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.193 [tomcat-handler-4] INFO  c.e.c.Interceptors.TimingInterceptor - trace=13863a84-9625-4c06-8c9a-e099e89921d0 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=6 handler=SendToKafkaController.batch
2025-10-13 20:52:23.449 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49ce82b2-e529-4572-9f0b-60c416a1873a","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"deeps...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.940 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7c6a4d0-92a4-4b9b-88b3-b88fea05f2b8","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-chat","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.940 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"494653d8-0994-4587-a06f-86fd1939d7cc","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"这视频标题党，一点干货没有。","context":"视频：如何一周学会XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"202...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"63bb9e23-9f12-4a9d-b798-a536d6afe569","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","create...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b2d8f693-8d28-4487-85ba-e015b950f224","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e0fe3ea4-a1a1-4423-a574-9f397b33c919","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"400478de-2529-4b97-8265-5de26e49f02b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"de...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e86ee1b3-b072-4f2d-ab46-9d3eb4296e61","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1ab31aec-e632-4b60-89ca-9c2a91243365","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0b5caf98-1555-416a-9eb5-bde1f5c4299b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cff094e6-507f-4c46-8b11-d2395942c492","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","creat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1272ea59-1ce4-41a0-90d7-0c5e5347a7f6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deep...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d488082a-2590-46c1-94bd-2ae9f8463cb3","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d80c7dd0-104f-47d9-b17e-0afdb2d450f2","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0fc78c89-defc-4fe2-a67b-04cec1fcd246","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"97c5acc5-1693-4520-9a06-3bb7a513b3c6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-chat"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f6d6bf8-f05d-4f4d-952e-0b3d38fd251e","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"牛！讲得非常清楚。","context":"教程：Java 虚拟线程","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9c165839-840e-486f-a9a3-a3cf7cbde096","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat",...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5c1371d9-2595-4a72-a2ab-619dba9be21f","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b3c3d87c-4e85-4bba-a846-fb104ee9d6e4","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:55:54.149 [tomcat-handler-7] INFO  c.e.c.Interceptors.TimingInterceptor - trace=9cc03623-1fc8-4c9b-9849-db7b27b64596 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=5 handler=SendToKafkaController.batch
2025-10-13 20:56:00.894 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dbea503-66f8-4837-bb4e-bfc4ac42c010, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about work"],"trustScore":0.8}
2025-10-13 20:56:01.345 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=148f9ccb-96e1-4731-9e7f-77b26f267416, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment was posted on a YouTube video about a new product"],"trustScore":0.8}
2025-10-13 20:56:01.548 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=016b4879-0453-4b38-b1ce-23ff1badf8dd, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 20:56:02.031 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d36c2c30-ac4a-4e33-95bd-4ec730bfe752, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The comment is a response to a guide about Docker"],"trustScore":0.8}
2025-10-13 20:56:02.364 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bb00bdd7-c982-445e-9cc3-e9eedd6ccd37, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about a Java virtual threads tutorial"],"trustScore":0.8}
2025-10-13 20:56:02.501 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=35b9ae45-777c-4f59-b614-8a51f6c67bfa, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.5,"facts":["The comment consists of a single word 'Source?'","The comment is requesting verification of a claim","The comment does not make any factual assertions"],"trustScore":0.7}
2025-10-13 20:56:02.581 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=81e715a6-8d50-41af-9979-37a925ff638e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 20:56:02.904 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=576d5948-13a4-4ad8-927a-09cd22eda1db, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service to buy followers","The website domain 'spammy.site' suggests potential spam activity","Such services typically violate platform terms of service"],"trustScore":0.1}
2025-10-13 20:56:02.943 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4c1b56fe-5561-461e-8c2e-482f35b0fe7c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators","The comment is identified as off-topic advertising","The comment contains no substantive content"],"trustScore":0.1}
2025-10-13 20:56:03.044 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c7c24514-c30f-4541-ac6b-000e3f5c60a1, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement","The comment does not provide specific factual claims","The comment is a personal viewpoint"],"trustScore":0.7}
2025-10-13 20:56:03.180 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3b8661fa-b478-41b0-acaa-3e49f7ceb54d, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 20:56:03.459 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=06c51f49-f8a2-428b-b9eb-f6a3fc19ee9f, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 20:56:03.558 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd28a2b-705c-4655-8193-c38e21835af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 20:56:03.623 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f7a76d79-9c99-4cf4-8efc-d2e1beb71adc, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","Cherry-picking refers to selectively choosing data","Benchmarks can be manipulated through selective data presentation"],"trustScore":0.4}
2025-10-13 20:56:04.561 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=40bc0bf4-3875-457f-9928-9944714ce0e6, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment serves as a content moderation report"],"trustScore":0.7}
2025-10-13 20:56:04.601 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1f9de0b6-ff90-4828-9566-ccea63ed2af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a critical assessment without providing specific corrections"],"trustScore":0.3}
2025-10-13 20:56:04.967 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bdd8791b-4d99-4540-bad3-934ab668ad4a, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["视频标题声称一周学会XX","评论者认为视频缺乏实质性内容","评论者使用了'标题党'这一表述"],"trustScore":0.7}
2025-10-13 20:56:05.351 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ef0d9ecf-c1bb-429d-9655-014e479bc9e8, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Scientific consensus supports vaccine safety and efficacy"],"trustScore":0.2}
2025-10-13 20:56:08.112 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6a691020-1be8-4682-bdc8-ff09cdf1db2c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 20:56:09.385 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9ed099bb-325a-46ba-8cf3-a376788d372e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them but never return funds","Legitimate giveaways don't require sending cryptocurrency first"],"trustScore":0.1}
2025-10-13 21:03:34.725 [tomcat-handler-10] INFO  c.e.c.Interceptors.TimingInterceptor - trace=7f61f143-d16e-4f3f-b766-546deec0c7e6 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=5 handler=SendToKafkaController.batch
2025-10-13 21:03:41.311 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2ab16530-5e1b-48a5-9609-f2a5b1dd195d, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about work"],"trustScore":0.8}
2025-10-13 21:03:41.958 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9d7a06fa-9576-4ba0-833c-e1abda5eb84c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:03:42.110 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=20749219-d661-4de9-9a14-ae2b9274d3f7, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:03:42.152 [tomcat-handler-11] INFO  c.e.c.Interceptors.TimingInterceptor - trace=b605c0d5-9186-4c9e-bd50-74d777d97b1e tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=5 handler=SendToKafkaController.batch
2025-10-13 21:03:42.657 [tomcat-handler-12] INFO  c.e.c.Interceptors.TimingInterceptor - trace=d060f62d-c273-4094-bb7f-350f205082e3 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=4 handler=SendToKafkaController.batch
2025-10-13 21:03:42.810 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6adde89d-0700-4107-aa1e-535cdbbc355f, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 21:03:42.947 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d9ae8151-7d58-45a6-91dc-2ae926012fde, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators.","The comment is identified as off-topic advertising.","The comment contains no substantive content."],"trustScore":0.1}
2025-10-13 21:03:43.234 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fe9fdad8-07bf-47f9-93d4-e3422c7694c8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","This pattern is commonly associated with spam"],"trustScore":0.1}
2025-10-13 21:03:43.816 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9545cb66-774e-4537-9995-768fe7ca5472, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment was posted on a YouTube video about a new product","The comment does not contain substantive content about the product"],"trustScore":0.1}
2025-10-13 21:03:43.942 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=05d824d4-83f6-404a-bc10-b617332d2348, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:03:43.944 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=39041652-0308-4595-bfe2-acc295652e46, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language to convey approval.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 21:03:44.262 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4bf23d27-5ab0-47c5-805b-20dbd66e84b6, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:44.456 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79dc8dd6-f120-4532-9f89-f71088eb6127, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment \"Source?\" is a request for verification","The comment questions the validity of a claim made by OP","The comment seeks additional supporting information"],"trustScore":0.7}
2025-10-13 21:03:44.477 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41f1e249-a1fe-4eff-8735-752f3fe3e36a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 21:03:44.821 [tomcat-handler-13] INFO  c.e.c.Interceptors.TimingInterceptor - trace=82891cd9-ca92-4e2f-a5da-5829f62231b6 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=6 handler=SendToKafkaController.batch
2025-10-13 21:03:45.016 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=109c7cf2-d7ee-4c59-bb86-73b199b572cb, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing social media followers","The website 'spammy.site' is advertised as a source for followers","Purchased followers are typically fake or inactive accounts"],"trustScore":0.1}
2025-10-13 21:03:45.135 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2b81cd5f-0f42-4ec6-86b5-e8498b537e8a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["视频标题声称一周学会XX","视频内容被评论者认为缺乏实质性内容","评论表达了观看者的主观感受"],"trustScore":0.7}
2025-10-13 21:03:46.854 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e72bdadd-2d8a-4352-a607-97bd15c4837c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["The comment claims something is misinformation without providing specific details","The comment references vaccines but lacks substantive claims to verify","The comment makes an assertion without supporting evidence"],"trustScore":0.2}
2025-10-13 21:03:47.082 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e3c86ce4-3f2f-4c80-b18f-a0ff5253baf8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:03:47.733 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6b55d4c8-3604-49d1-a1b5-5ba6a8acb7d9, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:03:48.873 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67e65cf1-393c-49dd-b482-5853217e3baf, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 21:03:48.878 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c0353cbc-15e3-47db-8e55-6c1834d000e1, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:03:49.057 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6497c0ba-6b98-4d6f-b5b4-68894dadc5ad, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment 'First!' is a common internet expression"],"trustScore":0.1}
2025-10-13 21:03:49.079 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f998ab15-ba4a-4adc-8071-38555397d04f, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:03:49.275 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b36cc0a3-d5b3-40ce-b341-bf3a655ba495, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment claims the reported content contains hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.3}
2025-10-13 21:03:49.306 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62d6988c-150d-40ba-9ad1-ad40d7a47a65, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:03:49.643 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eaa74604-527f-435e-b879-212c2c26fe7b, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Legitimate giveaways do not require sending money first","Such promises of doubling money are financially impossible to sustain"],"trustScore":0.1}
2025-10-13 21:03:49.774 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7fb800e1-3bc4-4164-b96b-c436d8babdd9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.7}
2025-10-13 21:03:50.350 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b51c8516-5bff-4faa-9d09-1b50652da06a, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation.","The context involves a guide about Docker.","The comment does not contain factual claims or opinions about Docker."],"trustScore":1.0}
2025-10-13 21:03:50.384 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b963e393-db2c-460f-9b86-13d24340e860, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker"],"trustScore":0.8}
2025-10-13 21:03:50.498 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6ed0d646-4885-4829-872c-84e728387ebc, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators","The comment is identified as off-topic advertising","The comment contains no substantive content"],"trustScore":0.1}
2025-10-13 21:03:50.985 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=277f8c6d-90fa-4cce-863b-5b13596cfcf4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a neutral information request","The context is a paper discussion"],"trustScore":0.8}
2025-10-13 21:03:50.999 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b0b86aa6-09a6-4c9f-8007-8d6e84f3567e, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators","The comment is identified as off-topic advertising","The comment contains no substantive content"],"trustScore":0.1}
2025-10-13 21:03:51.015 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=34a9aa92-4694-4a12-8c2a-06abd46c9570, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:03:51.027 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab75c19a-0bac-47ea-bd4d-a30c9afa8f7d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment 'Source?' is a request for verification","The comment responds to a claim of 'big improvement'","The comment does not contain substantive content itself"],"trustScore":0.5}
2025-10-13 21:03:51.036 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b87039b1-0ad4-469d-a01c-770618591bb4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'"],"trustScore":0.5}
2025-10-13 21:03:51.100 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=51ed5585-4a67-4948-8e65-2584d8ea4689, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses approval of a Java virtual threads tutorial.","The comment indicates the tutorial was explained clearly.","The comment is a positive reaction to educational content."],"trustScore":0.8}
2025-10-13 21:03:51.166 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b000f118-8c3a-4149-97c6-f821755a49c5, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language common in online platforms.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 21:03:51.209 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=892b3155-bd18-41a6-9dad-4f665701b633, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' appears to be associated with artificial engagement","Purchased followers typically violate platform terms of service"],"trustScore":0.1}
2025-10-13 21:03:51.412 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6e1ce085-5e70-479e-8832-837a2fc58454, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["This comment solicits cryptocurrency transfers","It promises to double any cryptocurrency sent","This is a common scam pattern on social media"],"trustScore":0.1}
2025-10-13 21:03:51.531 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=598ce2cf-7c6f-4024-bee6-8b46e3353f9d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:03:51.561 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dd8d9ef-3816-46cf-a232-05de8f7903f6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:03:51.634 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb361d89-44fc-47aa-b0fe-68c67b45b120, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper"],"trustScore":0.6}
2025-10-13 21:03:51.672 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3f9449b9-73af-4a48-8071-faf9827eb9f3, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 21:03:51.680 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ca2b61d-548c-4e54-8fb9-e780a290d678, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:03:51.736 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eeaa421d-6448-445c-b598-025575e5a5d8, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","The choice between tabs and spaces is subjective in programming"],"trustScore":0.8}
2025-10-13 21:03:51.779 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddf57981-197c-4c15-932c-13f850b5d634, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:03:51.785 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=236aecee-ddab-46f6-99ca-5424273ad97a, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The website domain 'spammy.site' suggests potential spam activity","Purchasing followers violates most platform terms of service"],"trustScore":0.1}
2025-10-13 21:03:51.989 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee031476-f227-4284-ae0e-8bb25385ecfe, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:03:52.075 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdea544e-14be-4c04-9d17-1bc87024fed8, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with an unspecified position"],"trustScore":0.7}
2025-10-13 21:03:52.088 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee8a4813-3889-41de-9d89-a57cb4a97bca, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment 'Source?' is a request for verification","The comment responds to a claim of 'big improvement'","The comment does not contain substantive claims itself"],"trustScore":0.7}
2025-10-13 21:03:52.209 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a71964d9-3543-43a5-b125-71be3808d163, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:03:52.344 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24a751f6-aae2-4f6e-891a-af44f51d68fd, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:52.462 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0973ef42-5216-42be-bc00-5e25cc3c05ae, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["视频标题声称一周学会XX","视频内容被评论者认为缺乏实质性内容"],"trustScore":0.6}
2025-10-13 21:03:52.600 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4e9c5a0b-746d-4311-9f31-5d11e6fffaac, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'"],"trustScore":0.5}
2025-10-13 21:03:52.644 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3ea118c4-6591-40c9-af3d-2d2a01fd0977, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The comment is responding to a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 21:03:52.681 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6bb54e4e-24e8-45df-b897-1b2b674d8aa6, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references a comparison between Model X and Y","The comment implies potential bias in benchmark selection"],"trustScore":0.4}
2025-10-13 21:03:52.684 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=643d7c3a-1214-4084-84dd-a50cbd3a009d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about a Java virtual threads tutorial"],"trustScore":0.8}
2025-10-13 21:03:52.776 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7dd90614-dad7-40ee-a18b-8aeeedd5eb72, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment claims the reported content contains hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 21:03:53.235 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2daec662-6315-4137-93d1-830159d8ed90, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety and efficacy"],"trustScore":0.15}
2025-10-13 21:03:53.250 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=52d07cc9-1cef-49b5-a06a-90d267f7c4aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests moderator removal","The comment is labeled as 'pure spam'","The comment is an off-topic advertisement"],"trustScore":0.1}
2025-10-13 21:03:53.355 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fba9d2a9-68e2-4367-bab2-b39b28070714, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment claims the reported content contains hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 21:03:53.489 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1de40a0a-307c-40e1-8440-1c569e800939, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment consists of a single word: \"Source?\"","The comment is requesting verification of a claim made by OP","The comment does not contain substantive content beyond requesting information"],"trustScore":0.5}
2025-10-13 21:03:53.573 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=26b4190d-dc44-42ed-a84f-04ef195b10b1, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.2}
2025-10-13 21:03:53.815 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95fdc418-ce31-4b0c-b279-547b2b6d4455, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for buying followers","The website domain 'spammy.site' suggests potential spam activity","Purchasing followers violates most platform terms of service"],"trustScore":0.1}
2025-10-13 21:03:54.149 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd42c12-58bb-4dff-ad4a-5473819273a3, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:03:54.683 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fc4a930b-d94d-40f3-b212-3b4d45472bd6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","The improvement is measurable"],"trustScore":0.7}
2025-10-13 21:03:54.707 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8a7422c4-386c-4648-9518-117a3c83149d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:55.057 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=875c4059-3206-4cea-859e-4fd5a2a8d427, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:03:55.061 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c38417d-6cf7-4b41-a39c-c68eead23b6c, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates hate speech occurred","The comment serves as a report of inappropriate content"],"trustScore":0.7}
2025-10-13 21:03:55.071 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8863bc1c-103d-490b-8e22-1190f71f7099, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims 'This benchmark is cherry-picked'","The context mentions 'Model X vs Y'","The statement is evaluative rather than purely descriptive"],"trustScore":0.4}
2025-10-13 21:03:55.078 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=769f8b0f-6fe5-4f43-a449-def450a3db00, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["视频标题声称一周学会XX","视频内容被评论者认为缺乏实质性内容","评论表达了观看后的主观感受"],"trustScore":0.7}
2025-10-13 21:03:55.494 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0014d772-1c46-4f6a-b12b-bc80b52656b7, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:03:55.802 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c6c5b504-43cd-47ca-b251-3a76743c4566, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:03:56.564 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=76e8c239-3365-4431-a207-f6bd93f9c378, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:03:56.587 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=88d15321-4968-41da-9e6f-e94ea18e547e, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:03:56.611 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e60d6b18-79cc-456a-8143-e2ad276d123e, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.15}
2025-10-13 21:03:56.818 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=adad4d4a-7e25-4ad7-90aa-1ee70f566785, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:03:57.505 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d7a78c5d-c89d-48df-b880-e21fba6a1244, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This tweet claims to double cryptocurrency sent to the user","Such 'send crypto to double' offers are commonly associated with scams","Legitimate cryptocurrency giveaways do not require sending funds first"],"trustScore":0.1}
2025-10-13 21:03:57.828 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fd46784e-8426-47df-8f69-8f11669186bf, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:58.412 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f76b1eac-7602-404e-ad08-fccd2b774df9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["视频标题声称一周学会XX","视频内容被评论者认为缺乏实质性内容","评论表达了观看者的主观感受"],"trustScore":0.7}
2025-10-13 21:03:58.748 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e6c9340e-08e0-4c8b-a9a5-38bd2bb007aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:04:00.314 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=21967a31-aeba-4ffa-80cb-7f15d55218e4, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them","These schemes result in permanent loss of funds for victims"],"trustScore":0.1}
2025-10-13 21:07:14.976 [tomcat-handler-16] INFO  c.e.c.Interceptors.TimingInterceptor - trace=83f7b1d4-8631-4a78-ada8-00ad914d114a tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=6 handler=SendToKafkaController.batch
2025-10-13 21:07:22.540 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=89ab3a8b-6fba-4f99-aba7-5ae6928a861c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a write-up","The comment indicates the user learned from the content","The comment does not contain verifiable factual claims"],"trustScore":0.8}
2025-10-13 21:07:22.668 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67f9d2ff-cbad-4598-b2ef-0bf9937ea6af, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for benchmarking methodology"],"trustScore":0.8}
2025-10-13 21:07:22.776 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=59e96b51-60eb-4284-a169-66ddc07d811f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The commenter states the video helped them pass an exam"],"trustScore":0.7}
2025-10-13 21:07:22.846 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d0c219ef-d9fa-45b9-8b8d-d4be260bb70b, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment requests subtitles for a technical lecture replay"],"trustScore":1.0}
2025-10-13 21:07:22.895 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddc10887-50b1-4a4c-932a-6f5f7db45a59, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment 'First!' is a common internet expression"],"trustScore":0.1}
2025-10-13 21:07:22.924 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1553cdd3-d380-4005-bf74-566a004148a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["User is asking where to download a dataset"],"trustScore":0.8}
2025-10-13 21:07:23.043 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7f7c1466-e612-4c02-86c2-26faf54c21f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment requests timestamps for a long-form interview video"],"trustScore":1.0}
2025-10-13 21:07:23.062 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24ad2bf1-a6f2-49ec-95cc-9a31416bf606, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment is requesting presentation materials from a conference talk"],"trustScore":1.0}
2025-10-13 21:07:23.062 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8230466c-a214-4f01-a5f0-c7f1cdc8e44c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses disagreement with someone's understanding of statistics"],"trustScore":0.3}
2025-10-13 21:07:23.236 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d2045139-3329-4cd2-828c-fe3d79bf6441, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a moderator response","The comment expresses gratitude","The comment acknowledges clarification"],"trustScore":0.9}
2025-10-13 21:07:23.362 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49f1e148-9e8d-426b-839d-b9ff3fb9b984, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a tutorial","The comment is positive in tone","The comment acknowledges the value of shared content"],"trustScore":0.8}
2025-10-13 21:07:23.374 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a9ff59a2-bc76-47c0-a8af-0912a726a346, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims results are cherry-picked"],"trustScore":0.3}
2025-10-13 21:07:23.434 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdd0779d-c0a8-4ced-9394-834f4a768528, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a duplicate post request","The user is asking for thread merging","The comment is about forum moderation"],"trustScore":0.8}
2025-10-13 21:07:23.445 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f6a0f493-05ae-445e-a02f-fe4400052d76, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["JSON is a data format","YAML is a data format","Both JSON and YAML are used for data serialization"],"trustScore":0.8}
2025-10-13 21:07:23.461 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19ccfc8c-3229-4298-bc81-c7acbd779121, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User reports bot replies flooding thread","Context indicates suspicious activity","Platform is Twitter"],"trustScore":0.7}
2025-10-13 21:07:23.641 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=03bb3a84-27cc-444e-aab5-2ba43fea1edf, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This comment states that something violates community rules","The comment does not specify what content is being referenced","The comment is making a claim about rule compliance"],"trustScore":0.3}
2025-10-13 21:07:23.646 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab6d490b-c0b7-417a-98a7-36d2f3a60b01, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a demo","The comment contains positive sentiment","The comment is a response to some form of presentation"],"trustScore":0.8}
2025-10-13 21:07:23.731 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=60b40d7e-ce1c-48eb-89c3-302b090b1260, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for assistance.","The comment describes the response as clear and concise.","The comment is a reply to a configuration issue resolution."],"trustScore":0.8}
2025-10-13 21:07:23.792 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b92ac8be-4c46-41d9-8a23-66cd86ea484c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment is asking for evidence supporting a 10x improvement claim","The comment does not make any factual assertions itself","The comment is requesting verification of another user's statement"],"trustScore":0.7}
2025-10-13 21:07:23.832 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2f2b557b-5f40-428d-9494-07663e14fc1d, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 25%"],"trustScore":0.7}
2025-10-13 21:07:23.857 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8ddd3064-7111-4b76-ac55-7d393b6ae2ff, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["Comment contains a promotional link","Link directs to a service selling followers","Domain name appears unprofessional"],"trustScore":0.1}
2025-10-13 21:07:23.878 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62b74d65-deef-49c2-a40e-c07722d28ddd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The model card lacks evaluation details"],"trustScore":0.7}
2025-10-13 21:07:24.002 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=480c4bb4-bd24-40ea-b9c3-1058bd0736ce, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses skepticism about data presentation","The comment suggests potential bias in chart selection","The comment compares Model A favorably in the presented data"],"trustScore":0.6}
2025-10-13 21:07:24.005 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=23073508-96ba-49b3-974e-735e4ca82fdb, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment warns users about a potential scam","The comment advises against clicking a link","The comment appears in a suspicious giveaway thread context"],"trustScore":0.7}
2025-10-13 21:07:24.207 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=caeab287-c0a5-4ab9-8a9c-3d1c584a204f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["User is requesting source code address","Video description appears to lack link","Comment is written in Chinese"],"trustScore":0.7}
2025-10-13 21:07:24.223 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f23a95ea-e397-428c-81bc-9dea4af79366, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of an off-topic advertisement.","The comment is posted in a thread about model interpretability.","The comment does not contribute to the discussion topic."],"trustScore":0.8}
2025-10-13 21:07:24.297 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79a45c71-22dd-4935-8f2b-111e52b9049f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["弹幕数量多","弹幕覆盖部分屏幕内容","用户报告观看体验受影响"],"trustScore":0.8}
2025-10-13 21:07:24.298 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19d654be-6563-4c9d-ac96-c5d60ec50380, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citation of sources","The comment does not contain any specific medical claim","The comment appears to be a response to another user"],"trustScore":0.7}
2025-10-13 21:07:24.370 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c6c43d5-6e8f-4940-b012-1a351559afc4, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment states that a claim lacks evidence","The comment is responding to a bold performance claim","The comment expresses skepticism about evidence supporting a claim"],"trustScore":0.7}
2025-10-13 21:07:24.443 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee6748fd-7b7b-4c5a-840a-3d4746ec5ed1, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims Section 3 contains mathematical errors","This is a critique of a paper summary","The statement is about mathematical correctness"],"trustScore":0.5}
2025-10-13 21:07:24.475 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f229f4ce-f7b1-45f8-955a-ee3f45b7e62c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["用户表达了对视频内容的积极评价","视频主题是Kubernetes基础教程","用户认为视频内容实用有价值"],"trustScore":0.8}
2025-10-13 21:07:24.504 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8757baf6-b7d0-4b24-b640-8b8994332770, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["Confidence intervals overlapping does not necessarily mean there is no statistically significant difference between groups."],"trustScore":0.8}
2025-10-13 21:07:24.750 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=00d73cce-8e9c-484b-8a9c-29a27a9feac6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment offers a free gift without context","This pattern is commonly used in spam comments","The comment appears unrelated to the video content"],"trustScore":0.1}
2025-10-13 21:07:24.814 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41fbe011-5aad-45a1-80d3-7a1735c4f418, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["User requested removal of comment for being off-topic","Comment was posted in thread about safety policies","User identified content as not relevant to discussion"],"trustScore":0.7}
2025-10-13 21:07:24.930 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c020b92-22d9-42dd-adf7-9c2595a64a4a, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["评论者认为视频内容一般","评论者认为视频例子较少"],"trustScore":0.7}
2025-10-13 21:07:25.105 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ec7ec9a2-ad63-41ae-a969-2b0df2d9f5a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, result={"type":"opinion","confidence":0.95,"facts":["User posted content containing a slur","The comment violates community guidelines against hate speech","Slurs are prohibited under platform content policies"],"trustScore":0.9}
2025-10-13 21:07:25.310 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95c8a7c6-0dea-4b41-862c-408f1a11fe73, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["Comment contains personal attack language","Comment violates platform civility guidelines","Comment occurred in code review context"],"trustScore":0.2}
2025-10-13 21:07:25.372 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49411a9d-252b-47ce-9b75-b907bd79eb27, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses approval of content","The comment indicates the user saved the content for later reference"],"trustScore":0.8}
2025-10-13 21:07:25.516 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0ba93b4d-2927-4dda-821f-4ee669536098, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citations for a health claim","The comment does not make any factual claims itself","The comment appears in a health claim discussion context"],"trustScore":0.7}
2025-10-13 21:07:25.587 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f299fe5f-b773-4aca-b018-6b228da535cd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:07:25.865 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=55d9b0ea-0e9c-4fc2-a777-a4814ce312c6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, result={"type":"opinion","confidence":0.7,"facts":["The comment requests proof for a claimed state-of-the-art achievement","The comment references a leaderboard screenshot as context","The comment expresses skepticism about an unverified claim"],"trustScore":0.5}
2025-10-13 21:07:26.027 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7296e25d-7a58-449e-9d52-9747cf5343f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["The graph lacks labeled axes","Unlabeled axes make data interpretation unreliable","Proper graphs require clear axis labels for context"],"trustScore":0.3}
2025-10-13 21:07:26.101 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb7868a8-1660-42d0-9524-6d787cc9acbd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset does not include license information","License information is typically required for data sharing and reuse","Missing license info can limit dataset usability"],"trustScore":0.85}
2025-10-13 21:07:26.275 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cb056b95-15f3-4e45-9a34-b575fa66efdc, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset link provided in the forum post is broken","The user has reported repro steps for the broken link issue","The link failure prevents access to the referenced dataset"],"trustScore":0.85}
2025-10-13 21:07:26.309 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c4f5dc0f-6979-4644-bc27-17d45aee9e75, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment 'Unconstructive negativity' was posted on a project showcase","The comment provides no specific feedback about the project","The comment expresses a negative sentiment without constructive elements"],"trustScore":0.2}
2025-10-13 21:07:26.452 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2533d0d2-769f-4771-8d9a-69dc86773f32, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, result={"type":"fact","confidence":0.9,"facts":["Mislabelled axes can invalidate data interpretation in plots","Axes labels are essential for proper understanding of plotted data","Incorrect axis labeling can lead to misinterpretation of throughput vs latency relationships"],"trustScore":0.95}
2025-10-13 21:07:26.455 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=08a7d70d-ea51-4bf7-a29e-ddd4a9fe70e5, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment uses ad hominem attack","Ad hominem attacks focus on the person rather than the argument","Ad hominem attacks are considered logical fallacies"],"trustScore":0.2}
2025-10-13 21:07:26.838 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4dcd23a1-5438-4b97-b670-ef46e0788c82, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["视频标题声称三天学会大数据","评论者认为内容质量低","评论者认为标题具有误导性"],"trustScore":0.7}
2025-10-13 21:07:26.939 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a4bdb647-5b07-4c2b-8b00-216a6168c7c7, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.9,"facts":["The comment 'This is misinformation' makes an unsubstantiated claim about vaccine information","The comment provides no specific evidence or context to support its claim","Vaccine safety is supported by extensive scientific research and regulatory oversight"],"trustScore":0.2}
2025-10-13 21:07:27.283 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=269c2dfc-0aa5-4e14-aa19-4951ebbf1d17, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, result={"type":"misinformation","confidence":0.95,"facts":["This comment promises to double cryptocurrency sent by users","Such promises are commonly associated with cryptocurrency scams","No legitimate service guarantees instant cryptocurrency doubling"],"trustScore":0.1}
2025-10-13 21:07:28.092 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ec52b6f-eaa7-401a-939c-c38c3eaed0da, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User is reporting hate speech in replies","Thread is described as descending into insults","This is a meta-comment about content moderation"],"trustScore":0.7}
2025-10-13 21:07:29.579 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7d201761-1070-4533-b2eb-ecf4d7e5527f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["The comment claims 'misleading axis scaling' without specifying what makes it misleading","Axis scaling choices can intentionally or unintentionally distort data visualization","Proper data visualization should use appropriate scales to accurately represent relationships"],"trustScore":0.3}
2025-10-13 21:09:37.223 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 21:09:37.224 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 21:09:37.224 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 21:09:37.225 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.225 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.225 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 21:09:37.226 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.226 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:09:37.754 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 21:09:37.755 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 21:09:37.755 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 21:09:37.765 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 21:09:37.772 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.producer for producer-1 unregistered
