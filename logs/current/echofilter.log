2025-10-13 20:24:59.453 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 97924 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 20:24:59.457 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 20:24:59.492 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 20:24:59.492 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 20:25:00.707 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 20:25:00.709 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 20:25:00.753 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 29 ms. Found 0 Redis repository interfaces.
2025-10-13 20:25:01.425 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 20:25:01.436 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 20:25:01.438 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 20:25:01.438 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 20:25:01.477 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 20:25:01.477 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1984 ms
2025-10-13 20:25:02.263 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 20:25:02.579 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 20:25:02.631 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 20:25:02.694 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:25:02.695 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:25:02.695 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760401502693
2025-10-13 20:25:05.267 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 20:25:05.270 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:25:05.270 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:25:05.270 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:25:05.274 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 20:25:05.279 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 20:25:05.298 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 20:25:05.330 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 20:25:05.367 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:25:05.367 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:25:05.367 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760401505367
2025-10-13 20:25:05.368 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 20:25:05.382 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 6.43 seconds (process running for 7.368)
2025-10-13 20:25:06.391 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:25:06.519 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 20:25:06.521 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:25:07.731 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100
2025-10-13 20:25:07.732 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:25:11.096 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100', protocol='range'}
2025-10-13 20:25:11.102 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 1: {consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 20:25:11.515 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100', protocol='range'}
2025-10-13 20:25:11.516 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 20:25:11.518 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:25:11.802 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-1
2025-10-13 20:25:11.802 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-0
2025-10-13 20:25:11.802 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-11
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-10
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-7
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-6
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-9
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-8
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-3
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-2
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-5
2025-10-13 20:25:11.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-4
2025-10-13 20:25:12.055 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-1
2025-10-13 20:25:12.055 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-0
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-11
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-10
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-7
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-6
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-9
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-8
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-3
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-2
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-5
2025-10-13 20:25:12.056 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Found no committed offset for partition ef.requests.v1-4
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-1 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-0 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-10 to position FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-7 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-6 to position FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.072 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-9 to position FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-8 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-3 to position FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-2 to position FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-5 to position FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.073 [kafka-1] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting offset for partition ef.requests.v1-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 20:25:13.417 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:25:49.759 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 20:25:49.759 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 20:25:49.760 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 1 ms
2025-10-13 20:25:49.880 [tomcat-handler-1] INFO  o.a.k.c.producer.ProducerConfig - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 20:25:49.881 [tomcat-handler-1] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= initializing Kafka metrics collector
2025-10-13 20:25:49.889 [tomcat-handler-1] INFO  o.a.k.clients.producer.KafkaProducer - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 20:25:49.900 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= Kafka version: 3.9.1
2025-10-13 20:25:49.901 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:25:49.901 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= Kafka startTimeMs: 1760401549900
2025-10-13 20:25:50.891 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:25:50.920 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=41a904d7-5dc0-41ea-8ce8-dc7ba7869bf2 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=1143 handler=SendToKafkaController.batch
2025-10-13 20:25:51.003 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1003 with epoch 0
2025-10-13 20:26:00.815 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:26:00.815 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:26:00.816 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-f2c6180c-a953-4120-b64e-ccf072f78100 sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 20:26:00.816 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:26:00.816 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:26:00.817 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 20:26:00.818 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:26:00.818 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 20:26:01.546 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:26:01.548 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 20:26:01.548 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 20:26:01.550 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 20:26:01.559 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 20:26:01.567 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 20:26:01.569 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:26:01.570 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.producer for producer-1 unregistered
2025-10-13 20:47:59.196 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 101028 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 20:47:59.197 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 20:47:59.228 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 20:47:59.229 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 20:47:59.731 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 20:47:59.733 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 20:47:59.769 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 27 ms. Found 0 Redis repository interfaces.
2025-10-13 20:48:00.318 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 20:48:00.326 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 20:48:00.327 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 20:48:00.327 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 20:48:00.364 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 20:48:00.364 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1135 ms
2025-10-13 20:48:01.018 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 20:48:01.314 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 20:48:01.360 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 20:48:01.408 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:48:01.409 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:48:01.409 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402881407
2025-10-13 20:48:04.214 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 20:48:04.217 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:48:04.217 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:48:04.217 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:48:04.222 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 20:48:04.227 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 20:48:04.244 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 20:48:04.269 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 20:48:04.302 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:48:04.302 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:48:04.302 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402884302
2025-10-13 20:48:04.303 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 20:48:04.316 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 5.551 seconds (process running for 6.021)
2025-10-13 20:48:05.300 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:48:05.302 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 20:48:05.303 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:48:06.304 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024
2025-10-13 20:48:06.304 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:48:09.549 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024', protocol='range'}
2025-10-13 20:48:09.555 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 3: {consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 20:48:09.800 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024', protocol='range'}
2025-10-13 20:48:09.801 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 20:48:09.803 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-1 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-10 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-7 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-6 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.299 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-9 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-8 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-3 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-5 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.300 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:48:10.411 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:48:15.000 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 20:48:15.000 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 20:48:15.001 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 1 ms
2025-10-13 20:48:15.070 [tomcat-handler-1] INFO  o.a.k.c.producer.ProducerConfig - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 20:48:15.072 [tomcat-handler-1] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= initializing Kafka metrics collector
2025-10-13 20:48:15.079 [tomcat-handler-1] INFO  o.a.k.clients.producer.KafkaProducer - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 20:48:15.089 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= Kafka version: 3.9.1
2025-10-13 20:48:15.089 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:48:15.089 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= Kafka startTimeMs: 1760402895089
2025-10-13 20:48:15.290 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4dc6ead6-2cb2-4afd-85c8-f464a7d30aab","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:16.076 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:48:16.076 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1004 with epoch 0
2025-10-13 20:48:16.098 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=7376ca4b-c51e-4b12-b41b-8743bfe9dfc7 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=1079 handler=SendToKafkaController.batch
2025-10-13 20:48:18.532 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"da2212e4-ed9f-4f17-82a0-1b69cd45765c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:21.774 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"61b3c210-c723-4389-8038-7bf748e40e05","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:25.022 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f181b28b-8a10-4774-8787-ee79f313fad5","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:28.269 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7ba9f5ce-1f6d-49a3-ba31-23372147ad97","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:31.524 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f1288b5f-fa60-4a01-90e5-2565f61b5818","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:34.767 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"37d7b13d-e050-4aff-a518-ce84a923ea75","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:38.004 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4695c4c6-b423-491b-afc0-5be05cce2fd4","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:41.323 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f8dcf824-e498-4d57-a76d-6bb2b1afd12e","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:44.606 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"250ef572-bc17-45b0-bb69-360ed89eabae","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:47.852 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1388b658-fd2b-4247-b69c-ef60d6e8db10","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:51.096 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"06f5109d-82a7-4369-b58f-98a3d649352c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:54.343 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b1144e25-6719-4033-8aaf-480c52f6f2ce","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:48:57.591 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5bfcdeb0-a769-4367-b97c-246b93d05f7f","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:00.839 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ef4fd9bd-95ba-4526-b39a-476dc5744ca1","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:04.108 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fe63aac6-691c-491d-b8c0-95d1127e31fb","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:07.348 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5378bb8e-d8a7-4e8e-9283-f00b65b18379","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:10.595 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5daf1b98-5c0e-4241-b726-eb0f8de11553","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:13.842 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d8f2d461-c7ee-4561-901d-bcedb8621054","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:17.097 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b78b17d5-c989-421b-a821-2ce0aa97c132","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:20.410 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eebe88a0-bc43-4e6c-a31d-ba32d208ecce","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:23.661 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fb4f6a9c-c2bf-4433-8d8e-f3c130f89001","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:26.921 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"90215d04-bb6d-464e-acb1-0e7b9e58e77c","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:30.171 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"abfc3123-8a55-4c55-9eff-e18dc70e06e5","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:33.422 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9dde89df-8b52-434d-ad6d-77bfd32b7e8b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:36.668 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1879c3a6-0377-4b25-9515-3403c15577af","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:39.951 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a1f0ce6b-6771-4b92-aeb4-61e1c9adeb1d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:41.695 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:49:41.695 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-e51cd171-2099-4def-8c44-5eade8e28024 sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:49:41.696 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 20:49:41.697 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 20:49:41.697 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 20:49:42.307 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:49:42.309 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 20:49:42.309 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 20:49:42.310 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 20:49:42.320 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 20:49:43.206 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"944b0f79-8615-4875-91ed-df56654baaf7","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis

org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1858)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1789)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1586)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.lambda$getConnection$0(LettuceConnectionFactory.java:1566)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.doInLock(LettuceConnectionFactory.java:1527)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1563)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:1249)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:1055)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:401)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:142)
	at org.springframework.data.redis.cache.DefaultRedisCacheWriter.get(DefaultRedisCacheWriter.java:133)
	at org.springframework.data.redis.cache.RedisCache.lookup(RedisCache.java:185)
	at org.springframework.cache.support.AbstractValueAdaptingCache.get(AbstractValueAdaptingCache.java:58)
	at org.springframework.cache.interceptor.AbstractCacheInvoker.doGet(AbstractCacheInvoker.java:78)
	at org.springframework.cache.interceptor.CacheAspectSupport.findInCaches(CacheAspectSupport.java:574)
	at org.springframework.cache.interceptor.CacheAspectSupport.findCachedValue(CacheAspectSupport.java:523)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:446)
	at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:410)
	at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:65)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl$$SpringCGLIB$$0.getCommentResult(<generated>)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:114)
	at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1787)
	... 25 common frames omitted
Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 81.70.198.98/<unresolved>:6379
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:63)
	at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:41)
	at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:354)
	at io.lettuce.core.RedisClient.connect(RedisClient.java:220)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:112)
	at java.base/java.util.Optional.orElseGet(Optional.java:364)
	at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:112)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.lambda$getConnection$0(LettucePoolingConnectionProvider.java:96)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:270)
	at io.lettuce.core.support.ConnectionPoolSupport$RedisPooledObjectFactory.create(ConnectionPoolSupport.java:257)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:68)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:557)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:299)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:231)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:149)
	at io.lettuce.core.support.ConnectionPoolSupport$1.borrowObject(ConnectionPoolSupport.java:144)
	at org.springframework.data.redis.connection.lettuce.LettucePoolingConnectionProvider.getConnection(LettucePoolingConnectionProvider.java:109)
	... 26 common frames omitted
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: getsockopt: /81.70.198.98:6379
Caused by: java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:336)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:339)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:784)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:732)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:1583)

2025-10-13 20:49:50.417 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 101528 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 20:49:50.418 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 20:49:50.450 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 20:49:50.450 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 20:49:50.983 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 20:49:50.985 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 20:49:51.026 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 30 ms. Found 0 Redis repository interfaces.
2025-10-13 20:49:51.592 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 20:49:51.599 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 20:49:51.600 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 20:49:51.600 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 20:49:51.637 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 20:49:51.637 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1187 ms
2025-10-13 20:49:52.288 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 20:49:52.618 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 20:49:52.664 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 20:49:52.711 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:49:52.711 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:49:52.711 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402992710
2025-10-13 20:49:55.205 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 20:49:55.208 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 20:49:55.208 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 20:49:55.208 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 20:49:55.212 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 20:49:55.218 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 20:49:55.237 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 20:49:55.264 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 20:49:55.299 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 20:49:55.299 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:49:55.299 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760402995299
2025-10-13 20:49:55.300 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 20:49:55.317 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 5.31 seconds (process running for 5.773)
2025-10-13 20:49:56.298 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:49:56.298 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 20:49:56.300 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:49:57.326 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da
2025-10-13 20:49:57.326 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 20:50:00.583 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=5, memberId='consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da', protocol='range'}
2025-10-13 20:50:00.588 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 5: {consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 20:50:00.847 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=5, memberId='consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da', protocol='range'}
2025-10-13 20:50:00.847 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 20:50:00.850 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 20:50:01.367 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-1 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-10 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-7 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-6 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-9 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-8 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-3 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-5 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.368 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 20:50:01.475 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"37d7b13d-e050-4aff-a518-ce84a923ea75","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"90215d04-bb6d-464e-acb1-0e7b9e58e77c","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f8dcf824-e498-4d57-a76d-6bb2b1afd12e","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d8f2d461-c7ee-4561-901d-bcedb8621054","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"61b3c210-c723-4389-8038-7bf748e40e05","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7226e493-13b5-4ec9-8298-6519b92783db","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"944b0f79-8615-4875-91ed-df56654baaf7","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"abfc3123-8a55-4c55-9eff-e18dc70e06e5","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fb4f6a9c-c2bf-4433-8d8e-f3c130f89001","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ef4fd9bd-95ba-4526-b39a-476dc5744ca1","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b78b17d5-c989-421b-a821-2ce0aa97c132","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"bb0c720a-eddc-4566-a38c-c6497c82f3ff","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b552efad-91d0-4653-8967-fd7e32170ac0","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eab2df4d-223c-43f0-8100-ed3ad7e49d2b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"368748a5-d7d5-4cb1-8bb7-f832e2d97356","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1c13c745-28c1-4a5e-af9d-f6321b1fbac1","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"250ef572-bc17-45b0-bb69-360ed89eabae","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4695c4c6-b423-491b-afc0-5be05cce2fd4","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fe63aac6-691c-491d-b8c0-95d1127e31fb","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"25c48b7b-5407-438a-a97b-00adbc88b71b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f1288b5f-fa60-4a01-90e5-2565f61b5818","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5bfcdeb0-a769-4367-b97c-246b93d05f7f","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"da2212e4-ed9f-4f17-82a0-1b69cd45765c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5378bb8e-d8a7-4e8e-9283-f00b65b18379","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a6144b46-9905-4fbe-9c0c-ec993db2b954","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.792 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eebe88a0-bc43-4e6c-a31d-ba32d208ecce","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f181b28b-8a10-4774-8787-ee79f313fad5","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9dde89df-8b52-434d-ad6d-77bfd32b7e8b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7ba9f5ce-1f6d-49a3-ba31-23372147ad97","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"36b77cb6-1873-4b23-af79-0eba9dd47d73","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"06f5109d-82a7-4369-b58f-98a3d649352c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4dc6ead6-2cb2-4afd-85c8-f464a7d30aab","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1388b658-fd2b-4247-b69c-ef60d6e8db10","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.790 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5daf1b98-5c0e-4241-b726-eb0f8de11553","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b1144e25-6719-4033-8aaf-480c52f6f2ce","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49181ded-eb9b-492c-a75a-13e6de16f1ef","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.789 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a1f0ce6b-6771-4b92-aeb4-61e1c9adeb1d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1879c3a6-0377-4b25-9515-3403c15577af","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c656f110-fc25-4134-80e8-e0d115eaa18d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:02.793 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eaa5fb18-89a1-491e-a4b8-a5629715ba46","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:14.318 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 20:50:14.318 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 20:50:14.318 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 0 ms
2025-10-13 20:50:14.377 [tomcat-handler-1] INFO  o.a.k.c.producer.ProducerConfig - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 20:50:14.378 [tomcat-handler-1] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= initializing Kafka metrics collector
2025-10-13 20:50:14.390 [tomcat-handler-1] INFO  o.a.k.clients.producer.KafkaProducer - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 20:50:14.412 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= Kafka version: 3.9.1
2025-10-13 20:50:14.413 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 20:50:14.413 [tomcat-handler-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= Kafka startTimeMs: 1760403014412
2025-10-13 20:50:15.396 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 20:50:15.397 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1005 with epoch 0
2025-10-13 20:50:15.417 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=1e0b34b3-c7c7-472e-b8cb-b9bc378de2b6 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=1083 handler=SendToKafkaController.batch
2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2b9c0a71-5a6f-4260-b5c6-9c06d544d3d6","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"27114458-856a-41a3-a417-5d47ddaa391e","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c8e3a661-5803-492d-8edd-0f56d0263023","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7067b14-d740-47be-813f-812f7c7a68cb","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"8200c528-d3d8-4600-915e-480795f6e0d1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f6e76aa1-5c48-47aa-9a7e-36b78e3e59a4","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f07ed24b-006e-495f-aa26-c3feb5819971","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4a6234ca-633f-48b5-ab34-a646ed8a2d59","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.928 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5d519dd8-9235-4abf-9115-9f43d1169b34","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ca7745b9-7066-47c6-be88-89cd366254f5","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"3929a0bc-388a-4e18-bec9-1e16d5a6f755","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"44ee5d32-69e4-444b-84a4-efbc3a3d2df1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b4dba9a1-24d8-4ad3-9cac-387149d1711a","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cce4ba6c-742a-42aa-93fc-d49aa5fda649","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"31803d28-539a-45d4-ae39-26269e133726","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b5fc141e-750f-4dfc-ac48-2b800e138788","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f5e1db9-3263-4b71-a4c3-a1c9582ea77c","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2ac9067a-e6cd-40b4-923c-e7ea96e23f17","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4c5791e6-f63f-49df-86e1-544099abe1aa","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:50:16.929 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9ac39178-b084-4862-99b3-447680d3c9ae","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.193 [tomcat-handler-4] INFO  c.e.c.Interceptors.TimingInterceptor - trace=13863a84-9625-4c06-8c9a-e099e89921d0 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=6 handler=SendToKafkaController.batch
2025-10-13 20:52:23.449 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49ce82b2-e529-4572-9f0b-60c416a1873a","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"deeps...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.940 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7c6a4d0-92a4-4b9b-88b3-b88fea05f2b8","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-chat","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.940 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"494653d8-0994-4587-a06f-86fd1939d7cc","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"202...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"63bb9e23-9f12-4a9d-b798-a536d6afe569","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","create...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b2d8f693-8d28-4487-85ba-e015b950f224","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e0fe3ea4-a1a1-4423-a574-9f397b33c919","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:23.941 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"400478de-2529-4b97-8265-5de26e49f02b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"de...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e86ee1b3-b072-4f2d-ab46-9d3eb4296e61","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1ab31aec-e632-4b60-89ca-9c2a91243365","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0b5caf98-1555-416a-9eb5-bde1f5c4299b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cff094e6-507f-4c46-8b11-d2395942c492","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","creat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1272ea59-1ce4-41a0-90d7-0c5e5347a7f6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deep...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d488082a-2590-46c1-94bd-2ae9f8463cb3","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d80c7dd0-104f-47d9-b17e-0afdb2d450f2","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0fc78c89-defc-4fe2-a67b-04cec1fcd246","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"97c5acc5-1693-4520-9a06-3bb7a513b3c6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-chat"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f6d6bf8-f05d-4f4d-952e-0b3d38fd251e","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9c165839-840e-486f-a9a3-a3cf7cbde096","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat",...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5c1371d9-2595-4a72-a2ab-619dba9be21f","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:52:24.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b3c3d87c-4e85-4bba-a846-fb104ee9d6e4","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:52)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 20:55:54.149 [tomcat-handler-7] INFO  c.e.c.Interceptors.TimingInterceptor - trace=9cc03623-1fc8-4c9b-9849-db7b27b64596 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=5 handler=SendToKafkaController.batch
2025-10-13 20:56:00.894 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dbea503-66f8-4837-bb4e-bfc4ac42c010, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about work"],"trustScore":0.8}
2025-10-13 20:56:01.345 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=148f9ccb-96e1-4731-9e7f-77b26f267416, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment was posted on a YouTube video about a new product"],"trustScore":0.8}
2025-10-13 20:56:01.548 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=016b4879-0453-4b38-b1ce-23ff1badf8dd, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 20:56:02.031 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d36c2c30-ac4a-4e33-95bd-4ec730bfe752, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The comment is a response to a guide about Docker"],"trustScore":0.8}
2025-10-13 20:56:02.364 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bb00bdd7-c982-445e-9cc3-e9eedd6ccd37, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about a Java virtual threads tutorial"],"trustScore":0.8}
2025-10-13 20:56:02.501 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=35b9ae45-777c-4f59-b614-8a51f6c67bfa, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.5,"facts":["The comment consists of a single word 'Source?'","The comment is requesting verification of a claim","The comment does not make any factual assertions"],"trustScore":0.7}
2025-10-13 20:56:02.581 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=81e715a6-8d50-41af-9979-37a925ff638e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 20:56:02.904 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=576d5948-13a4-4ad8-927a-09cd22eda1db, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service to buy followers","The website domain 'spammy.site' suggests potential spam activity","Such services typically violate platform terms of service"],"trustScore":0.1}
2025-10-13 20:56:02.943 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4c1b56fe-5561-461e-8c2e-482f35b0fe7c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators","The comment is identified as off-topic advertising","The comment contains no substantive content"],"trustScore":0.1}
2025-10-13 20:56:03.044 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c7c24514-c30f-4541-ac6b-000e3f5c60a1, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement","The comment does not provide specific factual claims","The comment is a personal viewpoint"],"trustScore":0.7}
2025-10-13 20:56:03.180 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3b8661fa-b478-41b0-acaa-3e49f7ceb54d, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 20:56:03.459 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=06c51f49-f8a2-428b-b9eb-f6a3fc19ee9f, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 20:56:03.558 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd28a2b-705c-4655-8193-c38e21835af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 20:56:03.623 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f7a76d79-9c99-4cf4-8efc-d2e1beb71adc, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","Cherry-picking refers to selectively choosing data","Benchmarks can be manipulated through selective data presentation"],"trustScore":0.4}
2025-10-13 20:56:04.561 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=40bc0bf4-3875-457f-9928-9944714ce0e6, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment serves as a content moderation report"],"trustScore":0.7}
2025-10-13 20:56:04.601 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1f9de0b6-ff90-4828-9566-ccea63ed2af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a critical assessment without providing specific corrections"],"trustScore":0.3}
2025-10-13 20:56:04.967 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bdd8791b-4d99-4540-bad3-934ab668ad4a, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","","''"],"trustScore":0.7}
2025-10-13 20:56:05.351 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ef0d9ecf-c1bb-429d-9655-014e479bc9e8, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Scientific consensus supports vaccine safety and efficacy"],"trustScore":0.2}
2025-10-13 20:56:08.112 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6a691020-1be8-4682-bdc8-ff09cdf1db2c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 20:56:09.385 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9ed099bb-325a-46ba-8cf3-a376788d372e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them but never return funds","Legitimate giveaways don't require sending cryptocurrency first"],"trustScore":0.1}
2025-10-13 21:03:34.725 [tomcat-handler-10] INFO  c.e.c.Interceptors.TimingInterceptor - trace=7f61f143-d16e-4f3f-b766-546deec0c7e6 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=5 handler=SendToKafkaController.batch
2025-10-13 21:03:41.311 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2ab16530-5e1b-48a5-9609-f2a5b1dd195d, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about work"],"trustScore":0.8}
2025-10-13 21:03:41.958 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9d7a06fa-9576-4ba0-833c-e1abda5eb84c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:03:42.110 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=20749219-d661-4de9-9a14-ae2b9274d3f7, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:03:42.152 [tomcat-handler-11] INFO  c.e.c.Interceptors.TimingInterceptor - trace=b605c0d5-9186-4c9e-bd50-74d777d97b1e tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=5 handler=SendToKafkaController.batch
2025-10-13 21:03:42.657 [tomcat-handler-12] INFO  c.e.c.Interceptors.TimingInterceptor - trace=d060f62d-c273-4094-bb7f-350f205082e3 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=4 handler=SendToKafkaController.batch
2025-10-13 21:03:42.810 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6adde89d-0700-4107-aa1e-535cdbbc355f, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 21:03:42.947 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d9ae8151-7d58-45a6-91dc-2ae926012fde, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators.","The comment is identified as off-topic advertising.","The comment contains no substantive content."],"trustScore":0.1}
2025-10-13 21:03:43.234 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fe9fdad8-07bf-47f9-93d4-e3422c7694c8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","This pattern is commonly associated with spam"],"trustScore":0.1}
2025-10-13 21:03:43.816 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9545cb66-774e-4537-9995-768fe7ca5472, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment was posted on a YouTube video about a new product","The comment does not contain substantive content about the product"],"trustScore":0.1}
2025-10-13 21:03:43.942 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=05d824d4-83f6-404a-bc10-b617332d2348, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:03:43.944 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=39041652-0308-4595-bfe2-acc295652e46, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language to convey approval.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 21:03:44.262 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4bf23d27-5ab0-47c5-805b-20dbd66e84b6, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:44.456 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79dc8dd6-f120-4532-9f89-f71088eb6127, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment \"Source?\" is a request for verification","The comment questions the validity of a claim made by OP","The comment seeks additional supporting information"],"trustScore":0.7}
2025-10-13 21:03:44.477 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41f1e249-a1fe-4eff-8735-752f3fe3e36a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 21:03:44.821 [tomcat-handler-13] INFO  c.e.c.Interceptors.TimingInterceptor - trace=82891cd9-ca92-4e2f-a5da-5829f62231b6 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=6 handler=SendToKafkaController.batch
2025-10-13 21:03:45.016 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=109c7cf2-d7ee-4c59-bb86-73b199b572cb, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing social media followers","The website 'spammy.site' is advertised as a source for followers","Purchased followers are typically fake or inactive accounts"],"trustScore":0.1}
2025-10-13 21:03:45.135 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2b81cd5f-0f42-4ec6-86b5-e8498b537e8a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:03:46.854 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e72bdadd-2d8a-4352-a607-97bd15c4837c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["The comment claims something is misinformation without providing specific details","The comment references vaccines but lacks substantive claims to verify","The comment makes an assertion without supporting evidence"],"trustScore":0.2}
2025-10-13 21:03:47.082 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e3c86ce4-3f2f-4c80-b18f-a0ff5253baf8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:03:47.733 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6b55d4c8-3604-49d1-a1b5-5ba6a8acb7d9, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:03:48.873 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67e65cf1-393c-49dd-b482-5853217e3baf, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 21:03:48.878 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c0353cbc-15e3-47db-8e55-6c1834d000e1, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:03:49.057 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6497c0ba-6b98-4d6f-b5b4-68894dadc5ad, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment 'First!' is a common internet expression"],"trustScore":0.1}
2025-10-13 21:03:49.079 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f998ab15-ba4a-4adc-8071-38555397d04f, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:03:49.275 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b36cc0a3-d5b3-40ce-b341-bf3a655ba495, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment claims the reported content contains hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.3}
2025-10-13 21:03:49.306 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62d6988c-150d-40ba-9ad1-ad40d7a47a65, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:03:49.643 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eaa74604-527f-435e-b879-212c2c26fe7b, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Legitimate giveaways do not require sending money first","Such promises of doubling money are financially impossible to sustain"],"trustScore":0.1}
2025-10-13 21:03:49.774 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7fb800e1-3bc4-4164-b96b-c436d8babdd9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.7}
2025-10-13 21:03:50.350 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b51c8516-5bff-4faa-9d09-1b50652da06a, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation.","The context involves a guide about Docker.","The comment does not contain factual claims or opinions about Docker."],"trustScore":1.0}
2025-10-13 21:03:50.384 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b963e393-db2c-460f-9b86-13d24340e860, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker"],"trustScore":0.8}
2025-10-13 21:03:50.498 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6ed0d646-4885-4829-872c-84e728387ebc, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators","The comment is identified as off-topic advertising","The comment contains no substantive content"],"trustScore":0.1}
2025-10-13 21:03:50.985 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=277f8c6d-90fa-4cce-863b-5b13596cfcf4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a neutral information request","The context is a paper discussion"],"trustScore":0.8}
2025-10-13 21:03:50.999 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b0b86aa6-09a6-4c9f-8007-8d6e84f3567e, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators","The comment is identified as off-topic advertising","The comment contains no substantive content"],"trustScore":0.1}
2025-10-13 21:03:51.015 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=34a9aa92-4694-4a12-8c2a-06abd46c9570, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:03:51.027 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab75c19a-0bac-47ea-bd4d-a30c9afa8f7d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment 'Source?' is a request for verification","The comment responds to a claim of 'big improvement'","The comment does not contain substantive content itself"],"trustScore":0.5}
2025-10-13 21:03:51.036 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b87039b1-0ad4-469d-a01c-770618591bb4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'"],"trustScore":0.5}
2025-10-13 21:03:51.100 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=51ed5585-4a67-4948-8e65-2584d8ea4689, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses approval of a Java virtual threads tutorial.","The comment indicates the tutorial was explained clearly.","The comment is a positive reaction to educational content."],"trustScore":0.8}
2025-10-13 21:03:51.166 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b000f118-8c3a-4149-97c6-f821755a49c5, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language common in online platforms.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 21:03:51.209 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=892b3155-bd18-41a6-9dad-4f665701b633, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' appears to be associated with artificial engagement","Purchased followers typically violate platform terms of service"],"trustScore":0.1}
2025-10-13 21:03:51.412 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6e1ce085-5e70-479e-8832-837a2fc58454, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["This comment solicits cryptocurrency transfers","It promises to double any cryptocurrency sent","This is a common scam pattern on social media"],"trustScore":0.1}
2025-10-13 21:03:51.531 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=598ce2cf-7c6f-4024-bee6-8b46e3353f9d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:03:51.561 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dd8d9ef-3816-46cf-a232-05de8f7903f6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:03:51.634 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb361d89-44fc-47aa-b0fe-68c67b45b120, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper"],"trustScore":0.6}
2025-10-13 21:03:51.672 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3f9449b9-73af-4a48-8071-faf9827eb9f3, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 21:03:51.680 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ca2b61d-548c-4e54-8fb9-e780a290d678, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:03:51.736 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eeaa421d-6448-445c-b598-025575e5a5d8, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","The choice between tabs and spaces is subjective in programming"],"trustScore":0.8}
2025-10-13 21:03:51.779 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddf57981-197c-4c15-932c-13f850b5d634, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:03:51.785 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=236aecee-ddab-46f6-99ca-5424273ad97a, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The website domain 'spammy.site' suggests potential spam activity","Purchasing followers violates most platform terms of service"],"trustScore":0.1}
2025-10-13 21:03:51.989 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee031476-f227-4284-ae0e-8bb25385ecfe, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:03:52.075 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdea544e-14be-4c04-9d17-1bc87024fed8, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with an unspecified position"],"trustScore":0.7}
2025-10-13 21:03:52.088 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee8a4813-3889-41de-9d89-a57cb4a97bca, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment 'Source?' is a request for verification","The comment responds to a claim of 'big improvement'","The comment does not contain substantive claims itself"],"trustScore":0.7}
2025-10-13 21:03:52.209 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a71964d9-3543-43a5-b125-71be3808d163, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:03:52.344 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24a751f6-aae2-4f6e-891a-af44f51d68fd, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:52.462 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0973ef42-5216-42be-bc00-5e25cc3c05ae, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX",""],"trustScore":0.6}
2025-10-13 21:03:52.600 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4e9c5a0b-746d-4311-9f31-5d11e6fffaac, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'"],"trustScore":0.5}
2025-10-13 21:03:52.644 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3ea118c4-6591-40c9-af3d-2d2a01fd0977, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The comment is responding to a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 21:03:52.681 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6bb54e4e-24e8-45df-b897-1b2b674d8aa6, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references a comparison between Model X and Y","The comment implies potential bias in benchmark selection"],"trustScore":0.4}
2025-10-13 21:03:52.684 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=643d7c3a-1214-4084-84dd-a50cbd3a009d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about a Java virtual threads tutorial"],"trustScore":0.8}
2025-10-13 21:03:52.776 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7dd90614-dad7-40ee-a18b-8aeeedd5eb72, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment claims the reported content contains hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 21:03:53.235 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2daec662-6315-4137-93d1-830159d8ed90, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety and efficacy"],"trustScore":0.15}
2025-10-13 21:03:53.250 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=52d07cc9-1cef-49b5-a06a-90d267f7c4aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests moderator removal","The comment is labeled as 'pure spam'","The comment is an off-topic advertisement"],"trustScore":0.1}
2025-10-13 21:03:53.355 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fba9d2a9-68e2-4367-bab2-b39b28070714, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment claims the reported content contains hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 21:03:53.489 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1de40a0a-307c-40e1-8440-1c569e800939, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment consists of a single word: \"Source?\"","The comment is requesting verification of a claim made by OP","The comment does not contain substantive content beyond requesting information"],"trustScore":0.5}
2025-10-13 21:03:53.573 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=26b4190d-dc44-42ed-a84f-04ef195b10b1, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.2}
2025-10-13 21:03:53.815 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95fdc418-ce31-4b0c-b279-547b2b6d4455, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for buying followers","The website domain 'spammy.site' suggests potential spam activity","Purchasing followers violates most platform terms of service"],"trustScore":0.1}
2025-10-13 21:03:54.149 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd42c12-58bb-4dff-ad4a-5473819273a3, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:03:54.683 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fc4a930b-d94d-40f3-b212-3b4d45472bd6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","The improvement is measurable"],"trustScore":0.7}
2025-10-13 21:03:54.707 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8a7422c4-386c-4648-9518-117a3c83149d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:55.057 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=875c4059-3206-4cea-859e-4fd5a2a8d427, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:03:55.061 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c38417d-6cf7-4b41-a39c-c68eead23b6c, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates hate speech occurred","The comment serves as a report of inappropriate content"],"trustScore":0.7}
2025-10-13 21:03:55.071 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8863bc1c-103d-490b-8e22-1190f71f7099, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims 'This benchmark is cherry-picked'","The context mentions 'Model X vs Y'","The statement is evaluative rather than purely descriptive"],"trustScore":0.4}
2025-10-13 21:03:55.078 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=769f8b0f-6fe5-4f43-a449-def450a3db00, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:03:55.494 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0014d772-1c46-4f6a-b12b-bc80b52656b7, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:03:55.802 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c6c5b504-43cd-47ca-b251-3a76743c4566, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:03:56.564 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=76e8c239-3365-4431-a207-f6bd93f9c378, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:03:56.587 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=88d15321-4968-41da-9e6f-e94ea18e547e, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:03:56.611 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e60d6b18-79cc-456a-8143-e2ad276d123e, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.15}
2025-10-13 21:03:56.818 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=adad4d4a-7e25-4ad7-90aa-1ee70f566785, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:03:57.505 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d7a78c5d-c89d-48df-b880-e21fba6a1244, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This tweet claims to double cryptocurrency sent to the user","Such 'send crypto to double' offers are commonly associated with scams","Legitimate cryptocurrency giveaways do not require sending funds first"],"trustScore":0.1}
2025-10-13 21:03:57.828 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fd46784e-8426-47df-8f69-8f11669186bf, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:03:58.412 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f76b1eac-7602-404e-ad08-fccd2b774df9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:03:58.748 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e6c9340e-08e0-4c8b-a9a5-38bd2bb007aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:04:00.314 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=21967a31-aeba-4ffa-80cb-7f15d55218e4, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them","These schemes result in permanent loss of funds for victims"],"trustScore":0.1}
2025-10-13 21:07:14.976 [tomcat-handler-16] INFO  c.e.c.Interceptors.TimingInterceptor - trace=83f7b1d4-8631-4a78-ada8-00ad914d114a tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=6 handler=SendToKafkaController.batch
2025-10-13 21:07:22.540 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=89ab3a8b-6fba-4f99-aba7-5ae6928a861c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a write-up","The comment indicates the user learned from the content","The comment does not contain verifiable factual claims"],"trustScore":0.8}
2025-10-13 21:07:22.668 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67f9d2ff-cbad-4598-b2ef-0bf9937ea6af, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for benchmarking methodology"],"trustScore":0.8}
2025-10-13 21:07:22.776 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=59e96b51-60eb-4284-a169-66ddc07d811f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The commenter states the video helped them pass an exam"],"trustScore":0.7}
2025-10-13 21:07:22.846 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d0c219ef-d9fa-45b9-8b8d-d4be260bb70b, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment requests subtitles for a technical lecture replay"],"trustScore":1.0}
2025-10-13 21:07:22.895 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddc10887-50b1-4a4c-932a-6f5f7db45a59, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment 'First!' is a common internet expression"],"trustScore":0.1}
2025-10-13 21:07:22.924 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1553cdd3-d380-4005-bf74-566a004148a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["User is asking where to download a dataset"],"trustScore":0.8}
2025-10-13 21:07:23.043 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7f7c1466-e612-4c02-86c2-26faf54c21f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment requests timestamps for a long-form interview video"],"trustScore":1.0}
2025-10-13 21:07:23.062 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24ad2bf1-a6f2-49ec-95cc-9a31416bf606, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment is requesting presentation materials from a conference talk"],"trustScore":1.0}
2025-10-13 21:07:23.062 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8230466c-a214-4f01-a5f0-c7f1cdc8e44c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses disagreement with someone's understanding of statistics"],"trustScore":0.3}
2025-10-13 21:07:23.236 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d2045139-3329-4cd2-828c-fe3d79bf6441, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a moderator response","The comment expresses gratitude","The comment acknowledges clarification"],"trustScore":0.9}
2025-10-13 21:07:23.362 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49f1e148-9e8d-426b-839d-b9ff3fb9b984, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a tutorial","The comment is positive in tone","The comment acknowledges the value of shared content"],"trustScore":0.8}
2025-10-13 21:07:23.374 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a9ff59a2-bc76-47c0-a8af-0912a726a346, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims results are cherry-picked"],"trustScore":0.3}
2025-10-13 21:07:23.434 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdd0779d-c0a8-4ced-9394-834f4a768528, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a duplicate post request","The user is asking for thread merging","The comment is about forum moderation"],"trustScore":0.8}
2025-10-13 21:07:23.445 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f6a0f493-05ae-445e-a02f-fe4400052d76, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["JSON is a data format","YAML is a data format","Both JSON and YAML are used for data serialization"],"trustScore":0.8}
2025-10-13 21:07:23.461 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19ccfc8c-3229-4298-bc81-c7acbd779121, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User reports bot replies flooding thread","Context indicates suspicious activity","Platform is Twitter"],"trustScore":0.7}
2025-10-13 21:07:23.641 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=03bb3a84-27cc-444e-aab5-2ba43fea1edf, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This comment states that something violates community rules","The comment does not specify what content is being referenced","The comment is making a claim about rule compliance"],"trustScore":0.3}
2025-10-13 21:07:23.646 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab6d490b-c0b7-417a-98a7-36d2f3a60b01, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a demo","The comment contains positive sentiment","The comment is a response to some form of presentation"],"trustScore":0.8}
2025-10-13 21:07:23.731 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=60b40d7e-ce1c-48eb-89c3-302b090b1260, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for assistance.","The comment describes the response as clear and concise.","The comment is a reply to a configuration issue resolution."],"trustScore":0.8}
2025-10-13 21:07:23.792 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b92ac8be-4c46-41d9-8a23-66cd86ea484c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment is asking for evidence supporting a 10x improvement claim","The comment does not make any factual assertions itself","The comment is requesting verification of another user's statement"],"trustScore":0.7}
2025-10-13 21:07:23.832 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2f2b557b-5f40-428d-9494-07663e14fc1d, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 25%"],"trustScore":0.7}
2025-10-13 21:07:23.857 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8ddd3064-7111-4b76-ac55-7d393b6ae2ff, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["Comment contains a promotional link","Link directs to a service selling followers","Domain name appears unprofessional"],"trustScore":0.1}
2025-10-13 21:07:23.878 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62b74d65-deef-49c2-a40e-c07722d28ddd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The model card lacks evaluation details"],"trustScore":0.7}
2025-10-13 21:07:24.002 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=480c4bb4-bd24-40ea-b9c3-1058bd0736ce, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses skepticism about data presentation","The comment suggests potential bias in chart selection","The comment compares Model A favorably in the presented data"],"trustScore":0.6}
2025-10-13 21:07:24.005 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=23073508-96ba-49b3-974e-735e4ca82fdb, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment warns users about a potential scam","The comment advises against clicking a link","The comment appears in a suspicious giveaway thread context"],"trustScore":0.7}
2025-10-13 21:07:24.207 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=caeab287-c0a5-4ab9-8a9c-3d1c584a204f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["User is requesting source code address","Video description appears to lack link","Comment is written in Chinese"],"trustScore":0.7}
2025-10-13 21:07:24.223 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f23a95ea-e397-428c-81bc-9dea4af79366, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of an off-topic advertisement.","The comment is posted in a thread about model interpretability.","The comment does not contribute to the discussion topic."],"trustScore":0.8}
2025-10-13 21:07:24.297 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79a45c71-22dd-4935-8f2b-111e52b9049f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.8}
2025-10-13 21:07:24.298 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19d654be-6563-4c9d-ac96-c5d60ec50380, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citation of sources","The comment does not contain any specific medical claim","The comment appears to be a response to another user"],"trustScore":0.7}
2025-10-13 21:07:24.370 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c6c43d5-6e8f-4940-b012-1a351559afc4, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment states that a claim lacks evidence","The comment is responding to a bold performance claim","The comment expresses skepticism about evidence supporting a claim"],"trustScore":0.7}
2025-10-13 21:07:24.443 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee6748fd-7b7b-4c5a-840a-3d4746ec5ed1, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims Section 3 contains mathematical errors","This is a critique of a paper summary","The statement is about mathematical correctness"],"trustScore":0.5}
2025-10-13 21:07:24.475 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f229f4ce-f7b1-45f8-955a-ee3f45b7e62c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","Kubernetes",""],"trustScore":0.8}
2025-10-13 21:07:24.504 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8757baf6-b7d0-4b24-b640-8b8994332770, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["Confidence intervals overlapping does not necessarily mean there is no statistically significant difference between groups."],"trustScore":0.8}
2025-10-13 21:07:24.750 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=00d73cce-8e9c-484b-8a9c-29a27a9feac6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment offers a free gift without context","This pattern is commonly used in spam comments","The comment appears unrelated to the video content"],"trustScore":0.1}
2025-10-13 21:07:24.814 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41fbe011-5aad-45a1-80d3-7a1735c4f418, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["User requested removal of comment for being off-topic","Comment was posted in thread about safety policies","User identified content as not relevant to discussion"],"trustScore":0.7}
2025-10-13 21:07:24.930 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c020b92-22d9-42dd-adf7-9c2595a64a4a, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["",""],"trustScore":0.7}
2025-10-13 21:07:25.105 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ec7ec9a2-ad63-41ae-a969-2b0df2d9f5a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, result={"type":"opinion","confidence":0.95,"facts":["User posted content containing a slur","The comment violates community guidelines against hate speech","Slurs are prohibited under platform content policies"],"trustScore":0.9}
2025-10-13 21:07:25.310 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95c8a7c6-0dea-4b41-862c-408f1a11fe73, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["Comment contains personal attack language","Comment violates platform civility guidelines","Comment occurred in code review context"],"trustScore":0.2}
2025-10-13 21:07:25.372 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49411a9d-252b-47ce-9b75-b907bd79eb27, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses approval of content","The comment indicates the user saved the content for later reference"],"trustScore":0.8}
2025-10-13 21:07:25.516 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0ba93b4d-2927-4dda-821f-4ee669536098, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citations for a health claim","The comment does not make any factual claims itself","The comment appears in a health claim discussion context"],"trustScore":0.7}
2025-10-13 21:07:25.587 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f299fe5f-b773-4aca-b018-6b228da535cd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:07:25.865 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=55d9b0ea-0e9c-4fc2-a777-a4814ce312c6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, result={"type":"opinion","confidence":0.7,"facts":["The comment requests proof for a claimed state-of-the-art achievement","The comment references a leaderboard screenshot as context","The comment expresses skepticism about an unverified claim"],"trustScore":0.5}
2025-10-13 21:07:26.027 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7296e25d-7a58-449e-9d52-9747cf5343f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["The graph lacks labeled axes","Unlabeled axes make data interpretation unreliable","Proper graphs require clear axis labels for context"],"trustScore":0.3}
2025-10-13 21:07:26.101 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb7868a8-1660-42d0-9524-6d787cc9acbd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset does not include license information","License information is typically required for data sharing and reuse","Missing license info can limit dataset usability"],"trustScore":0.85}
2025-10-13 21:07:26.275 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cb056b95-15f3-4e45-9a34-b575fa66efdc, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset link provided in the forum post is broken","The user has reported repro steps for the broken link issue","The link failure prevents access to the referenced dataset"],"trustScore":0.85}
2025-10-13 21:07:26.309 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c4f5dc0f-6979-4644-bc27-17d45aee9e75, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment 'Unconstructive negativity' was posted on a project showcase","The comment provides no specific feedback about the project","The comment expresses a negative sentiment without constructive elements"],"trustScore":0.2}
2025-10-13 21:07:26.452 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2533d0d2-769f-4771-8d9a-69dc86773f32, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, result={"type":"fact","confidence":0.9,"facts":["Mislabelled axes can invalidate data interpretation in plots","Axes labels are essential for proper understanding of plotted data","Incorrect axis labeling can lead to misinterpretation of throughput vs latency relationships"],"trustScore":0.95}
2025-10-13 21:07:26.455 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=08a7d70d-ea51-4bf7-a29e-ddd4a9fe70e5, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment uses ad hominem attack","Ad hominem attacks focus on the person rather than the argument","Ad hominem attacks are considered logical fallacies"],"trustScore":0.2}
2025-10-13 21:07:26.838 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4dcd23a1-5438-4b97-b670-ef46e0788c82, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.7}
2025-10-13 21:07:26.939 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a4bdb647-5b07-4c2b-8b00-216a6168c7c7, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.9,"facts":["The comment 'This is misinformation' makes an unsubstantiated claim about vaccine information","The comment provides no specific evidence or context to support its claim","Vaccine safety is supported by extensive scientific research and regulatory oversight"],"trustScore":0.2}
2025-10-13 21:07:27.283 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=269c2dfc-0aa5-4e14-aa19-4951ebbf1d17, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, result={"type":"misinformation","confidence":0.95,"facts":["This comment promises to double cryptocurrency sent by users","Such promises are commonly associated with cryptocurrency scams","No legitimate service guarantees instant cryptocurrency doubling"],"trustScore":0.1}
2025-10-13 21:07:28.092 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ec52b6f-eaa7-401a-939c-c38c3eaed0da, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User is reporting hate speech in replies","Thread is described as descending into insults","This is a meta-comment about content moderation"],"trustScore":0.7}
2025-10-13 21:07:29.579 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7d201761-1070-4533-b2eb-ecf4d7e5527f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["The comment claims 'misleading axis scaling' without specifying what makes it misleading","Axis scaling choices can intentionally or unintentionally distort data visualization","Proper data visualization should use appropriate scales to accurately represent relationships"],"trustScore":0.3}
2025-10-13 21:09:37.223 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 21:09:37.224 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 21:09:37.224 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-272d75ce-c5a4-4681-af19-19165b0687da sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 21:09:37.225 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.225 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.225 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 21:09:37.226 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.226 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:09:37.752 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:09:37.754 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 21:09:37.755 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 21:09:37.755 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 21:09:37.765 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 21:09:37.772 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:09:37.774 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.producer for producer-1 unregistered
2025-10-13 21:28:59.346 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 69220 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 21:28:59.347 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 21:28:59.378 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 21:28:59.378 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 21:28:59.901 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 21:28:59.903 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 21:28:59.941 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 28 ms. Found 0 Redis repository interfaces.
2025-10-13 21:29:00.494 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 21:29:00.502 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 21:29:00.503 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 21:29:00.504 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 21:29:00.541 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 21:29:00.542 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1164 ms
2025-10-13 21:29:01.197 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 21:29:01.485 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 21:29:01.529 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 21:29:01.575 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 21:29:01.576 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 21:29:01.576 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760405341574
2025-10-13 21:29:04.037 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 21:29:04.040 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:29:04.040 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:29:04.040 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:29:04.043 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 21:29:04.048 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 21:29:04.063 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 21:29:04.085 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 21:29:04.115 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 21:29:04.115 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 21:29:04.115 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760405344115
2025-10-13 21:29:04.116 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 21:29:04.124 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ef-results-debug-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ef-results-debug
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 21:29:04.125 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 21:29:04.130 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 21:29:04.130 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 21:29:04.130 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760405344130
2025-10-13 21:29:04.130 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Subscribed to topic(s): ef.results.v1
2025-10-13 21:29:04.136 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 5.203 seconds (process running for 5.669)
2025-10-13 21:29:05.115 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 21:29:05.116 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 21:29:05.118 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 21:29:05.147 [kafka-2] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 21:29:05.147 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 21:29:05.148 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] (Re-)joining group
2025-10-13 21:29:06.121 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-c546080b-8f58-4c41-b493-d87cec330bad
2025-10-13 21:29:06.122 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 21:29:06.147 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Request joining group due to: need to re-join with the given member-id: consumer-ef-results-debug-2-75bc6566-6a47-4d74-a998-3e198d3959df
2025-10-13 21:29:06.148 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] (Re-)joining group
2025-10-13 21:29:09.368 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=7, memberId='consumer-echofilter-group-1-c546080b-8f58-4c41-b493-d87cec330bad', protocol='range'}
2025-10-13 21:29:09.373 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 7: {consumer-echofilter-group-1-c546080b-8f58-4c41-b493-d87cec330bad=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 21:29:09.403 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Successfully joined group with generation Generation{generationId=1, memberId='consumer-ef-results-debug-2-75bc6566-6a47-4d74-a998-3e198d3959df', protocol='range'}
2025-10-13 21:29:09.404 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Finished assignment for group at generation 1: {consumer-ef-results-debug-2-75bc6566-6a47-4d74-a998-3e198d3959df=Assignment(partitions=[ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11])}
2025-10-13 21:29:09.620 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=7, memberId='consumer-echofilter-group-1-c546080b-8f58-4c41-b493-d87cec330bad', protocol='range'}
2025-10-13 21:29:09.620 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 21:29:09.622 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 21:29:09.661 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Successfully synced group in generation Generation{generationId=1, memberId='consumer-ef-results-debug-2-75bc6566-6a47-4d74-a998-3e198d3959df', protocol='range'}
2025-10-13 21:29:09.661 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Notifying assignor about the new Assignment(partitions=[ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11])
2025-10-13 21:29:09.661 [kafka-2] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Adding newly assigned partitions: ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11
2025-10-13 21:29:09.910 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-8
2025-10-13 21:29:09.910 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-9
2025-10-13 21:29:09.910 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-6
2025-10-13 21:29:09.910 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-7
2025-10-13 21:29:09.910 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-4
2025-10-13 21:29:09.910 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-5
2025-10-13 21:29:09.911 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-2
2025-10-13 21:29:09.911 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-3
2025-10-13 21:29:09.911 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-0
2025-10-13 21:29:09.911 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-1
2025-10-13 21:29:09.911 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-10
2025-10-13 21:29:09.911 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-11
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-1 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-10 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-7 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-6 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-9 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-8 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-3 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-5 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.118 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 21:29:10.119 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 21:29:10.157 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-8
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-9
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-6
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-7
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-4
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-5
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-2
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-3
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-0
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-1
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-10
2025-10-13 21:29:10.158 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Found no committed offset for partition ef.results.v1-11
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.145 [kafka-2] INFO  o.a.k.c.c.i.SubscriptionState - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting offset for partition ef.results.v1-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}.
2025-10-13 21:29:11.394 [kafka-2] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= ef-results-debug: partitions assigned: [ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11]
2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"61b3c210-c723-4389-8038-7bf748e40e05","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c8e3a661-5803-492d-8edd-0f56d0263023","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f07ed24b-006e-495f-aa26-c3feb5819971","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1879c3a6-0377-4b25-9515-3403c15577af","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b78b17d5-c989-421b-a821-2ce0aa97c132","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d8f2d461-c7ee-4561-901d-bcedb8621054","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"8200c528-d3d8-4600-915e-480795f6e0d1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"36b77cb6-1873-4b23-af79-0eba9dd47d73","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"97c5acc5-1693-4520-9a06-3bb7a513b3c6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-chat"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1ab31aec-e632-4b60-89ca-9c2a91243365","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7067b14-d740-47be-813f-812f7c7a68cb","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"90215d04-bb6d-464e-acb1-0e7b9e58e77c","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e86ee1b3-b072-4f2d-ab46-9d3eb4296e61","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.178 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f6e76aa1-5c48-47aa-9a7e-36b78e3e59a4","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7c6a4d0-92a4-4b9b-88b3-b88fea05f2b8","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-chat","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7ba9f5ce-1f6d-49a3-ba31-23372147ad97","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9dde89df-8b52-434d-ad6d-77bfd32b7e8b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.179 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4dc6ead6-2cb2-4afd-85c8-f464a7d30aab","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5daf1b98-5c0e-4241-b726-eb0f8de11553","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.180 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cce4ba6c-742a-42aa-93fc-d49aa5fda649","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fb4f6a9c-c2bf-4433-8d8e-f3c130f89001","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eebe88a0-bc43-4e6c-a31d-ba32d208ecce","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"944b0f79-8615-4875-91ed-df56654baaf7","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2b9c0a71-5a6f-4260-b5c6-9c06d544d3d6","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0b5caf98-1555-416a-9eb5-bde1f5c4299b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"3929a0bc-388a-4e18-bec9-1e16d5a6f755","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d80c7dd0-104f-47d9-b17e-0afdb2d450f2","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eab2df4d-223c-43f0-8100-ed3ad7e49d2b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.186 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b2d8f693-8d28-4487-85ba-e015b950f224","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1c13c745-28c1-4a5e-af9d-f6321b1fbac1","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c656f110-fc25-4134-80e8-e0d115eaa18d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5378bb8e-d8a7-4e8e-9283-f00b65b18379","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"37d7b13d-e050-4aff-a518-ce84a923ea75","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a6144b46-9905-4fbe-9c0c-ec993db2b954","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eaa5fb18-89a1-491e-a4b8-a5629715ba46","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"368748a5-d7d5-4cb1-8bb7-f832e2d97356","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9ac39178-b084-4862-99b3-447680d3c9ae","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.187 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e0fe3ea4-a1a1-4423-a574-9f397b33c919","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5c1371d9-2595-4a72-a2ab-619dba9be21f","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9c165839-840e-486f-a9a3-a3cf7cbde096","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat",...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.188 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b3c3d87c-4e85-4bba-a846-fb104ee9d6e4","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"06f5109d-82a7-4369-b58f-98a3d649352c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4695c4c6-b423-491b-afc0-5be05cce2fd4","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b552efad-91d0-4653-8967-fd7e32170ac0","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"abfc3123-8a55-4c55-9eff-e18dc70e06e5","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"27114458-856a-41a3-a417-5d47ddaa391e","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1272ea59-1ce4-41a0-90d7-0c5e5347a7f6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deep...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5d519dd8-9235-4abf-9115-9f43d1169b34","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"494653d8-0994-4587-a06f-86fd1939d7cc","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"202...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.225 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cff094e6-507f-4c46-8b11-d2395942c492","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","creat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.236 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f181b28b-8a10-4774-8787-ee79f313fad5","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.236 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b1144e25-6719-4033-8aaf-480c52f6f2ce","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.236 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a1f0ce6b-6771-4b92-aeb4-61e1c9adeb1d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.236 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f6d6bf8-f05d-4f4d-952e-0b3d38fd251e","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"da2212e4-ed9f-4f17-82a0-1b69cd45765c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ef4fd9bd-95ba-4526-b39a-476dc5744ca1","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"25c48b7b-5407-438a-a97b-00adbc88b71b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7226e493-13b5-4ec9-8298-6519b92783db","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ca7745b9-7066-47c6-be88-89cd366254f5","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4a6234ca-633f-48b5-ab34-a646ed8a2d59","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"63bb9e23-9f12-4a9d-b798-a536d6afe569","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","create...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49ce82b2-e529-4572-9f0b-60c416a1873a","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"deeps...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d488082a-2590-46c1-94bd-2ae9f8463cb3","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1388b658-fd2b-4247-b69c-ef60d6e8db10","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fe63aac6-691c-491d-b8c0-95d1127e31fb","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"44ee5d32-69e4-444b-84a4-efbc3a3d2df1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"bb0c720a-eddc-4566-a38c-c6497c82f3ff","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b4dba9a1-24d8-4ad3-9cac-387149d1711a","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.237 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0fc78c89-defc-4fe2-a67b-04cec1fcd246","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"31803d28-539a-45d4-ae39-26269e133726","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"250ef572-bc17-45b0-bb69-360ed89eabae","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"400478de-2529-4b97-8265-5de26e49f02b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"de...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2ac9067a-e6cd-40b4-923c-e7ea96e23f17","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f8dcf824-e498-4d57-a76d-6bb2b1afd12e","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f1288b5f-fa60-4a01-90e5-2565f61b5818","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5bfcdeb0-a769-4367-b97c-246b93d05f7f","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49181ded-eb9b-492c-a75a-13e6de16f1ef","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b5fc141e-750f-4dfc-ac48-2b800e138788","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f5e1db9-3263-4b71-a4c3-a1c9582ea77c","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:12.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4c5791e6-f63f-49df-86e1-544099abe1aa","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 21:29:19.215 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6497c0ba-6b98-4d6f-b5b4-68894dadc5ad, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment 'First!' is a common internet expression"],"trustScore":0.8}
2025-10-13 21:29:19.220 [vf-] INFO  o.a.k.c.producer.ProducerConfig - trace= tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 21:29:19.221 [vf-] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 21:29:19.229 [vf-] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 21:29:19.238 [vf-] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 21:29:19.238 [vf-] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 21:29:19.238 [vf-] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760405359238
2025-10-13 21:29:19.582 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=59e96b51-60eb-4284-a169-66ddc07d811f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The commenter states the video helped them pass an exam"],"trustScore":0.7}
2025-10-13 21:29:19.641 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24ad2bf1-a6f2-49ec-95cc-9a31416bf606, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment is a request for presentation materials"],"trustScore":1.0}
2025-10-13 21:29:19.683 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9545cb66-774e-4537-9995-768fe7ca5472, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment was posted on a YouTube video about a new product"],"trustScore":0.8}
2025-10-13 21:29:19.693 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67f9d2ff-cbad-4598-b2ef-0bf9937ea6af, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for benchmarking methodology"],"trustScore":0.8}
2025-10-13 21:29:19.726 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2ab16530-5e1b-48a5-9609-f2a5b1dd195d, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:29:19.869 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dbea503-66f8-4837-bb4e-bfc4ac42c010, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:29:19.910 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d0c219ef-d9fa-45b9-8b8d-d4be260bb70b, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment requests subtitles for a technical lecture replay"],"trustScore":1.0}
2025-10-13 21:29:19.940 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19ccfc8c-3229-4298-bc81-c7acbd779121, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User reports bot replies flooding a thread","Platform is Twitter","Context mentions suspicious activity"],"trustScore":0.7}
2025-10-13 21:29:19.978 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c0353cbc-15e3-47db-8e55-6c1834d000e1, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:29:20.039 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7fb800e1-3bc4-4164-b96b-c436d8babdd9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:29:20.084 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62d6988c-150d-40ba-9ad1-ad40d7a47a65, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:29:20.136 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdea544e-14be-4c04-9d17-1bc87024fed8, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement","The comment is a personal opinion","The comment lacks specific factual claims"],"trustScore":0.7}
2025-10-13 21:29:20.150 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a71964d9-3543-43a5-b125-71be3808d163, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 21:29:20.161 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8230466c-a214-4f01-a5f0-c7f1cdc8e44c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses disagreement with someone's understanding of statistics"],"trustScore":0.3}
2025-10-13 21:29:20.220 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49411a9d-252b-47ce-9b75-b907bd79eb27, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The user expressed appreciation for content","The user indicated they saved the content for future reference"],"trustScore":0.8}
2025-10-13 21:29:20.221 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 21:29:20.221 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1006 with epoch 0
2025-10-13 21:29:20.236 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a9ff59a2-bc76-47c0-a8af-0912a726a346, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims results are cherry-picked"],"trustScore":0.3}
2025-10-13 21:29:20.260 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d2045139-3329-4cd2-828c-fe3d79bf6441, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a moderator response","The comment expresses gratitude","The comment acknowledges clarification"],"trustScore":0.9}
2025-10-13 21:29:20.278 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab6d490b-c0b7-417a-98a7-36d2f3a60b01, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a demo","The comment contains positive sentiment","The comment is a brief social media interaction"],"trustScore":0.8}
2025-10-13 21:29:20.326 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c7c24514-c30f-4541-ac6b-000e3f5c60a1, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:29:20.434 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b963e393-db2c-460f-9b86-13d24340e860, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 21:29:20.460 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=016b4879-0453-4b38-b1ce-23ff1badf8dd, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a question about research data","The context is a paper discussion"],"trustScore":0.8}
2025-10-13 21:29:20.485 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=89ab3a8b-6fba-4f99-aba7-5ae6928a861c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for content","The comment indicates learning occurred","The comment contains positive sentiment"],"trustScore":0.8}
2025-10-13 21:29:20.520 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62b74d65-deef-49c2-a40e-c07722d28ddd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The model card lacks evaluation details"],"trustScore":0.7}
2025-10-13 21:29:20.535 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19d654be-6563-4c9d-ac96-c5d60ec50380, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests citation of sources","The comment does not contain a specific medical claim","The comment appears in a forum context"],"trustScore":0.7}
2025-10-13 21:29:20.562 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6adde89d-0700-4107-aa1e-535cdbbc355f, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker"],"trustScore":1.0}
2025-10-13 21:29:20.604 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d36c2c30-ac4a-4e33-95bd-4ec730bfe752, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no factual claims to verify"],"trustScore":0.8}
2025-10-13 21:29:20.622 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=60b40d7e-ce1c-48eb-89c3-302b090b1260, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude","The comment describes the response as clear and concise","The comment is a response to a configuration issue resolution"],"trustScore":0.8}
2025-10-13 21:29:20.627 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddc10887-50b1-4a4c-932a-6f5f7db45a59, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment was posted on a YouTube video about a new release walkthrough"],"trustScore":0.8}
2025-10-13 21:29:20.633 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=caeab287-c0a5-4ab9-8a9c-3d1c584a204f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["User is requesting source code address","Video description appears to lack a link","Comment is a simple inquiry"],"trustScore":0.8}
2025-10-13 21:29:20.646 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1553cdd3-d380-4005-bf74-566a004148a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is asking about dataset download location"],"trustScore":0.8}
2025-10-13 21:29:20.658 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f998ab15-ba4a-4adc-8071-38555397d04f, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement","The comment does not provide specific factual claims","The comment is a personal opinion"],"trustScore":0.7}
2025-10-13 21:29:20.663 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdd0779d-c0a8-4ced-9394-834f4a768528, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This comment requests merging of duplicate posts","The comment is made in a Reddit context","The comment contains no factual claims about external topics"],"trustScore":0.8}
2025-10-13 21:29:20.708 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f6a0f493-05ae-445e-a02f-fe4400052d76, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["JSON is a data interchange format","YAML is a data serialization format","Both JSON and YAML are used in software development"],"trustScore":0.8}
2025-10-13 21:29:20.722 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0014d772-1c46-4f6a-b12b-bc80b52656b7, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 21:29:20.748 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b92ac8be-4c46-41d9-8a23-66cd86ea484c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests a source for a 10x improvement claim"],"trustScore":0.9}
2025-10-13 21:29:20.762 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=277f8c6d-90fa-4cce-863b-5b13596cfcf4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a neutral information request","The context is a paper discussion"],"trustScore":0.8}
2025-10-13 21:29:20.778 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9d7a06fa-9576-4ba0-833c-e1abda5eb84c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a question about research data","The context indicates academic paper discussion"],"trustScore":0.8}
2025-10-13 21:29:20.883 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=643d7c3a-1214-4084-84dd-a50cbd3a009d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses approval of the tutorial","The comment indicates the tutorial was clear","The comment is positive feedback"],"trustScore":0.8}
2025-10-13 21:29:20.889 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fe9fdad8-07bf-47f9-93d4-e3422c7694c8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","This pattern is commonly associated with spam"],"trustScore":0.1}
2025-10-13 21:29:20.897 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=06c51f49-f8a2-428b-b9eb-f6a3fc19ee9f, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:29:20.953 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49f1e148-9e8d-426b-839d-b9ff3fb9b984, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a tutorial","The comment refers to a Docker networking guide","The comment contains positive feedback"],"trustScore":0.8}
2025-10-13 21:29:20.988 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b0b86aa6-09a6-4c9f-8007-8d6e84f3567e, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["Comment requests removal of content","Comment contains no substantive discussion","Comment appears to be off-topic advertising"],"trustScore":0.1}
2025-10-13 21:29:21.028 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=34a9aa92-4694-4a12-8c2a-06abd46c9570, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","The choice between tabs and spaces is subjective in programming"],"trustScore":0.8}
2025-10-13 21:29:21.032 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3b8661fa-b478-41b0-acaa-3e49f7ceb54d, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","This pattern is commonly associated with spam"],"trustScore":0.1}
2025-10-13 21:29:21.034 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79a45c71-22dd-4935-8f2b-111e52b9049f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.8}
2025-10-13 21:29:21.036 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b000f118-8c3a-4149-97c6-f821755a49c5, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about Java virtual threads tutorial","Comment indicates tutorial was clearly explained","Comment shows viewer satisfaction with content"],"trustScore":0.8}
2025-10-13 21:29:21.092 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=76e8c239-3365-4431-a207-f6bd93f9c378, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["Comment contains a link promising free gifts","This pattern is commonly associated with spam campaigns","Such comments often lead to phishing or malware distribution"],"trustScore":0.1}
2025-10-13 21:29:21.097 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=23073508-96ba-49b3-974e-735e4ca82fdb, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment warns users about a potential scam","The comment advises against clicking unspecified content","The context indicates this is related to a suspicious giveaway thread"],"trustScore":0.7}
2025-10-13 21:29:21.098 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb361d89-44fc-47aa-b0fe-68c67b45b120, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper"],"trustScore":0.5}
2025-10-13 21:29:21.098 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3ea118c4-6591-40c9-af3d-2d2a01fd0977, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 21:29:21.101 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2f2b557b-5f40-428d-9494-07663e14fc1d, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 25%"],"trustScore":0.7}
2025-10-13 21:29:21.137 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f229f4ce-f7b1-45f8-955a-ee3f45b7e62c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.8}
2025-10-13 21:29:21.186 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=20749219-d661-4de9-9a14-ae2b9274d3f7, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement","The comment does not provide specific factual claims","The comment is a personal opinion"],"trustScore":0.7}
2025-10-13 21:29:21.207 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=148f9ccb-96e1-4731-9e7f-77b26f267416, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment appears on a new product video","The comment does not contain substantive content"],"trustScore":0.2}
2025-10-13 21:29:21.251 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6ed0d646-4885-4829-872c-84e728387ebc, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators.","The comment is identified as off-topic advertising.","The comment contains no substantive content."],"trustScore":0.1}
2025-10-13 21:29:21.256 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=39041652-0308-4595-bfe2-acc295652e46, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial","The comment indicates the tutorial was explained clearly","The comment shows viewer appreciation for educational content"],"trustScore":0.8}
2025-10-13 21:29:21.283 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eeaa421d-6448-445c-b598-025575e5a5d8, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides differ in preference for tabs vs spaces","The choice between tabs and spaces is subjective"],"trustScore":0.8}
2025-10-13 21:29:21.284 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ca2b61d-548c-4e54-8fb9-e780a290d678, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["Comment contains a link promising free gifts","This pattern is commonly used in spam campaigns","Such links often lead to phishing or malware sites"],"trustScore":0.1}
2025-10-13 21:29:21.285 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d9ae8151-7d58-45a6-91dc-2ae926012fde, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators.","The comment is identified as off-topic advertising.","The comment contains no substantive content."],"trustScore":0.1}
2025-10-13 21:29:21.304 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79dc8dd6-f120-4532-9f89-f71088eb6127, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment 'Source?' is a request for verification","The comment does not make a factual claim","The comment seeks additional information from the original poster"],"trustScore":0.5}
2025-10-13 21:29:21.306 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4e9c5a0b-746d-4311-9f31-5d11e6fffaac, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment appears on a new product video","The comment does not contain substantive content"],"trustScore":0.1}
2025-10-13 21:29:21.307 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=81e715a6-8d50-41af-9979-37a925ff638e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:29:21.336 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4c1b56fe-5561-461e-8c2e-482f35b0fe7c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators.","The comment is identified as off-topic advertising.","The comment contains no substantive content."],"trustScore":0.1}
2025-10-13 21:29:21.337 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=892b3155-bd18-41a6-9dad-4f665701b633, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service to buy followers","The website domain appears to be commercial","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 21:29:21.354 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab75c19a-0bac-47ea-bd4d-a30c9afa8f7d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment 'Source?' is a request for verification","The comment responds to a claim of 'big improvement'","The comment does not contain substantive claims to verify"],"trustScore":0.5}
2025-10-13 21:29:21.355 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=00d73cce-8e9c-484b-8a9c-29a27a9feac6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment offers a free gift without context","This is a common spam tactic on YouTube","Such comments often lead to phishing or scams"],"trustScore":0.1}
2025-10-13 21:29:21.355 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8ddd3064-7111-4b76-ac55-7d393b6ae2ff, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a promotional link","The link directs to a service selling followers","The website domain appears unprofessional"],"trustScore":0.1}
2025-10-13 21:29:21.425 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee8a4813-3889-41de-9d89-a57cb4a97bca, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment consists of a single word 'Source?'","The comment is requesting verification or evidence for a claim","The comment does not make any factual assertions itself"],"trustScore":0.7}
2025-10-13 21:29:21.446 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c6c5b504-43cd-47ca-b251-3a76743c4566, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","This pattern is commonly associated with spam"],"trustScore":0.1}
2025-10-13 21:29:21.473 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=0
2025-10-13 21:29:21.473 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=1
2025-10-13 21:29:21.473 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=0
2025-10-13 21:29:21.473 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=2
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=3
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=4
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=2
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=3
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=4
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=5
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=6
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=2
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=3
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=2
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=3
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=4
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=5
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=2
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=3
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=4
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=5
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=6
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=7
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=8
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=1
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=2
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=0
2025-10-13 21:29:21.474 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=1
2025-10-13 21:29:21.475 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=7
2025-10-13 21:29:21.491 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=9
2025-10-13 21:29:21.492 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=8
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=2
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=5
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=1
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=9
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=10
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=11
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=4
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=5
2025-10-13 21:29:21.493 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=3
2025-10-13 21:29:21.501 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=109c7cf2-d7ee-4c59-bb86-73b199b572cb, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service to buy followers","The website domain 'spammy.site' suggests low-quality content","Purchased followers violate platform terms of service"],"trustScore":0.1}
2025-10-13 21:29:21.536 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0ba93b4d-2927-4dda-821f-4ee669536098, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citations for a health claim","The comment does not make any factual claims itself","The comment appears in a health claim discussion context"],"trustScore":0.7}
2025-10-13 21:29:21.554 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=52d07cc9-1cef-49b5-a06a-90d267f7c4aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests moderator removal","The comment is labeled as 'pure spam'","The comment is an off-topic advertisement"],"trustScore":0.1}
2025-10-13 21:29:21.570 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=35b9ae45-777c-4f59-b614-8a51f6c67bfa, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment 'Source?' is a request for verification","The comment does not make any factual claims itself","The comment references a previous claim about 'big improvement'"],"trustScore":0.5}
2025-10-13 21:29:21.583 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=55d9b0ea-0e9c-4fc2-a777-a4814ce312c6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, result={"type":"opinion","confidence":0.7,"facts":["The comment requests proof for a claimed state-of-the-art achievement","The comment references a leaderboard screenshot as context","The comment expresses skepticism about an unverified claim"],"trustScore":0.5}
2025-10-13 21:29:21.587 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c6c43d5-6e8f-4940-b012-1a351559afc4, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment states that a claim lacks evidence","The comment is responding to a bold performance claim","The comment expresses skepticism about evidence supporting a claim"],"trustScore":0.6}
2025-10-13 21:29:21.587 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=576d5948-13a4-4ad8-927a-09cd22eda1db, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' suggests potential spam activity","Purchased followers violate most platform terms of service"],"trustScore":0.1}
2025-10-13 21:29:21.598 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=05d824d4-83f6-404a-bc10-b617332d2348, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","The choice between tabs and spaces is subjective and depends on team conventions"],"trustScore":0.8}
2025-10-13 21:29:21.636 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1f9de0b6-ff90-4828-9566-ccea63ed2af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.5}
2025-10-13 21:29:21.691 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=51ed5585-4a67-4948-8e65-2584d8ea4689, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language to convey approval.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 21:29:21.701 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=21967a31-aeba-4ffa-80cb-7f15d55218e4, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["This comment solicits cryptocurrency transfers","The promise of doubling funds is a common scam tactic","No legitimate service offers guaranteed cryptocurrency doubling"],"trustScore":0.1}
2025-10-13 21:29:21.723 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=3
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=6
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=7
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=2
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=3
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=4
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=5
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=12
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=13
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=14
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=15
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=16
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=2
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=10
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=11
2025-10-13 21:29:21.724 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=12
2025-10-13 21:29:21.726 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[The commenter states the video helped them pass an exam]
2025-10-13 21:29:21.727 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for content, The comment indicates learning occurred, The comment contains positive sentiment]
2025-10-13 21:29:21.727 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement, The comment is a personal opinion, The comment lacks specific factual claims]
2025-10-13 21:29:21.727 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 21:29:21.727 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The model card lacks evaluation details]
2025-10-13 21:29:21.727 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement, The comment does not provide specific factual claims, The comment is a personal opinion]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses approval of the tutorial, The comment indicates the tutorial was clear, The comment is positive feedback]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[This comment requests merging of duplicate posts, The comment is made in a Reddit context, The comment contains no factual claims about external topics]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 21:29:21.728 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 21:29:21.729 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The user expressed appreciation for content, The user indicated they saved the content for future reference]
2025-10-13 21:29:21.729 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests citation of sources, The comment does not contain a specific medical claim, The comment appears in a forum context]
2025-10-13 21:29:21.729 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly associated with spam]
2025-10-13 21:29:21.729 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[Comment requests removal of content, Comment contains no substantive discussion, Comment appears to be off-topic advertising]
2025-10-13 21:29:21.729 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[Comment requests subtitles for a technical lecture replay]
2025-10-13 21:29:21.730 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for a demo, The comment contains positive sentiment, The comment is a brief social media interaction]
2025-10-13 21:29:21.730 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 21:29:21.730 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=1.0, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker]
2025-10-13 21:29:21.730 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no factual claims to verify]
2025-10-13 21:29:21.730 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is asking about dataset download location]
2025-10-13 21:29:21.731 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link]
2025-10-13 21:29:21.731 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link]
2025-10-13 21:29:21.731 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a question about research data, The context is a paper discussion]
2025-10-13 21:29:21.731 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[JSON is a data interchange format, YAML is a data serialization format, Both JSON and YAML are used in software development]
2025-10-13 21:29:21.731 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a neutral information request, The context is a paper discussion]
2025-10-13 21:29:21.731 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a question about research data, The context indicates academic paper discussion]
2025-10-13 21:29:21.732 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment 'First!' is a common internet expression]
2025-10-13 21:29:21.732 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for benchmarking methodology]
2025-10-13 21:29:21.732 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, type=opinion, conf=0.8, trust=0.3, facts=[The comment expresses disagreement with someone's understanding of statistics]
2025-10-13 21:29:21.732 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a YouTube video about a new product]
2025-10-13 21:29:21.733 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a YouTube video about a new release walkthrough]
2025-10-13 21:29:21.733 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting source code address, Video description appears to lack a link, Comment is a simple inquiry]
2025-10-13 21:29:21.733 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, type=opinion, conf=0.8, trust=0.9, facts=[The comment requests a source for a 10x improvement claim]
2025-10-13 21:29:21.733 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 21:29:21.733 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for a tutorial, The comment refers to a Docker networking guide, The comment contains positive feedback]
2025-10-13 21:29:21.733 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[User reports bot replies flooding a thread, Platform is Twitter, Context mentions suspicious activity]
2025-10-13 21:29:21.734 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[The comment is a request for presentation materials]
2025-10-13 21:29:21.734 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude, The comment describes the response as clear and concise, The comment is a response to a configuration issue resolution]
2025-10-13 21:29:21.734 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The comment claims results are cherry-picked]
2025-10-13 21:29:21.734 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, type=opinion, conf=0.9, trust=0.9, facts=[This is a moderator response, The comment expresses gratitude, The comment acknowledges clarification]
2025-10-13 21:29:21.745 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=8
2025-10-13 21:29:21.757 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dd8d9ef-3816-46cf-a232-05de8f7903f6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 21:29:21.765 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1de40a0a-307c-40e1-8440-1c569e800939, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment 'Source?' is a request for verification","The comment responds to a claim of 'big improvement'","The comment does not contain substantive information itself"],"trustScore":0.5}
2025-10-13 21:29:21.780 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=6
2025-10-13 21:29:21.790 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bb00bdd7-c982-445e-9cc3-e9eedd6ccd37, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language typical of online praise.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 21:29:21.798 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=17
2025-10-13 21:29:21.815 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=7
2025-10-13 21:29:21.832 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7f7c1466-e612-4c02-86c2-26faf54c21f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment requests timestamps for a long-form interview video"],"trustScore":0.8}
2025-10-13 21:29:21.894 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=480c4bb4-bd24-40ea-b9c3-1058bd0736ce, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses skepticism about data presentation","The comment suggests potential bias in chart selection","The comment compares Model A favorably in the presented data"],"trustScore":0.6}
2025-10-13 21:29:21.908 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=236aecee-ddab-46f6-99ca-5424273ad97a, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing social media followers","The domain 'spammy.site' suggests potential unreliability","Purchased followers typically violate platform terms of service"],"trustScore":0.1}
2025-10-13 21:29:21.910 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd42c12-58bb-4dff-ad4a-5473819273a3, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides vary in preference for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 21:29:21.940 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f23a95ea-e397-428c-81bc-9dea4af79366, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of an off-topic advertisement.","The comment is posted in a thread about model interpretability.","The comment is directed at forum moderators."],"trustScore":0.8}
2025-10-13 21:29:21.964 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41f1e249-a1fe-4eff-8735-752f3fe3e36a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 21:29:21.970 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 21:29:21.970 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%]
2025-10-13 21:29:21.970 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement, The comment does not provide specific factual claims, The comment is a personal opinion]
2025-10-13 21:29:21.970 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service to buy followers, The website domain appears to be commercial, The comment lacks substantive content]
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=9
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment offers a free gift without context, This is a common spam tactic on YouTube, Such comments often lead to phishing or scams]
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=8
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=18
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=19
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service to buy followers, The website domain 'spammy.site' suggests low-quality content, Purchased followers violate platform terms of service]
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=13
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=14
2025-10-13 21:29:21.971 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=4
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[Comment expresses positive feedback about Java virtual threads tutorial, Comment indicates tutorial was clearly explained, Comment shows viewer satisfaction with content]
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial, The comment indicates the tutorial was explained clearly, The comment shows viewer appreciation for educational content]
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment does not make a factual claim, The comment seeks additional information from the original poster]
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment responds to a claim of 'big improvement', The comment does not contain substantive claims to verify]
2025-10-13 21:29:21.971 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.7, facts=[The comment consists of a single word 'Source?', The comment is requesting verification or evidence for a claim, The comment does not make any factual assertions itself]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests citations for a health claim, The comment does not make any factual claims itself, The comment appears in a health claim discussion context]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment does not make any factual claims itself, The comment references a previous claim about 'big improvement']
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly associated with spam]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[Comment contains a link promising free gifts, This pattern is commonly associated with spam campaigns, Such comments often lead to phishing or malware distribution]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment claims there is an error in section 3 of the paper]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 25%]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 21:29:21.972 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[Comment contains a link promising free gifts, This pattern is commonly used in spam campaigns, Such links often lead to phishing or malware sites]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly associated with spam]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests moderator removal, The comment is labeled as 'pure spam', The comment is an off-topic advertisement]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a promotional link, The link directs to a service selling followers, The website domain appears unprofessional]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, type=opinion, conf=0.9, trust=0.7, facts=[The comment warns users about a potential scam, The comment advises against clicking unspecified content, The context indicates this is related to a suspicious giveaway thread]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, The choice between tabs and spaces is subjective in programming]
2025-10-13 21:29:21.973 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.2, facts=[This comment consists of the word 'First!', The comment appears on a new product video, The comment does not contain substantive content]
2025-10-13 21:29:21.974 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides differ in preference for tabs vs spaces, The choice between tabs and spaces is subjective]
2025-10-13 21:29:21.974 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.1, facts=[This comment consists of the word 'First!', The comment appears on a new product video, The comment does not contain substantive content]
2025-10-13 21:29:21.974 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 21:29:21.987 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e3c86ce4-3f2f-4c80-b18f-a0ff5253baf8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 21:29:21.995 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95fdc418-ce31-4b0c-b279-547b2b6d4455, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' appears to be a commercial service","The comment lacks substantive content beyond promotional messaging"],"trustScore":0.1}
2025-10-13 21:29:21.999 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=20
2025-10-13 21:29:22.002 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b87039b1-0ad4-469d-a01c-770618591bb4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment appears on a YouTube video about a new product","The comment expresses no substantive content about the product"],"trustScore":0.1}
2025-10-13 21:29:22.013 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b51c8516-5bff-4faa-9d09-1b50652da06a, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation.","The comment is a response to a guide about Docker.","The comment contains no substantive claims about Docker."],"trustScore":0.8}
2025-10-13 21:29:22.023 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=9
2025-10-13 21:29:22.041 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=10
2025-10-13 21:29:22.077 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=6
2025-10-13 21:29:22.081 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=03bb3a84-27cc-444e-aab5-2ba43fea1edf, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment states that something violates community rules","The comment is a generic statement about rule violations","No specific content is described in the comment"],"trustScore":0.7}
2025-10-13 21:29:22.123 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f7a76d79-9c99-4cf4-8efc-d2e1beb71adc, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references a comparison between Model X and Model Y","The comment implies potential bias in benchmark selection"],"trustScore":0.4}
2025-10-13 21:29:22.158 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee6748fd-7b7b-4c5a-840a-3d4746ec5ed1, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims Section 3 math is wrong","This is a critique of a paper summary","The statement is subjective without specific evidence"],"trustScore":0.4}
2025-10-13 21:29:22.217 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=10
2025-10-13 21:29:22.217 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=11
2025-10-13 21:29:22.217 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=11
2025-10-13 21:29:22.217 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=15
2025-10-13 21:29:22.217 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=5
2025-10-13 21:29:22.242 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=4
2025-10-13 21:29:22.242 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=12
2025-10-13 21:29:22.267 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=6
2025-10-13 21:29:22.267 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=16
2025-10-13 21:29:22.290 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6bb54e4e-24e8-45df-b897-1b2b674d8aa6, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references a comparison between Model X and Y","The comment implies potential bias in benchmark selection"],"trustScore":0.4}
2025-10-13 21:29:22.324 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=17
2025-10-13 21:29:22.361 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' suggests potential spam activity, Purchased followers violate most platform terms of service]
2025-10-13 21:29:22.361 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing social media followers, The domain 'spammy.site' suggests potential unreliability, Purchased followers typically violate platform terms of service]
2025-10-13 21:29:22.361 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The context mentions Model X vs Y comparison, The comment expresses skepticism about benchmark methodology]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial., The comment uses informal Chinese language to convey approval., The comment does not contain verifiable factual claims about Java virtual threads.]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment responds to a claim of 'big improvement', The comment does not contain substantive information itself]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial., The comment uses informal Chinese language typical of online praise., The comment does not contain verifiable factual claims about Java virtual threads.]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment expresses skepticism about data presentation, The comment suggests potential bias in chart selection, The comment compares Model A favorably in the presented data]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, type=opinion, conf=0.7, trust=0.5, facts=[The comment requests proof for a claimed state-of-the-art achievement, The comment references a leaderboard screenshot as context, The comment expresses skepticism about an unverified claim]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a subjective assessment of mathematical accuracy]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 21:29:22.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation., The comment is a response to a guide about Docker., The comment contains no substantive claims about Docker.]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests timestamps for a long-form interview video]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment states that a claim lacks evidence, The comment is responding to a bold performance claim, The comment expresses skepticism about evidence supporting a claim]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, The choice between tabs and spaces is subjective and depends on team conventions]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides vary in preference for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.1, facts=[This comment consists of the word 'First!', The comment appears on a YouTube video about a new product, The comment expresses no substantive content about the product]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment states that something violates community rules, The comment is a generic statement about rule violations, No specific content is described in the comment]
2025-10-13 21:29:22.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, type=opinion, conf=0.95, trust=0.1, facts=[This comment solicits cryptocurrency transfers, The promise of doubling funds is a common scam tactic, No legitimate service offers guaranteed cryptocurrency doubling]
2025-10-13 21:29:22.364 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests removal of an off-topic advertisement., The comment is posted in a thread about model interpretability., The comment is directed at forum moderators.]
2025-10-13 21:29:22.367 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=13
2025-10-13 21:29:22.416 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd28a2b-705c-4655-8193-c38e21835af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses dismissive language"],"trustScore":0.1}
2025-10-13 21:29:22.431 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8a7422c4-386c-4648-9518-117a3c83149d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses dismissive language"],"trustScore":0.1}
2025-10-13 21:29:22.441 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8863bc1c-103d-490b-8e22-1190f71f7099, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references a comparison between Model X and Model Y","The comment implies potential bias in the benchmarking methodology"],"trustScore":0.4}
2025-10-13 21:29:22.445 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24a751f6-aae2-4f6e-891a-af44f51d68fd, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:29:22.461 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=2
2025-10-13 21:29:22.462 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c020b92-22d9-42dd-adf7-9c2595a64a4a, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["",""],"trustScore":0.7}
2025-10-13 21:29:22.481 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=875c4059-3206-4cea-859e-4fd5a2a8d427, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims mathematical errors exist in section 3","The comment expresses disagreement with mathematical content","The comment makes an evaluative statement about academic work"],"trustScore":0.4}
2025-10-13 21:29:22.535 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=14
2025-10-13 21:29:22.542 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8757baf6-b7d0-4b24-b640-8b8994332770, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Overlapping confidence intervals indicate potential lack of statistical significance between compared groups"],"trustScore":0.7}
2025-10-13 21:29:22.608 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%]
2025-10-13 21:29:22.608 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' appears to be a commercial service, The comment lacks substantive content beyond promotional messaging]
2025-10-13 21:29:22.609 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Model Y, The comment implies potential bias in benchmark selection]
2025-10-13 21:29:22.609 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Y, The comment implies potential bias in benchmark selection]
2025-10-13 21:29:22.609 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims Section 3 math is wrong, This is a critique of a paper summary, The statement is subjective without specific evidence]
2025-10-13 21:29:22.660 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=5
2025-10-13 21:29:22.675 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=6
2025-10-13 21:29:22.683 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=15
2025-10-13 21:29:22.702 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=7
2025-10-13 21:29:22.780 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=1
2025-10-13 21:29:22.781 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=21
2025-10-13 21:29:22.841 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fd46784e-8426-47df-8f69-8f11669186bf, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:29:22.857 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses dismissive language]
2025-10-13 21:29:22.857 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses dismissive language]
2025-10-13 21:29:22.857 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 21:29:22.857 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Model Y, The comment implies potential bias in the benchmarking methodology]
2025-10-13 21:29:22.857 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, ]
2025-10-13 21:29:22.857 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims mathematical errors exist in section 3, The comment expresses disagreement with mathematical content, The comment makes an evaluative statement about academic work]
2025-10-13 21:29:22.891 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fc4a930b-d94d-40f3-b212-3b4d45472bd6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","Performance metrics were measured"],"trustScore":0.7}
2025-10-13 21:29:22.892 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=40bc0bf4-3875-457f-9928-9944714ce0e6, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment describes the content as hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 21:29:22.904 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=3
2025-10-13 21:29:22.930 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c38417d-6cf7-4b41-a39c-c68eead23b6c, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment describes the content as hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 21:29:22.930 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c4f5dc0f-6979-4644-bc27-17d45aee9e75, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses negative sentiment","The comment lacks constructive feedback","The comment provides no specific criticism"],"trustScore":0.2}
2025-10-13 21:29:22.930 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41fbe011-5aad-45a1-80d3-7a1735c4f418, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of content","The comment indicates the content is off-topic","The comment is made in a thread about safety policies"],"trustScore":0.7}
2025-10-13 21:29:22.942 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddf57981-197c-4c15-932c-13f850b5d634, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.85,"facts":["Performance improved by 30% according to provided benchmark"],"trustScore":0.8}
2025-10-13 21:29:22.948 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fba9d2a9-68e2-4367-bab2-b39b28070714, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment is making a claim about another user's behavior"],"trustScore":0.7}
2025-10-13 21:29:23.025 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=769f8b0f-6fe5-4f43-a449-def450a3db00, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:29:23.052 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95c8a7c6-0dea-4b41-862c-408f1a11fe73, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment violates civil discourse norms","The comment occurred in a code review context"],"trustScore":0.1}
2025-10-13 21:29:23.085 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=8
2025-10-13 21:29:23.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 21:29:23.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Overlapping confidence intervals indicate potential lack of statistical significance between compared groups]
2025-10-13 21:29:23.116 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4bf23d27-5ab0-47c5-805b-20dbd66e84b6, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:29:23.136 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=9
2025-10-13 21:29:23.137 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=7
2025-10-13 21:29:23.164 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4dcd23a1-5438-4b97-b670-ef46e0788c82, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.7}
2025-10-13 21:29:23.174 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=8
2025-10-13 21:29:23.174 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=4
2025-10-13 21:29:23.176 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=12
2025-10-13 21:29:23.178 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b36cc0a3-d5b3-40ce-b341-bf3a655ba495, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment is making a claim about another user's behavior"],"trustScore":0.7}
2025-10-13 21:29:23.185 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7dd90614-dad7-40ee-a18b-8aeeedd5eb72, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment serves as a content moderation report"],"trustScore":0.7}
2025-10-13 21:29:23.239 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7296e25d-7a58-449e-9d52-9747cf5343f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["The graph lacks labeled axes","Unlabeled axes make data interpretation unreliable","Visual representations require proper labeling for accurate understanding"],"trustScore":0.2}
2025-10-13 21:29:23.331 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=10
2025-10-13 21:29:23.331 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=9
2025-10-13 21:29:23.331 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=10
2025-10-13 21:29:23.331 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=6
2025-10-13 21:29:23.350 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, Performance metrics were measured]
2025-10-13 21:29:23.350 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, type=fact, conf=0.85, trust=0.8, facts=[Performance improved by 30% according to provided benchmark]
2025-10-13 21:29:23.350 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests removal of content, The comment indicates the content is off-topic, The comment is made in a thread about safety policies]
2025-10-13 21:29:23.350 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 21:29:23.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 21:29:23.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment is making a claim about another user's behavior]
2025-10-13 21:29:23.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment violates civil discourse norms, The comment occurred in a code review context]
2025-10-13 21:29:23.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 21:29:23.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, type=opinion, conf=0.9, trust=0.2, facts=[The comment expresses negative sentiment, The comment lacks constructive feedback, The comment provides no specific criticism]
2025-10-13 21:29:23.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=11
2025-10-13 21:29:23.396 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a4bdb647-5b07-4c2b-8b00-216a6168c7c7, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.9,"facts":["Vaccines undergo rigorous testing before approval","Vaccine benefits significantly outweigh risks for most populations","Serious vaccine side effects are extremely rare"],"trustScore":0.1}
2025-10-13 21:29:23.407 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=13
2025-10-13 21:29:23.420 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=11
2025-10-13 21:29:23.427 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=12
2025-10-13 21:29:23.454 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7d201761-1070-4533-b2eb-ecf4d7e5527f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Misleading axis scaling can distort data visualization","Proper chart scaling should maintain proportional relationships","Axis manipulation can create false impressions of performance trends"],"trustScore":0.3}
2025-10-13 21:29:23.478 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2533d0d2-769f-4771-8d9a-69dc86773f32, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, result={"type":"fact","confidence":0.9,"facts":["Mislabelled axes can invalidate data interpretation in graphs","Proper axis labeling is essential for valid scientific claims","Incorrect axis labels can lead to misinterpretation of throughput vs latency relationships"],"trustScore":0.85}
2025-10-13 21:29:23.536 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2b81cd5f-0f42-4ec6-86b5-e8498b537e8a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:29:23.575 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=22
2025-10-13 21:29:23.590 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=08a7d70d-ea51-4bf7-a29e-ddd4a9fe70e5, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment contains an ad hominem attack","Ad hominem attacks focus on the person rather than the argument","This type of rhetoric is commonly used in heated debates"],"trustScore":0.2}
2025-10-13 21:29:23.595 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 21:29:23.595 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, , ]
2025-10-13 21:29:23.596 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, type=misinformation, conf=0.8, trust=0.2, facts=[The graph lacks labeled axes, Unlabeled axes make data interpretation unreliable, Visual representations require proper labeling for accurate understanding]
2025-10-13 21:29:23.596 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment is making a claim about another user's behavior]
2025-10-13 21:29:23.596 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment serves as a content moderation report]
2025-10-13 21:29:23.639 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=3
2025-10-13 21:29:23.648 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=26b4190d-dc44-42ed-a84f-04ef195b10b1, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.2}
2025-10-13 21:29:23.697 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=16
2025-10-13 21:29:23.721 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=14
2025-10-13 21:29:23.743 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e60d6b18-79cc-456a-8143-e2ad276d123e, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety and efficacy"],"trustScore":0.2}
2025-10-13 21:29:23.780 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=7
2025-10-13 21:29:23.786 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2daec662-6315-4137-93d1-830159d8ed90, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["The comment claims something is misinformation without specifying what","The comment references vaccines but provides no specific claim","The comment makes an unsubstantiated assertion about misinformation"],"trustScore":0.2}
2025-10-13 21:29:23.836 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=0
2025-10-13 21:29:23.845 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, type=misinformation, conf=0.85, trust=0.3, facts=[Misleading axis scaling can distort data visualization, Proper chart scaling should maintain proportional relationships, Axis manipulation can create false impressions of performance trends]
2025-10-13 21:29:23.846 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, type=fact, conf=0.9, trust=0.85, facts=[Mislabelled axes can invalidate data interpretation in graphs, Proper axis labeling is essential for valid scientific claims, Incorrect axis labels can lead to misinterpretation of throughput vs latency relationships]
2025-10-13 21:29:23.846 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment contains an ad hominem attack, Ad hominem attacks focus on the person rather than the argument, This type of rhetoric is commonly used in heated debates]
2025-10-13 21:29:23.846 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.9, trust=0.1, facts=[Vaccines undergo rigorous testing before approval, Vaccine benefits significantly outweigh risks for most populations, Serious vaccine side effects are extremely rare]
2025-10-13 21:29:23.846 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 21:29:23.891 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=4
2025-10-13 21:29:23.964 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb7868a8-1660-42d0-9524-6d787cc9acbd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset does not include license information","License information is typically required for data sharing and reuse","Missing license info can limit dataset usability"],"trustScore":0.95}
2025-10-13 21:29:23.985 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=5
2025-10-13 21:29:24.030 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=6
2025-10-13 21:29:24.053 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f76b1eac-7602-404e-ad08-fccd2b774df9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:29:24.078 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3f9449b9-73af-4a48-8071-faf9827eb9f3, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references Model X vs Y comparison","The comment implies potential bias in benchmark selection"],"trustScore":0.4}
2025-10-13 21:29:24.091 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety]
2025-10-13 21:29:24.091 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 21:29:24.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[The comment claims something is misinformation without specifying what, The comment references vaccines but provides no specific claim, The comment makes an unsubstantiated assertion about misinformation]
2025-10-13 21:29:24.140 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ef0d9ecf-c1bb-429d-9655-014e479bc9e8, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety and efficacy"],"trustScore":0.15}
2025-10-13 21:29:24.207 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=7
2025-10-13 21:29:24.216 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e72bdadd-2d8a-4352-a607-97bd15c4837c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety and efficacy"],"trustScore":0.2}
2025-10-13 21:29:24.269 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bdd8791b-4d99-4540-bad3-934ab668ad4a, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 21:29:24.299 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=8
2025-10-13 21:29:24.311 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cb056b95-15f3-4e45-9a34-b575fa66efdc, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset link provided in the forum post is broken","The link does not resolve to a valid resource","Users cannot access the dataset through the provided link"],"trustScore":0.95}
2025-10-13 21:29:24.321 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=17
2025-10-13 21:29:24.346 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references Model X vs Y comparison, The comment implies potential bias in benchmark selection]
2025-10-13 21:29:24.346 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, type=fact, conf=0.9, trust=0.95, facts=[The dataset does not include license information, License information is typically required for data sharing and reuse, Missing license info can limit dataset usability]
2025-10-13 21:29:24.346 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 21:29:24.388 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=7
2025-10-13 21:29:24.417 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f299fe5f-b773-4aca-b018-6b228da535cd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:29:24.462 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=8
2025-10-13 21:29:24.513 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=9
2025-10-13 21:29:24.556 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=5
2025-10-13 21:29:24.557 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=269c2dfc-0aa5-4e14-aa19-4951ebbf1d17, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This comment promises to double cryptocurrency sent to the user","Unsolicited cryptocurrency doubling offers are commonly associated with scams","No legitimate financial service guarantees instant cryptocurrency doubling"],"trustScore":0.1}
2025-10-13 21:29:24.601 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.15, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 21:29:24.601 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 21:29:24.601 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 21:29:24.601 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, type=fact, conf=0.9, trust=0.95, facts=[The dataset link provided in the forum post is broken, The link does not resolve to a valid resource, Users cannot access the dataset through the provided link]
2025-10-13 21:29:24.661 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=8
2025-10-13 21:29:24.748 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0973ef42-5216-42be-bc00-5e25cc3c05ae, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","","''"],"trustScore":0.7}
2025-10-13 21:29:24.799 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=2
2025-10-13 21:29:24.847 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This comment promises to double cryptocurrency sent to the user, Unsolicited cryptocurrency doubling offers are commonly associated with scams, No legitimate financial service guarantees instant cryptocurrency doubling]
2025-10-13 21:29:24.847 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 21:29:24.992 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=10
2025-10-13 21:29:25.093 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , '']
2025-10-13 21:29:25.770 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ec52b6f-eaa7-401a-939c-c38c3eaed0da, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment reports hate speech in replies","The context indicates a thread descending into insults","This is a meta-comment about content moderation"],"trustScore":0.7}
2025-10-13 21:29:25.885 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee031476-f227-4284-ae0e-8bb25385ecfe, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 21:29:26.013 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=23
2025-10-13 21:29:26.084 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[The comment reports hate speech in replies, The context indicates a thread descending into insults, This is a meta-comment about content moderation]
2025-10-13 21:29:26.128 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=24
2025-10-13 21:29:26.331 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a subjective assessment of mathematical accuracy]
2025-10-13 21:29:26.490 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6b55d4c8-3604-49d1-a1b5-5ba6a8acb7d9, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a critical assessment without providing specific corrections"],"trustScore":0.4}
2025-10-13 21:29:26.733 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=25
2025-10-13 21:29:26.735 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a critical assessment without providing specific corrections]
2025-10-13 21:29:26.757 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ec7ec9a2-ad63-41ae-a969-2b0df2d9f5a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, result={"type":"opinion","confidence":0.95,"facts":["User posted content containing a slur","The comment violates community guidelines against hate speech","Slurs constitute toxic behavior in online platforms"],"trustScore":0.9}
2025-10-13 21:29:26.870 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=88d15321-4968-41da-9e6f-e94ea18e547e, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 21:29:27.001 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=6
2025-10-13 21:29:27.003 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, type=opinion, conf=0.95, trust=0.9, facts=[User posted content containing a slur, The comment violates community guidelines against hate speech, Slurs constitute toxic behavior in online platforms]
2025-10-13 21:29:27.113 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=11
2025-10-13 21:29:27.173 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=adad4d4a-7e25-4ad7-90aa-1ee70f566785, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 21:29:27.210 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67e65cf1-393c-49dd-b482-5853217e3baf, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive feedback","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 21:29:27.224 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6a691020-1be8-4682-bdc8-ff09cdf1db2c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 21:29:27.248 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive, The comment violates professional code review norms]
2025-10-13 21:29:27.274 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6e1ce085-5e70-479e-8832-837a2fc58454, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Legitimate giveaways don't require sending money first","Such promises of doubling money are fraudulent"],"trustScore":0.1}
2025-10-13 21:29:27.416 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=12
2025-10-13 21:29:27.454 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=13
2025-10-13 21:29:27.470 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=14
2025-10-13 21:29:27.495 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks constructive feedback, The comment violates professional code review norms]
2025-10-13 21:29:27.495 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive feedback, The comment violates professional code review norms]
2025-10-13 21:29:27.495 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive, The comment violates professional code review norms]
2025-10-13 21:29:27.518 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=15
2025-10-13 21:29:27.637 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=598ce2cf-7c6f-4024-bee6-8b46e3353f9d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","The improvement is measurable"],"trustScore":0.7}
2025-10-13 21:29:27.741 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Legitimate giveaways don't require sending money first, Such promises of doubling money are fraudulent]
2025-10-13 21:29:27.876 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e6c9340e-08e0-4c8b-a9a5-38bd2bb007aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive feedback","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 21:29:27.880 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=12
2025-10-13 21:29:27.986 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, The improvement is measurable]
2025-10-13 21:29:28.119 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=16
2025-10-13 21:29:28.232 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive feedback, The comment violates professional code review etiquette]
2025-10-13 21:29:28.666 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eaa74604-527f-435e-b879-212c2c26fe7b, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Legitimate giveaways do not require sending money first","Such promises of doubling money are financially impossible to sustain"],"trustScore":0.1}
2025-10-13 21:29:28.910 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=17
2025-10-13 21:29:28.911 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Legitimate giveaways do not require sending money first, Such promises of doubling money are financially impossible to sustain]
2025-10-13 21:29:30.287 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9ed099bb-325a-46ba-8cf3-a376788d372e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Legitimate giveaways do not require sending money first","Such promises of doubling money are financially impossible to sustain"],"trustScore":0.1}
2025-10-13 21:29:30.530 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=18
2025-10-13 21:29:30.650 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Legitimate giveaways do not require sending money first, Such promises of doubling money are financially impossible to sustain]
2025-10-13 21:29:30.912 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d7a78c5d-c89d-48df-b880-e21fba6a1244, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them","These schemes result in permanent loss of funds for victims"],"trustScore":0.1}
2025-10-13 21:29:31.157 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=19
2025-10-13 21:29:31.158 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Scammers promise to double cryptocurrency sent to them, These schemes result in permanent loss of funds for victims]
2025-10-13 21:30:27.572 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 21:30:27.572 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 21:30:27.573 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 1 ms
2025-10-13 21:30:27.886 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=21f9c9af-78e0-410e-a148-14a740e22220 tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=298 handler=SendToKafkaController.batch
2025-10-13 21:30:35.477 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=854926d5-e5c8-412b-815a-a2e1ad863bef, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d54b596e, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is asking about dataset download location"],"trustScore":0.8}
2025-10-13 21:30:35.564 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3d9debe4-ff21-42c8-8985-b85827f3b4ea, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=529d023c, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for content","The comment indicates learning occurred","The comment is positive in tone"],"trustScore":0.8}
2025-10-13 21:30:35.714 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0a28a844-5c5c-461b-b8cb-6abbebe76631, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d529f800, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses disagreement with someone's understanding of statistics"],"trustScore":0.3}
2025-10-13 21:30:35.720 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=9
2025-10-13 21:30:35.722 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d54b596e, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is asking about dataset download location]
2025-10-13 21:30:35.761 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=192d480c-77cb-4379-99cf-df55d826b5f3, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=cf7592ba, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a moderator response expressing gratitude"],"trustScore":0.9}
2025-10-13 21:30:35.808 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=13
2025-10-13 21:30:35.882 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19048caa-ff6b-433b-8f5f-3bdd2a0ad93b, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b0f15b0d, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The user claims the results are cherry-picked"],"trustScore":0.3}
2025-10-13 21:30:35.958 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=18
2025-10-13 21:30:35.969 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=529d023c, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for content, The comment indicates learning occurred, The comment is positive in tone]
2025-10-13 21:30:35.969 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d529f800, platform=Twitter, type=opinion, conf=0.8, trust=0.3, facts=[The comment expresses disagreement with someone's understanding of statistics]
2025-10-13 21:30:36.004 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=7
2025-10-13 21:30:36.016 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=99e75624-b3b2-4829-8120-9e668c880f4c, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=47ae4eb2, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment requests timestamps for a long-form interview video"],"trustScore":1.0}
2025-10-13 21:30:36.024 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5476821e-762c-432a-ad04-fab1bc630d43, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f8604760, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for benchmarking methodology","The comment does not make factual claims about benchmarking","The comment is subjective in nature"],"trustScore":0.8}
2025-10-13 21:30:36.028 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f4fbfe13-3dbb-42b3-9c4a-870933064550, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bd5efba3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["User is requesting thread merging due to duplication"],"trustScore":0.8}
2025-10-13 21:30:36.051 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=702fdbeb-c456-4dab-bcb3-34c5b0d97152, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=96a0805b, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The commenter states the video helped them pass an exam"],"trustScore":0.7}
2025-10-13 21:30:36.085 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5651855f-cf54-4b58-9a6c-a58104332082, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment was posted on a YouTube video about a new release walkthrough"],"trustScore":0.8}
2025-10-13 21:30:36.125 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=8
2025-10-13 21:30:36.154 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b0210ff5-7b9c-4b55-b840-b13753b57c2f, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=526b75ee, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a promotional link","The link directs to a service selling followers","The domain name appears unprofessional"],"trustScore":0.1}
2025-10-13 21:30:36.216 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=cf7592ba, platform=Reddit, type=opinion, conf=0.9, trust=0.9, facts=[This is a moderator response expressing gratitude]
2025-10-13 21:30:36.216 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b0f15b0d, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The user claims the results are cherry-picked]
2025-10-13 21:30:36.224 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=75de2176-a96d-4174-b032-3d61b6220e4a, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=95b284eb, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests moderator removal of an off-topic advertisement"],"trustScore":0.8}
2025-10-13 21:30:36.243 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a2ac4c43-cb3e-4275-a819-484461c2a95c, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=fe7e89fc, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment is requesting presentation materials from a conference talk upload"],"trustScore":0.8}
2025-10-13 21:30:36.259 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=13
2025-10-13 21:30:36.269 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=19
2025-10-13 21:30:36.271 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=3
2025-10-13 21:30:36.294 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=14
2025-10-13 21:30:36.358 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2cd5e94f-c4bc-43d0-8df9-4741cc40e283, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=1579238, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests citation of sources for a medical claim"],"trustScore":0.8}
2025-10-13 21:30:36.368 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=20
2025-10-13 21:30:36.463 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=96a0805b, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[The commenter states the video helped them pass an exam]
2025-10-13 21:30:36.463 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bd5efba3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting thread merging due to duplication]
2025-10-13 21:30:36.463 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=47ae4eb2, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[The comment requests timestamps for a long-form interview video]
2025-10-13 21:30:36.463 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f8604760, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for benchmarking methodology, The comment does not make factual claims about benchmarking, The comment is subjective in nature]
2025-10-13 21:30:36.463 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a YouTube video about a new release walkthrough]
2025-10-13 21:30:36.473 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=94a47078-8d3a-4907-b714-b3ae8e28d8ff, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c064ad61, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","","''"],"trustScore":0.8}
2025-10-13 21:30:36.502 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=9
2025-10-13 21:30:36.502 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=20
2025-10-13 21:30:36.502 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=21
2025-10-13 21:30:36.601 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=26
2025-10-13 21:30:36.622 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c0cd360-879b-49ec-958d-b290e580c2d9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=45bb11f3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["User expressed appreciation for a tutorial","Comment was posted in context of Docker networking guide"],"trustScore":0.8}
2025-10-13 21:30:36.709 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=1579238, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests citation of sources for a medical claim]
2025-10-13 21:30:36.709 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=526b75ee, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a promotional link, The link directs to a service selling followers, The domain name appears unprofessional]
2025-10-13 21:30:36.709 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=95b284eb, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests moderator removal of an off-topic advertisement]
2025-10-13 21:30:36.709 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=fe7e89fc, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment is requesting presentation materials from a conference talk upload]
2025-10-13 21:30:36.716 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=22
2025-10-13 21:30:36.865 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=21
2025-10-13 21:30:36.935 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6625f772-0654-45f6-987b-f42ad7c173f9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ab00e62d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The model card lacks evaluation details."],"trustScore":0.7}
2025-10-13 21:30:36.935 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=82bacb3c-845b-4263-b774-a0728f075ba9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b199fee4, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The user expressed appreciation for a demo","The user used positive language in their comment","The comment was posted on Twitter"],"trustScore":0.8}
2025-10-13 21:30:36.955 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=45bb11f3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[User expressed appreciation for a tutorial, Comment was posted in context of Docker networking guide]
2025-10-13 21:30:36.955 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c064ad61, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , '']
2025-10-13 21:30:36.997 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fa3b96cb-19f9-443d-be76-4e762ec67c6a, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=67bc6e0d, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["JSON is a data interchange format","YAML is a data serialization format","Both JSON and YAML are used in software development"],"trustScore":0.8}
2025-10-13 21:30:37.024 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=91a32e0c-a479-40b3-8207-e0490da9924c, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a88e8e1f, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests a source for a 10x improvement claim","The context indicates someone made a 10x speedup claim","The comment does not make a factual assertion itself"],"trustScore":0.7}
2025-10-13 21:30:37.064 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b39fa1f3-781c-4ceb-bc6d-8d4654962e52, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c15a1fb8, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude","The comment describes the response as clear and concise","The comment is a response to a config issue resolution"],"trustScore":0.8}
2025-10-13 21:30:37.099 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=aaa1c27f-2468-4c02-b47e-c45cccebfdc9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=2d8aeef, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses skepticism about data presentation","The comment suggests potential bias in chart selection","The comment compares Model A favorably in the presented data"],"trustScore":0.6}
2025-10-13 21:30:37.156 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d6c76da0-0130-44d2-97be-45da6ba31ee6, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d153d2dd, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment requests subtitles for a technical lecture replay"],"trustScore":1.0}
2025-10-13 21:30:37.178 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=18
2025-10-13 21:30:37.178 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=10
2025-10-13 21:30:37.202 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ab00e62d, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The model card lacks evaluation details.]
2025-10-13 21:30:37.202 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b199fee4, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The user expressed appreciation for a demo, The user used positive language in their comment, The comment was posted on Twitter]
2025-10-13 21:30:37.239 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=14
2025-10-13 21:30:37.267 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=22
2025-10-13 21:30:37.297 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=32b328b6-f782-4aca-b1ed-abfec4bb8f61, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=5367e6a5, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["Confidence intervals overlapping indicates no statistically significant difference between groups"],"trustScore":0.8}
2025-10-13 21:30:37.307 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=23
2025-10-13 21:30:37.345 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=15
2025-10-13 21:30:37.414 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5845db0b-52b3-4a1c-a9f2-1ebf455d17f0, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4b1e90eb, platform=Forum, result={"type":"opinion","confidence":0.8,"facts":["The graph lacks labeled axes","Unlabeled axes can lead to misinterpretation","Proper graphs require clear axis labels"],"trustScore":0.7}
2025-10-13 21:30:37.421 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=11
2025-10-13 21:30:37.423 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=656df53f-c7f0-4713-b803-897f60ac73d7, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=90f74847, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims Section 3 contains mathematical errors","This is a critique of a paper summary","The comment provides no specific mathematical evidence"],"trustScore":0.3}
2025-10-13 21:30:37.450 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=2d8aeef, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment expresses skepticism about data presentation, The comment suggests potential bias in chart selection, The comment compares Model A favorably in the presented data]
2025-10-13 21:30:37.450 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d153d2dd, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[Comment requests subtitles for a technical lecture replay]
2025-10-13 21:30:37.450 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=67bc6e0d, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[JSON is a data interchange format, YAML is a data serialization format, Both JSON and YAML are used in software development]
2025-10-13 21:30:37.450 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a88e8e1f, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests a source for a 10x improvement claim, The context indicates someone made a 10x speedup claim, The comment does not make a factual assertion itself]
2025-10-13 21:30:37.450 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c15a1fb8, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude, The comment describes the response as clear and concise, The comment is a response to a config issue resolution]
2025-10-13 21:30:37.540 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=9
2025-10-13 21:30:37.657 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=27
2025-10-13 21:30:37.666 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=10
2025-10-13 21:30:37.695 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4b1e90eb, platform=Forum, type=opinion, conf=0.8, trust=0.7, facts=[The graph lacks labeled axes, Unlabeled axes can lead to misinterpretation, Proper graphs require clear axis labels]
2025-10-13 21:30:37.695 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=5367e6a5, platform=Forum, type=fact, conf=0.9, trust=0.8, facts=[Confidence intervals overlapping indicates no statistically significant difference between groups]
2025-10-13 21:30:37.695 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=90f74847, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The comment claims Section 3 contains mathematical errors, This is a critique of a paper summary, The comment provides no specific mathematical evidence]
2025-10-13 21:30:37.730 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4fe72c93-90d1-43ee-8f56-2f3d41a02d71, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3695f2cb, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment offers a free gift without context","This pattern is commonly used in spam comments","YouTube tutorials often attract spam comments"],"trustScore":0.1}
2025-10-13 21:30:37.775 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4574467a-a88c-4c72-8337-3f4bc8e82199, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8462d113, platform=Reddit, result={"type":"opinion","confidence":0.95,"facts":["User posted content containing a slur","Slurs violate community guidelines","Moderators can take action against rule violations"],"trustScore":0.9}
2025-10-13 21:30:37.778 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62c8e179-90a1-40dd-b7da-3cf89f0d40a9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f7c81544, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.8}
2025-10-13 21:30:37.856 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=070b6d14-126a-4aad-a74b-53ac7bc18b01, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a10338c7, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment states that a claim lacks evidence","The comment is responding to a bold performance claim","The comment expresses skepticism about evidence supporting a claim"],"trustScore":0.7}
2025-10-13 21:30:37.863 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fc4f1596-e747-438f-a467-f0f18497e4eb, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=249afa42, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citations for a health claim","The comment does not make any factual assertions itself","The comment is seeking verification of information"],"trustScore":0.7}
2025-10-13 21:30:37.922 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=12443bfd-9796-4fb6-8dd9-29ed6ff4d235, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=e4b6047f, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment reports hate speech in replies","The context indicates a thread descending into insults","This is a meta-comment about content moderation"],"trustScore":0.7}
2025-10-13 21:30:37.973 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=19
2025-10-13 21:30:37.974 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3695f2cb, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment offers a free gift without context, This pattern is commonly used in spam comments, YouTube tutorials often attract spam comments]
2025-10-13 21:30:37.979 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c11b6f22-ddde-4ba1-ac8c-a1ab881578df, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=aa177b64, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 25%"],"trustScore":0.7}
2025-10-13 21:30:37.991 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb5fb054-21dd-41fc-8224-6c3257dba99f, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dce37358, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment warns users about a potential scam","The comment advises against clicking something","The comment appears in a suspicious giveaway thread context"],"trustScore":0.7}
2025-10-13 21:30:38.006 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0f02944d-62f8-445d-8914-c9b87f2a50c1, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dcd4c761, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["",""],"trustScore":0.7}
2025-10-13 21:30:38.018 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=11
2025-10-13 21:30:38.020 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=15
2025-10-13 21:30:38.068 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4414aebe-ff58-4b73-9d10-6bee3c811ad1, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b71bc599, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of content","The comment states the content is off-topic","The comment is made in a thread about safety policies"],"trustScore":0.7}
2025-10-13 21:30:38.099 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=23
2025-10-13 21:30:38.105 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=16
2025-10-13 21:30:38.145 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=047bd9aa-1a72-47c3-a244-afea1e50ebef, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a7f81f33, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User reports bot replies flooding thread","Context indicates suspicious activity","Platform is Twitter"],"trustScore":0.7}
2025-10-13 21:30:38.215 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=28
2025-10-13 21:30:38.221 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f7c81544, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 21:30:38.221 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=249afa42, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests citations for a health claim, The comment does not make any factual assertions itself, The comment is seeking verification of information]
2025-10-13 21:30:38.221 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=e4b6047f, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[The comment reports hate speech in replies, The context indicates a thread descending into insults, This is a meta-comment about content moderation]
2025-10-13 21:30:38.222 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a10338c7, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment states that a claim lacks evidence, The comment is responding to a bold performance claim, The comment expresses skepticism about evidence supporting a claim]
2025-10-13 21:30:38.222 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8462d113, platform=Reddit, type=opinion, conf=0.95, trust=0.9, facts=[User posted content containing a slur, Slurs violate community guidelines, Moderators can take action against rule violations]
2025-10-13 21:30:38.262 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=4
2025-10-13 21:30:38.263 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=29
2025-10-13 21:30:38.263 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=10
2025-10-13 21:30:38.312 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=17
2025-10-13 21:30:38.368 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8f25704b-2a89-441c-a23f-89914d159160, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9e89bdf, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["User is requesting source code address","Video description appears to lack a link","Comment is a simple request for information"],"trustScore":0.8}
2025-10-13 21:30:38.388 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=24
2025-10-13 21:30:38.463 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3d69ffee-47c6-40dc-a2b1-8041392d26fd, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=83b22e3c, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment violates civil discourse norms","The comment occurred in a code review context"],"trustScore":0.1}
2025-10-13 21:30:38.467 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b71bc599, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests removal of content, The comment states the content is off-topic, The comment is made in a thread about safety policies]
2025-10-13 21:30:38.467 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dcd4c761, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, ]
2025-10-13 21:30:38.467 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=aa177b64, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 25%]
2025-10-13 21:30:38.467 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dce37358, platform=Twitter, type=opinion, conf=0.9, trust=0.7, facts=[The comment warns users about a potential scam, The comment advises against clicking something, The comment appears in a suspicious giveaway thread context]
2025-10-13 21:30:38.467 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a7f81f33, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[User reports bot replies flooding thread, Context indicates suspicious activity, Platform is Twitter]
2025-10-13 21:30:38.611 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=24
2025-10-13 21:30:38.706 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=15
2025-10-13 21:30:38.713 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=83b22e3c, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment violates civil discourse norms, The comment occurred in a code review context]
2025-10-13 21:30:38.713 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9e89bdf, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting source code address, Video description appears to lack a link, Comment is a simple request for information]
2025-10-13 21:30:38.874 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=caa3f017-5703-4660-a1e5-449ab1c21817, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bae34db9, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["User expressed approval of content","User indicated intent to save content for later reference"],"trustScore":0.8}
2025-10-13 21:30:39.079 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f25ec728-6a25-410a-bca4-602660b75957, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=79c5d488, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment uses ad hominem attack","The comment dismisses the argument without engagement","The comment focuses on the person rather than the argument"],"trustScore":0.2}
2025-10-13 21:30:39.118 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=30
2025-10-13 21:30:39.121 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bae34db9, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[User expressed approval of content, User indicated intent to save content for later reference]
2025-10-13 21:30:39.305 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=21119b93-4bbb-46c0-8aec-ee92eab96c60, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dabb0dea, platform=Twitter, result={"type":"opinion","confidence":0.7,"facts":["The comment requests proof for a claimed state-of-the-art achievement","The comment references a leaderboard screenshot as context","The comment expresses skepticism about an unverified claim"],"trustScore":0.5}
2025-10-13 21:30:39.323 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=1
2025-10-13 21:30:39.368 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=79c5d488, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment uses ad hominem attack, The comment dismisses the argument without engagement, The comment focuses on the person rather than the argument]
2025-10-13 21:30:39.430 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=07dc37df-6e0e-4870-b1b7-e1c76e0772f4, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=84456f9b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This comment states that something violates community rules","The comment does not specify what content is being referenced","The comment makes a claim about rule violation without providing evidence"],"trustScore":0.3}
2025-10-13 21:30:39.549 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=31
2025-10-13 21:30:39.614 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dabb0dea, platform=Twitter, type=opinion, conf=0.7, trust=0.5, facts=[The comment requests proof for a claimed state-of-the-art achievement, The comment references a leaderboard screenshot as context, The comment expresses skepticism about an unverified claim]
2025-10-13 21:30:39.655 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2ac90b37-dfec-45a3-aee3-e871fc08b588, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=afceae1f, platform=Twitter, result={"type":"misinformation","confidence":0.95,"facts":["This comment promises to double cryptocurrency sent by users","Such promises are commonly associated with cryptocurrency scams","No legitimate service guarantees instant cryptocurrency doubling"],"trustScore":0.1}
2025-10-13 21:30:39.674 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=25
2025-10-13 21:30:39.689 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=76e36ff8-706c-4bfd-aca3-98b0f15eabe4, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9546f9b5, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Axis scaling can distort data visualization","Misleading scaling exaggerates or minimizes trends","Proper scaling maintains proportional representation"],"trustScore":0.3}
2025-10-13 21:30:39.853 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7d076ede-5a66-4b96-9f0e-ec7217e9e0a4, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8d27383f, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.7}
2025-10-13 21:30:39.860 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=84456f9b, platform=Reddit, type=opinion, conf=0.9, trust=0.3, facts=[This comment states that something violates community rules, The comment does not specify what content is being referenced, The comment makes a claim about rule violation without providing evidence]
2025-10-13 21:30:39.899 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=5
2025-10-13 21:30:39.932 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=20
2025-10-13 21:30:40.001 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a5552c12-b916-4e8d-b3d5-5a6b5a89eae2, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ce786d9f, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset does not include license information","License information is typically included in dataset documentation","Missing license information creates uncertainty about usage rights"],"trustScore":0.85}
2025-10-13 21:30:40.076 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bede6ab1-38ea-4442-8982-669feb0873e0, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=6245232a, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses negative sentiment","The comment lacks constructive feedback","The comment provides no specific criticism"],"trustScore":0.2}
2025-10-13 21:30:40.095 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=18
2025-10-13 21:30:40.106 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9546f9b5, platform=Forum, type=misinformation, conf=0.85, trust=0.3, facts=[Axis scaling can distort data visualization, Misleading scaling exaggerates or minimizes trends, Proper scaling maintains proportional representation]
2025-10-13 21:30:40.106 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8d27383f, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, , ]
2025-10-13 21:30:40.106 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=afceae1f, platform=Twitter, type=misinformation, conf=0.95, trust=0.1, facts=[This comment promises to double cryptocurrency sent by users, Such promises are commonly associated with cryptocurrency scams, No legitimate service guarantees instant cryptocurrency doubling]
2025-10-13 21:30:40.246 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=11
2025-10-13 21:30:40.317 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e74fab65-51ce-4c95-963d-d875ac434b80, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=866e8221, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset link provided in the forum post is broken","The user reported being unable to access the dataset","Reproduction steps were provided alongside the broken link report"],"trustScore":0.85}
2025-10-13 21:30:40.319 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=12
2025-10-13 21:30:40.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ce786d9f, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset does not include license information, License information is typically included in dataset documentation, Missing license information creates uncertainty about usage rights]
2025-10-13 21:30:40.351 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=6245232a, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment expresses negative sentiment, The comment lacks constructive feedback, The comment provides no specific criticism]
2025-10-13 21:30:40.468 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fe0cf4fa-81db-4d61-bc19-51ffd640921b, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4432cdd, platform=Reddit, result={"type":"fact","confidence":0.9,"facts":["Mislabeled axes can invalidate data interpretation in scientific plots","Proper axis labeling is essential for valid scientific conclusions","Throughput vs latency plots require correct axis identification for meaningful analysis"],"trustScore":0.95}
2025-10-13 21:30:40.560 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=13
2025-10-13 21:30:40.597 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=866e8221, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset link provided in the forum post is broken, The user reported being unable to access the dataset, Reproduction steps were provided alongside the broken link report]
2025-10-13 21:30:40.710 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=19
2025-10-13 21:30:40.843 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4432cdd, platform=Reddit, type=fact, conf=0.9, trust=0.95, facts=[Mislabeled axes can invalidate data interpretation in scientific plots, Proper axis labeling is essential for valid scientific conclusions, Throughput vs latency plots require correct axis identification for meaningful analysis]
2025-10-13 21:30:40.877 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e6e2e644-f5a1-4022-a21d-0d9a85667ca3, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.9,"facts":["The comment claims 'This is misinformation' without specifying what is being referred to","The comment makes a blanket statement without providing evidence or context","The comment appears in a thread about vaccine risks but doesn't identify specific misinformation"],"trustScore":0.2}
2025-10-13 21:30:41.120 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=12
2025-10-13 21:30:41.121 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.9, trust=0.2, facts=[The comment claims 'This is misinformation' without specifying what is being referred to, The comment makes a blanket statement without providing evidence or context, The comment appears in a thread about vaccine risks but doesn't identify specific misinformation]
2025-10-13 21:30:43.487 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c3dd88ca-af31-413b-91cf-5f3703caf117, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4fcacd6b, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 21:30:43.731 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=12
2025-10-13 21:30:43.732 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4fcacd6b, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 21:37:23.496 [kafka-2] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Revoke previously assigned partitions ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11
2025-10-13 21:37:23.496 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 21:37:23.497 [kafka-2] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= ef-results-debug: partitions revoked: [ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11]
2025-10-13 21:37:23.497 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 21:37:23.497 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Member consumer-ef-results-debug-2-75bc6566-6a47-4d74-a998-3e198d3959df sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 21:37:23.497 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-c546080b-8f58-4c41-b493-d87cec330bad sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 21:37:23.498 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.498 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.498 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.498 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.498 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 21:37:23.498 [kafka-2] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 21:37:23.499 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.499 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.499 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.499 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 21:37:23.991 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:37:23.991 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:37:23.991 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:37:23.991 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:37:23.993 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 21:37:23.993 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 21:37:24.114 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:37:24.114 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:37:24.114 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:37:24.114 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:37:24.116 [kafka-2] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-ef-results-debug-2 unregistered
2025-10-13 21:37:24.116 [kafka-2] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= ef-results-debug: Consumer stopped
2025-10-13 21:37:24.116 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 21:37:24.126 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 21:37:24.131 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-10-13 21:37:24.133 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 21:37:24.133 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 21:37:24.133 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 21:37:24.133 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 21:37:24.133 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.producer for producer-1 unregistered
2025-10-13 23:04:56.462 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Starting EchoFilterApplication using Java 21.0.8 with PID 62920 (C:\Projects\EchoFilter\target\classes started by ZiDiY in C:\Projects\EchoFilter)
2025-10-13 23:04:56.464 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= No active profile set, falling back to 1 default profile: "default"
2025-10-13 23:04:56.499 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-10-13 23:04:56.499 [restartedMain] INFO  o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - trace= tenant= user= For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-10-13 23:04:57.163 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Multiple Spring Data modules found, entering strict repository configuration mode
2025-10-13 23:04:57.165 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-10-13 23:04:57.213 [restartedMain] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - trace= tenant= user= Finished Spring Data repository scanning in 32 ms. Found 0 Redis repository interfaces.
2025-10-13 23:04:57.925 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat initialized with port 8080 (http)
2025-10-13 23:04:57.934 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Initializing ProtocolHandler ["http-nio-8080"]
2025-10-13 23:04:57.936 [restartedMain] INFO  o.a.catalina.core.StandardService - trace= tenant= user= Starting service [Tomcat]
2025-10-13 23:04:57.936 [restartedMain] INFO  o.a.catalina.core.StandardEngine - trace= tenant= user= Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-10-13 23:04:57.976 [restartedMain] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring embedded WebApplicationContext
2025-10-13 23:04:57.976 [restartedMain] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - trace= tenant= user= Root WebApplicationContext: initialization completed in 1477 ms
2025-10-13 23:04:58.892 [restartedMain] INFO  o.s.v.b.OptionalValidatorFactoryBean - trace= tenant= user= Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
2025-10-13 23:04:59.240 [restartedMain] INFO  o.s.b.d.a.OptionalLiveReloadServer - trace= tenant= user= LiveReload server is running on port 35729
2025-10-13 23:04:59.300 [restartedMain] INFO  o.a.k.c.admin.AdminClientConfig - trace= tenant= user= AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [81.70.198.98:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-10-13 23:04:59.381 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 23:04:59.382 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 23:04:59.382 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760411099380
2025-10-13 23:05:01.996 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.admin.client for adminclient-1 unregistered
2025-10-13 23:05:02.000 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 23:05:02.000 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 23:05:02.000 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 23:05:02.004 [restartedMain] INFO  o.a.coyote.http11.Http11NioProtocol - trace= tenant= user= Starting ProtocolHandler ["http-nio-8080"]
2025-10-13 23:05:02.010 [restartedMain] INFO  o.s.b.w.e.tomcat.TomcatWebServer - trace= tenant= user= Tomcat started on port 8080 (http) with context path '/'
2025-10-13 23:05:02.030 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-echofilter-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = echofilter-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 23:05:02.063 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 23:05:02.104 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 23:05:02.104 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 23:05:02.104 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760411102104
2025-10-13 23:05:02.107 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Subscribed to topic(s): ef.requests.v1
2025-10-13 23:05:02.117 [restartedMain] INFO  o.a.k.c.consumer.ConsumerConfig - trace= tenant= user= ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [81.70.198.98:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-ef-results-debug-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ef-results-debug
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-10-13 23:05:02.118 [restartedMain] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 23:05:02.124 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 23:05:02.124 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 23:05:02.124 [restartedMain] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760411102124
2025-10-13 23:05:02.124 [restartedMain] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Subscribed to topic(s): ef.results.v1
2025-10-13 23:05:02.132 [restartedMain] INFO  c.echofilter.EchoFilterApplication - trace= tenant= user= Started EchoFilterApplication in 6.155 seconds (process running for 6.76)
2025-10-13 23:05:03.112 [kafka-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 23:05:03.112 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 23:05:03.113 [kafka-2] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 23:05:03.113 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Discovered group coordinator 81.70.198.98:9092 (id: 2147483646 rack: null)
2025-10-13 23:05:03.117 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] (Re-)joining group
2025-10-13 23:05:03.117 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 23:05:04.087 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Request joining group due to: need to re-join with the given member-id: consumer-ef-results-debug-2-9b696116-614a-4c89-9540-d0dded2e4ffc
2025-10-13 23:05:04.088 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] (Re-)joining group
2025-10-13 23:05:04.092 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: need to re-join with the given member-id: consumer-echofilter-group-1-ae61dfcf-481b-4c63-9474-0c4366e97029
2025-10-13 23:05:04.092 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] (Re-)joining group
2025-10-13 23:05:07.331 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Successfully joined group with generation Generation{generationId=3, memberId='consumer-ef-results-debug-2-9b696116-614a-4c89-9540-d0dded2e4ffc', protocol='range'}
2025-10-13 23:05:07.337 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Finished assignment for group at generation 3: {consumer-ef-results-debug-2-9b696116-614a-4c89-9540-d0dded2e4ffc=Assignment(partitions=[ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11])}
2025-10-13 23:05:07.339 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully joined group with generation Generation{generationId=9, memberId='consumer-echofilter-group-1-ae61dfcf-481b-4c63-9474-0c4366e97029', protocol='range'}
2025-10-13 23:05:07.339 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Finished assignment for group at generation 9: {consumer-echofilter-group-1-ae61dfcf-481b-4c63-9474-0c4366e97029=Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])}
2025-10-13 23:05:07.584 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Successfully synced group in generation Generation{generationId=3, memberId='consumer-ef-results-debug-2-9b696116-614a-4c89-9540-d0dded2e4ffc', protocol='range'}
2025-10-13 23:05:07.584 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Successfully synced group in generation Generation{generationId=9, memberId='consumer-echofilter-group-1-ae61dfcf-481b-4c63-9474-0c4366e97029', protocol='range'}
2025-10-13 23:05:07.584 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Notifying assignor about the new Assignment(partitions=[ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11])
2025-10-13 23:05:07.584 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Notifying assignor about the new Assignment(partitions=[ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11])
2025-10-13 23:05:07.589 [kafka-2] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Adding newly assigned partitions: ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11
2025-10-13 23:05:07.589 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Adding newly assigned partitions: ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 23:05:08.084 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-8 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-9 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-6 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-7 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-5 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-2 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-3 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-1 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.085 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-10 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-2] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.results.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-1 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-11 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-10 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-7 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-6 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-9 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-8 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.086 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-3 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.087 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.087 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-5 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.087 [kafka-1] INFO  o.a.k.c.c.internals.ConsumerUtils - trace= tenant= user= Setting offset for partition ef.requests.v1-4 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[81.70.198.98:9092 (id: 1 rack: null)], epoch=0}}
2025-10-13 23:05:08.197 [kafka-2] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= ef-results-debug: partitions assigned: [ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11]
2025-10-13 23:05:08.197 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions assigned: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 23:05:10.048 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[The commenter states the video helped them pass an exam]
2025-10-13 23:05:10.049 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for content, The comment indicates learning occurred, The comment contains positive sentiment]
2025-10-13 23:05:10.049 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 23:05:10.050 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%]
2025-10-13 23:05:10.051 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%]
2025-10-13 23:05:10.051 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses dismissive language]
2025-10-13 23:05:10.051 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses dismissive language]
2025-10-13 23:05:10.052 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:10.052 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:10.052 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, Performance metrics were measured]
2025-10-13 23:05:10.053 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, type=fact, conf=0.85, trust=0.8, facts=[Performance improved by 30% according to provided benchmark]
2025-10-13 23:05:10.053 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:10.054 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, The improvement is measurable]
2025-10-13 23:05:10.054 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=529d023c, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for content, The comment indicates learning occurred, The comment is positive in tone]
2025-10-13 23:05:10.055 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=96a0805b, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[The commenter states the video helped them pass an exam]
2025-10-13 23:05:10.055 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f7c81544, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 23:05:10.055 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement, The comment is a personal opinion, The comment lacks specific factual claims]
2025-10-13 23:05:10.056 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 23:05:10.056 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The model card lacks evaluation details]
2025-10-13 23:05:10.056 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement, The comment does not provide specific factual claims, The comment is a personal opinion]
2025-10-13 23:05:10.056 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 23:05:10.057 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement, The comment does not provide specific factual claims, The comment is a personal opinion]
2025-10-13 23:05:10.057 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service to buy followers, The website domain appears to be commercial, The comment lacks substantive content]
2025-10-13 23:05:10.057 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment offers a free gift without context, This is a common spam tactic on YouTube, Such comments often lead to phishing or scams]
2025-10-13 23:05:10.058 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service to buy followers, The website domain 'spammy.site' suggests low-quality content, Purchased followers violate platform terms of service]
2025-10-13 23:05:10.058 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' suggests potential spam activity, Purchased followers violate most platform terms of service]
2025-10-13 23:05:10.059 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing social media followers, The domain 'spammy.site' suggests potential unreliability, Purchased followers typically violate platform terms of service]
2025-10-13 23:05:10.059 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The context mentions Model X vs Y comparison, The comment expresses skepticism about benchmark methodology]
2025-10-13 23:05:10.059 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' appears to be a commercial service, The comment lacks substantive content beyond promotional messaging]
2025-10-13 23:05:10.060 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Model Y, The comment implies potential bias in benchmark selection]
2025-10-13 23:05:10.060 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Y, The comment implies potential bias in benchmark selection]
2025-10-13 23:05:10.060 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Model Y, The comment implies potential bias in the benchmarking methodology]
2025-10-13 23:05:10.061 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, type=misinformation, conf=0.85, trust=0.3, facts=[Misleading axis scaling can distort data visualization, Proper chart scaling should maintain proportional relationships, Axis manipulation can create false impressions of performance trends]
2025-10-13 23:05:10.061 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references Model X vs Y comparison, The comment implies potential bias in benchmark selection]
2025-10-13 23:05:10.061 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ab00e62d, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The model card lacks evaluation details.]
2025-10-13 23:05:10.062 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3695f2cb, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment offers a free gift without context, This pattern is commonly used in spam comments, YouTube tutorials often attract spam comments]
2025-10-13 23:05:10.062 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9546f9b5, platform=Forum, type=misinformation, conf=0.85, trust=0.3, facts=[Axis scaling can distort data visualization, Misleading scaling exaggerates or minimizes trends, Proper scaling maintains proportional representation]
2025-10-13 23:05:10.062 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses approval of the tutorial, The comment indicates the tutorial was clear, The comment is positive feedback]
2025-10-13 23:05:10.063 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[Comment expresses positive feedback about Java virtual threads tutorial, Comment indicates tutorial was clearly explained, Comment shows viewer satisfaction with content]
2025-10-13 23:05:10.063 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial, The comment indicates the tutorial was explained clearly, The comment shows viewer appreciation for educational content]
2025-10-13 23:05:10.063 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment does not make a factual claim, The comment seeks additional information from the original poster]
2025-10-13 23:05:10.064 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment responds to a claim of 'big improvement', The comment does not contain substantive claims to verify]
2025-10-13 23:05:10.064 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.7, facts=[The comment consists of a single word 'Source?', The comment is requesting verification or evidence for a claim, The comment does not make any factual assertions itself]
2025-10-13 23:05:10.064 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests citations for a health claim, The comment does not make any factual claims itself, The comment appears in a health claim discussion context]
2025-10-13 23:05:10.064 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment does not make any factual claims itself, The comment references a previous claim about 'big improvement']
2025-10-13 23:05:10.066 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial., The comment uses informal Chinese language to convey approval., The comment does not contain verifiable factual claims about Java virtual threads.]
2025-10-13 23:05:10.067 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment responds to a claim of 'big improvement', The comment does not contain substantive information itself]
2025-10-13 23:05:10.067 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial., The comment uses informal Chinese language typical of online praise., The comment does not contain verifiable factual claims about Java virtual threads.]
2025-10-13 23:05:10.067 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment expresses skepticism about data presentation, The comment suggests potential bias in chart selection, The comment compares Model A favorably in the presented data]
2025-10-13 23:05:10.067 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests removal of content, The comment indicates the content is off-topic, The comment is made in a thread about safety policies]
2025-10-13 23:05:10.068 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, , ]
2025-10-13 23:05:10.068 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, type=fact, conf=0.9, trust=0.85, facts=[Mislabelled axes can invalidate data interpretation in graphs, Proper axis labeling is essential for valid scientific claims, Incorrect axis labels can lead to misinterpretation of throughput vs latency relationships]
2025-10-13 23:05:10.068 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=2d8aeef, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment expresses skepticism about data presentation, The comment suggests potential bias in chart selection, The comment compares Model A favorably in the presented data]
2025-10-13 23:05:10.068 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=249afa42, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests citations for a health claim, The comment does not make any factual assertions itself, The comment is seeking verification of information]
2025-10-13 23:05:10.069 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b71bc599, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests removal of content, The comment states the content is off-topic, The comment is made in a thread about safety policies]
2025-10-13 23:05:10.069 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8d27383f, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, , ]
2025-10-13 23:05:10.069 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4432cdd, platform=Reddit, type=fact, conf=0.9, trust=0.95, facts=[Mislabeled axes can invalidate data interpretation in scientific plots, Proper axis labeling is essential for valid scientific conclusions, Throughput vs latency plots require correct axis identification for meaningful analysis]
2025-10-13 23:05:10.070 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment contains an ad hominem attack, Ad hominem attacks focus on the person rather than the argument, This type of rhetoric is commonly used in heated debates]
2025-10-13 23:05:10.070 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=79c5d488, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment uses ad hominem attack, The comment dismisses the argument without engagement, The comment focuses on the person rather than the argument]
2025-10-13 23:05:10.070 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[This comment requests merging of duplicate posts, The comment is made in a Reddit context, The comment contains no factual claims about external topics]
2025-10-13 23:05:10.070 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, ]
2025-10-13 23:05:10.071 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This comment promises to double cryptocurrency sent to the user, Unsolicited cryptocurrency doubling offers are commonly associated with scams, No legitimate financial service guarantees instant cryptocurrency doubling]
2025-10-13 23:05:10.071 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bd5efba3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting thread merging due to duplication]
2025-10-13 23:05:10.071 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dcd4c761, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, ]
2025-10-13 23:05:10.072 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=afceae1f, platform=Twitter, type=misinformation, conf=0.95, trust=0.1, facts=[This comment promises to double cryptocurrency sent by users, Such promises are commonly associated with cryptocurrency scams, No legitimate service guarantees instant cryptocurrency doubling]
2025-10-13 23:05:10.072 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:10.072 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:10.073 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:10.073 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:10.073 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The user expressed appreciation for content, The user indicated they saved the content for future reference]
2025-10-13 23:05:10.073 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests citation of sources, The comment does not contain a specific medical claim, The comment appears in a forum context]
2025-10-13 23:05:10.074 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly associated with spam]
2025-10-13 23:05:10.074 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[Comment requests removal of content, Comment contains no substantive discussion, Comment appears to be off-topic advertising]
2025-10-13 23:05:10.074 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly associated with spam]
2025-10-13 23:05:10.075 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[Comment contains a link promising free gifts, This pattern is commonly associated with spam campaigns, Such comments often lead to phishing or malware distribution]
2025-10-13 23:05:10.075 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment claims there is an error in section 3 of the paper]
2025-10-13 23:05:10.075 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 25%]
2025-10-13 23:05:10.075 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 23:05:10.075 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[Comment contains a link promising free gifts, This pattern is commonly used in spam campaigns, Such links often lead to phishing or malware sites]
2025-10-13 23:05:10.076 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 23:05:10.076 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 23:05:10.076 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly associated with spam]
2025-10-13 23:05:10.076 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests moderator removal, The comment is labeled as 'pure spam', The comment is an off-topic advertisement]
2025-10-13 23:05:10.077 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, type=opinion, conf=0.7, trust=0.5, facts=[The comment requests proof for a claimed state-of-the-art achievement, The comment references a leaderboard screenshot as context, The comment expresses skepticism about an unverified claim]
2025-10-13 23:05:10.077 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a subjective assessment of mathematical accuracy]
2025-10-13 23:05:10.077 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:10.078 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims mathematical errors exist in section 3, The comment expresses disagreement with mathematical content, The comment makes an evaluative statement about academic work]
2025-10-13 23:05:10.078 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, type=misinformation, conf=0.8, trust=0.2, facts=[The graph lacks labeled axes, Unlabeled axes make data interpretation unreliable, Visual representations require proper labeling for accurate understanding]
2025-10-13 23:05:10.078 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[The comment reports hate speech in replies, The context indicates a thread descending into insults, This is a meta-comment about content moderation]
2025-10-13 23:05:10.078 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a subjective assessment of mathematical accuracy]
2025-10-13 23:05:10.079 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a critical assessment without providing specific corrections]
2025-10-13 23:05:10.079 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=1579238, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests citation of sources for a medical claim]
2025-10-13 23:05:10.079 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4b1e90eb, platform=Forum, type=opinion, conf=0.8, trust=0.7, facts=[The graph lacks labeled axes, Unlabeled axes can lead to misinterpretation, Proper graphs require clear axis labels]
2025-10-13 23:05:10.079 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=e4b6047f, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[The comment reports hate speech in replies, The context indicates a thread descending into insults, This is a meta-comment about content moderation]
2025-10-13 23:05:10.079 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=aa177b64, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 25%]
2025-10-13 23:05:10.080 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bae34db9, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[User expressed approval of content, User indicated intent to save content for later reference]
2025-10-13 23:05:10.080 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dabb0dea, platform=Twitter, type=opinion, conf=0.7, trust=0.5, facts=[The comment requests proof for a claimed state-of-the-art achievement, The comment references a leaderboard screenshot as context, The comment expresses skepticism about an unverified claim]
2025-10-13 23:05:10.080 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[Comment requests subtitles for a technical lecture replay]
2025-10-13 23:05:10.080 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for a demo, The comment contains positive sentiment, The comment is a brief social media interaction]
2025-10-13 23:05:10.080 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a promotional link, The link directs to a service selling followers, The website domain appears unprofessional]
2025-10-13 23:05:10.081 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.9, trust=0.1, facts=[Vaccines undergo rigorous testing before approval, Vaccine benefits significantly outweigh risks for most populations, Serious vaccine side effects are extremely rare]
2025-10-13 23:05:10.081 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety]
2025-10-13 23:05:10.081 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 23:05:10.081 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[The comment claims something is misinformation without specifying what, The comment references vaccines but provides no specific claim, The comment makes an unsubstantiated assertion about misinformation]
2025-10-13 23:05:10.081 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.15, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 23:05:10.082 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 23:05:10.082 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=526b75ee, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a promotional link, The link directs to a service selling followers, The domain name appears unprofessional]
2025-10-13 23:05:10.082 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b199fee4, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The user expressed appreciation for a demo, The user used positive language in their comment, The comment was posted on Twitter]
2025-10-13 23:05:10.082 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d153d2dd, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[Comment requests subtitles for a technical lecture replay]
2025-10-13 23:05:10.082 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.9, trust=0.2, facts=[The comment claims 'This is misinformation' without specifying what is being referred to, The comment makes a blanket statement without providing evidence or context, The comment appears in a thread about vaccine risks but doesn't identify specific misinformation]
2025-10-13 23:05:10.083 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 23:05:10.083 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=1.0, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker]
2025-10-13 23:05:10.083 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no factual claims to verify]
2025-10-13 23:05:10.083 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is asking about dataset download location]
2025-10-13 23:05:10.083 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, type=opinion, conf=0.9, trust=0.7, facts=[The comment warns users about a potential scam, The comment advises against clicking unspecified content, The context indicates this is related to a suspicious giveaway thread]
2025-10-13 23:05:10.083 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 23:05:10.084 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation., The comment is a response to a guide about Docker., The comment contains no substantive claims about Docker.]
2025-10-13 23:05:10.084 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, type=fact, conf=0.9, trust=0.95, facts=[The dataset does not include license information, License information is typically required for data sharing and reuse, Missing license info can limit dataset usability]
2025-10-13 23:05:10.084 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:10.084 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d54b596e, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is asking about dataset download location]
2025-10-13 23:05:10.085 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dce37358, platform=Twitter, type=opinion, conf=0.9, trust=0.7, facts=[The comment warns users about a potential scam, The comment advises against clicking something, The comment appears in a suspicious giveaway thread context]
2025-10-13 23:05:10.085 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ce786d9f, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset does not include license information, License information is typically included in dataset documentation, Missing license information creates uncertainty about usage rights]
2025-10-13 23:05:10.085 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4fcacd6b, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:10.086 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link]
2025-10-13 23:05:10.086 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link]
2025-10-13 23:05:10.086 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a question about research data, The context is a paper discussion]
2025-10-13 23:05:10.086 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[JSON is a data interchange format, YAML is a data serialization format, Both JSON and YAML are used in software development]
2025-10-13 23:05:10.088 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a neutral information request, The context is a paper discussion]
2025-10-13 23:05:10.088 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a question about research data, The context indicates academic paper discussion]
2025-10-13 23:05:10.088 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests timestamps for a long-form interview video]
2025-10-13 23:05:10.089 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 23:05:10.089 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 23:05:10.089 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment is making a claim about another user's behavior]
2025-10-13 23:05:10.089 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment violates civil discourse norms, The comment occurred in a code review context]
2025-10-13 23:05:10.089 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment is making a claim about another user's behavior]
2025-10-13 23:05:10.090 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment serves as a content moderation report]
2025-10-13 23:05:10.090 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=47ae4eb2, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[The comment requests timestamps for a long-form interview video]
2025-10-13 23:05:10.090 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=67bc6e0d, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[JSON is a data interchange format, YAML is a data serialization format, Both JSON and YAML are used in software development]
2025-10-13 23:05:10.091 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=83b22e3c, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment violates civil discourse norms, The comment occurred in a code review context]
2025-10-13 23:05:10.091 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment 'First!' is a common internet expression]
2025-10-13 23:05:10.091 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for benchmarking methodology]
2025-10-13 23:05:10.091 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, type=opinion, conf=0.8, trust=0.3, facts=[The comment expresses disagreement with someone's understanding of statistics]
2025-10-13 23:05:10.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a YouTube video about a new product]
2025-10-13 23:05:10.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a YouTube video about a new release walkthrough]
2025-10-13 23:05:10.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting source code address, Video description appears to lack a link, Comment is a simple inquiry]
2025-10-13 23:05:10.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, type=opinion, conf=0.8, trust=0.9, facts=[The comment requests a source for a 10x improvement claim]
2025-10-13 23:05:10.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 23:05:10.092 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for a tutorial, The comment refers to a Docker networking guide, The comment contains positive feedback]
2025-10-13 23:05:10.093 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, The choice between tabs and spaces is subjective in programming]
2025-10-13 23:05:10.093 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.2, facts=[This comment consists of the word 'First!', The comment appears on a new product video, The comment does not contain substantive content]
2025-10-13 23:05:10.093 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides differ in preference for tabs vs spaces, The choice between tabs and spaces is subjective]
2025-10-13 23:05:10.093 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.1, facts=[This comment consists of the word 'First!', The comment appears on a new product video, The comment does not contain substantive content]
2025-10-13 23:05:10.093 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment states that a claim lacks evidence, The comment is responding to a bold performance claim, The comment expresses skepticism about evidence supporting a claim]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, The choice between tabs and spaces is subjective and depends on team conventions]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides vary in preference for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.1, facts=[This comment consists of the word 'First!', The comment appears on a YouTube video about a new product, The comment expresses no substantive content about the product]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment states that something violates community rules, The comment is a generic statement about rule violations, No specific content is described in the comment]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d529f800, platform=Twitter, type=opinion, conf=0.8, trust=0.3, facts=[The comment expresses disagreement with someone's understanding of statistics]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f8604760, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for benchmarking methodology, The comment does not make factual claims about benchmarking, The comment is subjective in nature]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a YouTube video about a new release walkthrough]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=45bb11f3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[User expressed appreciation for a tutorial, Comment was posted in context of Docker networking guide]
2025-10-13 23:05:10.094 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a88e8e1f, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests a source for a 10x improvement claim, The context indicates someone made a 10x speedup claim, The comment does not make a factual assertion itself]
2025-10-13 23:05:10.096 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a10338c7, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment states that a claim lacks evidence, The comment is responding to a bold performance claim, The comment expresses skepticism about evidence supporting a claim]
2025-10-13 23:05:10.096 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9e89bdf, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting source code address, Video description appears to lack a link, Comment is a simple request for information]
2025-10-13 23:05:10.096 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=84456f9b, platform=Reddit, type=opinion, conf=0.9, trust=0.3, facts=[This comment states that something violates community rules, The comment does not specify what content is being referenced, The comment makes a claim about rule violation without providing evidence]
2025-10-13 23:05:10.096 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[User reports bot replies flooding a thread, Platform is Twitter, Context mentions suspicious activity]
2025-10-13 23:05:10.097 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[The comment is a request for presentation materials]
2025-10-13 23:05:10.097 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude, The comment describes the response as clear and concise, The comment is a response to a configuration issue resolution]
2025-10-13 23:05:10.097 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 23:05:10.097 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, type=opinion, conf=0.95, trust=0.1, facts=[This comment solicits cryptocurrency transfers, The promise of doubling funds is a common scam tactic, No legitimate service offers guaranteed cryptocurrency doubling]
2025-10-13 23:05:10.098 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests removal of an off-topic advertisement., The comment is posted in a thread about model interpretability., The comment is directed at forum moderators.]
2025-10-13 23:05:10.098 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:10.098 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:10.099 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:10.099 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:10.099 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , '']
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive, The comment violates professional code review norms]
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks constructive feedback, The comment violates professional code review norms]
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive feedback, The comment violates professional code review norms]
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive, The comment violates professional code review norms]
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Legitimate giveaways don't require sending money first, Such promises of doubling money are fraudulent]
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive feedback, The comment violates professional code review etiquette]
2025-10-13 23:05:10.100 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Legitimate giveaways do not require sending money first, Such promises of doubling money are financially impossible to sustain]
2025-10-13 23:05:10.101 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Legitimate giveaways do not require sending money first, Such promises of doubling money are financially impossible to sustain]
2025-10-13 23:05:10.101 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Scammers promise to double cryptocurrency sent to them, These schemes result in permanent loss of funds for victims]
2025-10-13 23:05:10.101 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=95b284eb, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests moderator removal of an off-topic advertisement]
2025-10-13 23:05:10.101 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=fe7e89fc, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment is requesting presentation materials from a conference talk upload]
2025-10-13 23:05:10.102 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c064ad61, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , '']
2025-10-13 23:05:10.102 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c15a1fb8, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude, The comment describes the response as clear and concise, The comment is a response to a config issue resolution]
2025-10-13 23:05:10.102 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a7f81f33, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[User reports bot replies flooding thread, Context indicates suspicious activity, Platform is Twitter]
2025-10-13 23:05:10.102 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The comment claims results are cherry-picked]
2025-10-13 23:05:10.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, type=opinion, conf=0.9, trust=0.9, facts=[This is a moderator response, The comment expresses gratitude, The comment acknowledges clarification]
2025-10-13 23:05:10.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims Section 3 math is wrong, This is a critique of a paper summary, The statement is subjective without specific evidence]
2025-10-13 23:05:10.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Overlapping confidence intervals indicate potential lack of statistical significance between compared groups]
2025-10-13 23:05:10.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, type=opinion, conf=0.9, trust=0.2, facts=[The comment expresses negative sentiment, The comment lacks constructive feedback, The comment provides no specific criticism]
2025-10-13 23:05:10.103 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, type=fact, conf=0.9, trust=0.95, facts=[The dataset link provided in the forum post is broken, The link does not resolve to a valid resource, Users cannot access the dataset through the provided link]
2025-10-13 23:05:10.104 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, type=opinion, conf=0.95, trust=0.9, facts=[User posted content containing a slur, The comment violates community guidelines against hate speech, Slurs constitute toxic behavior in online platforms]
2025-10-13 23:05:10.104 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=cf7592ba, platform=Reddit, type=opinion, conf=0.9, trust=0.9, facts=[This is a moderator response expressing gratitude]
2025-10-13 23:05:10.104 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b0f15b0d, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The user claims the results are cherry-picked]
2025-10-13 23:05:10.104 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=5367e6a5, platform=Forum, type=fact, conf=0.9, trust=0.8, facts=[Confidence intervals overlapping indicates no statistically significant difference between groups]
2025-10-13 23:05:10.106 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=90f74847, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The comment claims Section 3 contains mathematical errors, This is a critique of a paper summary, The comment provides no specific mathematical evidence]
2025-10-13 23:05:10.107 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8462d113, platform=Reddit, type=opinion, conf=0.95, trust=0.9, facts=[User posted content containing a slur, Slurs violate community guidelines, Moderators can take action against rule violations]
2025-10-13 23:05:10.107 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=6245232a, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment expresses negative sentiment, The comment lacks constructive feedback, The comment provides no specific criticism]
2025-10-13 23:05:10.107 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=866e8221, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset link provided in the forum post is broken, The user reported being unable to access the dataset, Reproduction steps were provided alongside the broken link report]
2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0b5caf98-1555-416a-9eb5-bde1f5c4299b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.220 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f6d6bf8-f05d-4f4d-952e-0b3d38fd251e","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b78b17d5-c989-421b-a821-2ce0aa97c132","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"90215d04-bb6d-464e-acb1-0e7b9e58e77c","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.220 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7c6a4d0-92a4-4b9b-88b3-b88fea05f2b8","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-chat","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5daf1b98-5c0e-4241-b726-eb0f8de11553","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"06f5109d-82a7-4369-b58f-98a3d649352c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.213 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"36b77cb6-1873-4b23-af79-0eba9dd47d73","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4695c4c6-b423-491b-afc0-5be05cce2fd4","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b552efad-91d0-4653-8967-fd7e32170ac0","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2b9c0a71-5a6f-4260-b5c6-9c06d544d3d6","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.220 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7ba9f5ce-1f6d-49a3-ba31-23372147ad97","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.213 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cff094e6-507f-4c46-8b11-d2395942c492","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","creat...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.220 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"cce4ba6c-742a-42aa-93fc-d49aa5fda649","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.220 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a1f0ce6b-6771-4b92-aeb4-61e1c9adeb1d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.212 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9dde89df-8b52-434d-ad6d-77bfd32b7e8b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.230 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d8f2d461-c7ee-4561-901d-bcedb8621054","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.229 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4a6234ca-633f-48b5-ab34-a646ed8a2d59","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.229 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49ce82b2-e529-4572-9f0b-60c416a1873a","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"deeps...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.229 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fe63aac6-691c-491d-b8c0-95d1127e31fb","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.229 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4dc6ead6-2cb2-4afd-85c8-f464a7d30aab","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.230 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b4dba9a1-24d8-4ad3-9cac-387149d1711a","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.230 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"44ee5d32-69e4-444b-84a4-efbc3a3d2df1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.238 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d80c7dd0-104f-47d9-b17e-0afdb2d450f2","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"61b3c210-c723-4389-8038-7bf748e40e05","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"250ef572-bc17-45b0-bb69-360ed89eabae","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e86ee1b3-b072-4f2d-ab46-9d3eb4296e61","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"400478de-2529-4b97-8265-5de26e49f02b","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"de...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.239 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f6e76aa1-5c48-47aa-9a7e-36b78e3e59a4","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.240 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d7067b14-d740-47be-813f-812f7c7a68cb","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.240 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c8e3a661-5803-492d-8edd-0f56d0263023","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4bde9add","platform":"Twitter","language":"en","text":"Hot take: tabs > spaces.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.240 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1ab31aec-e632-4b60-89ca-9c2a91243365","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d706f91","platform":"YouTube","language":"en","text":"First!","context":"New product video.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.243 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"abfc3123-8a55-4c55-9eff-e18dc70e06e5","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.292 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"27114458-856a-41a3-a417-5d47ddaa391e","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"c178f635","platform":"Twitter","language":"en","text":"Giveaway: send me crypto to double!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.292 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5d519dd8-9235-4abf-9115-9f43d1169b34","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.292 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"8200c528-d3d8-4600-915e-480795f6e0d1","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"open...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.293 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"494653d8-0994-4587-a06f-86fd1939d7cc","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"4e8e8b25","platform":"YouTube","language":"zh","text":"","context":"XX","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"202...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.295 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1272ea59-1ce4-41a0-90d7-0c5e5347a7f6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"f9b07824","platform":"Reddit","language":"en","text":"Personal attack, not constructive.","context":"Code review thread.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deep...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.308 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1879c3a6-0377-4b25-9515-3403c15577af","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.308 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f07ed24b-006e-495f-aa26-c3feb5819971","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"eab53364","platform":"Reddit","language":"en","text":"Source?","context":"OP claims big improvement.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4o-mini","cre...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.308 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b1144e25-6719-4033-8aaf-480c52f6f2ce","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"4b2d7c08","platform":"YouTube","language":"zh","text":"","context":"Java ","region":"CN","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.338 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"97c5acc5-1693-4520-9a06-3bb7a513b3c6","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-chat"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ca7745b9-7066-47c6-be88-89cd366254f5","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"7226e493-13b5-4ec9-8298-6519b92783db","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"ef4fd9bd-95ba-4526-b39a-476dc5744ca1","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","c...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"25c48b7b-5407-438a-a97b-00adbc88b71b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"da2212e4-ed9f-4f17-82a0-1b69cd45765c","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f181b28b-8a10-4774-8787-ee79f313fad5","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"63bb9e23-9f12-4a9d-b798-a536d6afe569","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"355aed09","platform":"Forum","language":"en","text":"Buy cheap followers at spammy.site","context":null,"region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","create...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"3929a0bc-388a-4e18-bec9-1e16d5a6f755","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.339 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f1288b5f-fa60-4a01-90e5-2565f61b5818","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.339 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5bfcdeb0-a769-4367-b97c-246b93d05f7f","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.339 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5378bb8e-d8a7-4e8e-9283-f00b65b18379","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"37d7b13d-e050-4aff-a518-ce84a923ea75","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.310 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"d488082a-2590-46c1-94bd-2ae9f8463cb3","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"22aa5e6b","platform":"Reddit","language":"en","text":"This benchmark is cherry-picked.","context":"Model X vs Y.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"49181ded-eb9b-492c-a75a-13e6de16f1ef","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.311 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1388b658-fd2b-4247-b69c-ef60d6e8db10","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.312 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eab2df4d-223c-43f0-8100-ed3ad7e49d2b","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdA...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"4c5791e6-f63f-49df-86e1-544099abe1aa","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.341 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9c165839-840e-486f-a9a3-a3cf7cbde096","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat",...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.312 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"bb0c720a-eddc-4566-a38c-c6497c82f3ff","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.312 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"944b0f79-8615-4875-91ed-df56654baaf7","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"518d7dd2","platform":"Reddit","language":"en","text":"I totally disagree with this.","context":"Thread about AI ethics.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":48,"llmApi":"opena...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.312 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b2d8f693-8d28-4487-85ba-e015b950f224","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"7d0f1d71","platform":"Twitter","language":"en","text":"You are wrong and ignorant.","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.312 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"0fc78c89-defc-4fe2-a67b-04cec1fcd246","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"c951a2fe","platform":"Forum","language":"en","text":"Performance improved by 30% (proof).","context":"Attached benchmark link.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":24,"llmApi"...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.313 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"fb4f6a9c-c2bf-4433-8d8e-f3c130f89001","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c494b7bd","platform":"Reddit","language":"en","text":"Report: contains hate speech.","context":"He used a slur.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.313 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"1c13c745-28c1-4a5e-af9d-f6321b1fbac1","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.313 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"31803d28-539a-45d4-ae39-26269e133726","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"4ae5f89b","platform":"Reddit","language":"en","text":"Thanks for the detailed explanation!","context":"Guide about Docker.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"op...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.313 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eebe88a0-bc43-4e6c-a31d-ba32d208ecce","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"c8d440fc","platform":"Forum","language":"en","text":"Can you share the dataset link?","context":"Paper discussion.","region":"EU","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.337 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"c656f110-fc25-4134-80e8-e0d115eaa18d","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.337 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"2ac9067a-e6cd-40b4-923c-e7ea96e23f17","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.337 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"f8dcf824-e498-4d57-a76d-6bb2b1afd12e","correlationId":"corr-6896d665-5ea9-4e54-994a-3574b5186550","taskId":"task-bcf80c78-a30b-493c-9e0d-db01d036e151","commentId":"3b6e9205","platform":"Forum","language":"en","text":"This is misinformation.","context":"Claim about vaccines.","region":"US","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4o-...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"eaa5fb18-89a1-491e-a4b8-a5629715ba46","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"a6144b46-9905-4fbe-9c0c-ec993db2b954","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"368748a5-d7d5-4cb1-8bb7-f832e2d97356","correlationId":"corr-1e731853-7039-436d-8510-db6f361ef743","taskId":"task-d35ef257-4f3b-4fdf-8145-675355e34f84","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9f5e1db9-3263-4b71-a4c3-a1c9582ea77c","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"d29f683c","platform":"Forum","language":"en","text":"Mods please remove, pure spam.","context":"Off-topic ad.","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-m...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b5fc141e-750f-4dfc-ac48-2b800e138788","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4o-mini","createdAt":"20...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.340 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"e0fe3ea4-a1a1-4423-a574-9f397b33c919","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"8c755a59","platform":"Twitter","language":"en","text":"This is amazing work!","context":"","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-chat","createdAt":"2025-10...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.341 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"9ac39178-b084-4862-99b3-447680d3c9ae","correlationId":"corr-016addff-eed1-4753-b107-004d66402134","taskId":"task-b19fccdb-b7d8-466f-b7aa-eed47a63901a","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"openai:gpt-4...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: OPENAI:GPT-4O-MINI
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.341 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"5c1371d9-2595-4a72-a2ab-619dba9be21f","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6c6528bd","platform":"Reddit","language":"en","text":"The math in section 3 is wrong.","context":"Paper summary.","region":"EU","requiresFreshEvidence":true,"freshnessWindowHours":72,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:10.341 [vf-] ERROR c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] processing failed. raw={"version":"req.v1","eventId":"b3c3d87c-4e85-4bba-a846-fb104ee9d6e4","correlationId":"corr-f937a4d0-3974-424b-834b-0c1c434e7eee","taskId":"task-1645feff-79a8-473d-bfbf-6b6f7509b7c0","commentId":"6b59be10","platform":"YouTube","language":"en","text":"Click this link for free gift!","context":"Random comment","region":"US","requiresFreshEvidence":false,"freshnessWindowHours":0,"llmApi":"deepseek-cha...(truncated), err=java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT

java.lang.RuntimeException: DO NOT SUPPORT THIS LLM RIGHT NOW: DEEPSEEK-CHAT
	at com.echofilter.commons.enums.ModelAPI.lambda$fromString$0(ModelAPI.java:19)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.echofilter.commons.enums.ModelAPI.fromString(ModelAPI.java:15)
	at com.echofilter.lowerLevel.infrastructure.modules.factories.LLMApiFactory.getLLMApi(LLMApiFactory.java:27)
	at com.echofilter.lowerLevel.infrastructure.modules.service.Impl.CommentAnalysisServiceImpl.getCommentResult(CommentAnalysisServiceImpl.java:30)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.handleOne(MLRequestListener.java:53)
	at com.echofilter.lowerLevel.infrastructure.messaging.kafka.consumer.MLRequestListener.lambda$onMessage$0(MLRequestListener.java:36)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.lang.VirtualThread.run(VirtualThread.java:329)

2025-10-13 23:05:18.119 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c7c24514-c30f-4541-ac6b-000e3f5c60a1, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 23:05:18.130 [vf-] INFO  o.a.k.c.producer.ProducerConfig - trace= tenant= user= ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [81.70.198.98:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-13 23:05:18.130 [vf-] INFO  o.a.k.c.t.i.KafkaMetricsCollector - trace= tenant= user= initializing Kafka metrics collector
2025-10-13 23:05:18.142 [vf-] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-13 23:05:18.154 [vf-] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka version: 3.9.1
2025-10-13 23:05:18.154 [vf-] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka commitId: f745dfdcee2b9851
2025-10-13 23:05:18.154 [vf-] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= Kafka startTimeMs: 1760411118154
2025-10-13 23:05:18.271 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2ab16530-5e1b-48a5-9609-f2a5b1dd195d, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses a positive opinion about work"],"trustScore":0.8}
2025-10-13 23:05:18.517 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=192d480c-77cb-4379-99cf-df55d826b5f3, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=cf7592ba, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a moderator response","The comment expresses gratitude","The comment acknowledges clarification"],"trustScore":0.9}
2025-10-13 23:05:18.691 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=82bacb3c-845b-4263-b774-a0728f075ba9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b199fee4, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a demo","The comment contains positive sentiment","The comment is a brief social media interaction"],"trustScore":0.8}
2025-10-13 23:05:18.706 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6adde89d-0700-4107-aa1e-535cdbbc355f, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 23:05:18.742 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=854926d5-e5c8-412b-815a-a2e1ad863bef, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d54b596e, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is asking about dataset download location"],"trustScore":0.8}
2025-10-13 23:05:18.758 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3d9debe4-ff21-42c8-8985-b85827f3b4ea, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=529d023c, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for content","The comment indicates learning occurred","The comment is positive in tone"],"trustScore":0.8}
2025-10-13 23:05:18.824 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9d7a06fa-9576-4ba0-833c-e1abda5eb84c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 23:05:18.911 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7fb800e1-3bc4-4164-b96b-c436d8babdd9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 23:05:18.923 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79a45c71-22dd-4935-8f2b-111e52b9049f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["",""],"trustScore":0.8}
2025-10-13 23:05:18.923 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62d6988c-150d-40ba-9ad1-ad40d7a47a65, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link"],"trustScore":0.8}
2025-10-13 23:05:18.937 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49f1e148-9e8d-426b-839d-b9ff3fb9b984, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for a tutorial","The comment indicates the tutorial was helpful","The comment is positive feedback"],"trustScore":0.8}
2025-10-13 23:05:18.963 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dd8d9ef-3816-46cf-a232-05de8f7903f6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 23:05:18.972 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c0353cbc-15e3-47db-8e55-6c1834d000e1, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 23:05:19.034 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=51ed5585-4a67-4948-8e65-2584d8ea4689, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial"],"trustScore":0.8}
2025-10-13 23:05:19.080 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0dbea503-66f8-4837-bb4e-bfc4ac42c010, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive sentiment about unspecified work"],"trustScore":0.8}
2025-10-13 23:05:19.122 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - trace= tenant= user= [Producer clientId=producer-1] Cluster ID: Some(5L6g3nShT-eMCtK--X86sw)
2025-10-13 23:05:19.123 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - trace= tenant= user= [Producer clientId=producer-1] ProducerId set to 1007 with epoch 0
2025-10-13 23:05:19.123 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24ad2bf1-a6f2-49ec-95cc-9a31416bf606, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment is a request for presentation materials"],"trustScore":1.0}
2025-10-13 23:05:19.177 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f998ab15-ba4a-4adc-8071-38555397d04f, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 23:05:19.178 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=59e96b51-60eb-4284-a169-66ddc07d811f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The commenter states the video helped them pass an exam"],"trustScore":0.8}
2025-10-13 23:05:19.180 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2cd5e94f-c4bc-43d0-8df9-4741cc40e283, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=1579238, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests citation of sources for a medical claim."],"trustScore":0.8}
2025-10-13 23:05:19.208 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0a28a844-5c5c-461b-b8cb-6abbebe76631, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d529f800, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses disagreement with someone's understanding of statistics"],"trustScore":0.3}
2025-10-13 23:05:19.211 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a71964d9-3543-43a5-b125-71be3808d163, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["User is requesting a dataset link"],"trustScore":0.8}
2025-10-13 23:05:19.234 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=94a47078-8d3a-4907-b714-b3ae8e28d8ff, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c064ad61, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This is a positive opinion about a Kubernetes tutorial"],"trustScore":0.8}
2025-10-13 23:05:19.238 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5476821e-762c-432a-ad04-fab1bc630d43, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f8604760, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for benchmarking methodology"],"trustScore":0.8}
2025-10-13 23:05:19.281 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a2ac4c43-cb3e-4275-a819-484461c2a95c, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=fe7e89fc, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment is requesting presentation materials from a conference talk"],"trustScore":0.8}
2025-10-13 23:05:19.282 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=99e75624-b3b2-4829-8120-9e668c880f4c, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=47ae4eb2, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment requests timestamps for a long-form interview video"],"trustScore":0.8}
2025-10-13 23:05:19.301 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=016b4879-0453-4b38-b1ce-23ff1badf8dd, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a paper discussion context","The platform is a forum"],"trustScore":0.8}
2025-10-13 23:05:19.303 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=89ab3a8b-6fba-4f99-aba7-5ae6928a861c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for content","The comment indicates learning occurred","The comment is positive in tone"],"trustScore":0.8}
2025-10-13 23:05:19.320 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d6c76da0-0130-44d2-97be-45da6ba31ee6, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d153d2dd, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment requests subtitles for a technical lecture replay"],"trustScore":1.0}
2025-10-13 23:05:19.391 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=702fdbeb-c456-4dab-bcb3-34c5b0d97152, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=96a0805b, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The commenter states the video helped them pass an exam"],"trustScore":0.7}
2025-10-13 23:05:19.407 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=60b40d7e-ce1c-48eb-89c3-302b090b1260, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude","The comment describes the response as clear and concise"],"trustScore":0.8}
2025-10-13 23:05:19.427 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d2045139-3329-4cd2-828c-fe3d79bf6441, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a moderator response","The comment expresses gratitude","The comment acknowledges clarification"],"trustScore":0.9}
2025-10-13 23:05:19.436 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7f7c1466-e612-4c02-86c2-26faf54c21f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, result={"type":"opinion","confidence":1.0,"facts":["The comment is requesting timestamps for a long-form interview video"],"trustScore":1.0}
2025-10-13 23:05:19.614 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=148f9ccb-96e1-4731-9e7f-77b26f267416, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'"],"trustScore":0.5}
2025-10-13 23:05:19.619 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19048caa-ff6b-433b-8f5f-3bdd2a0ad93b, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b0f15b0d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The user claims the results are cherry-picked"],"trustScore":0.3}
2025-10-13 23:05:19.642 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f229f4ce-f7b1-45f8-955a-ee3f45b7e62c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","Kubernetes",""],"trustScore":0.8}
2025-10-13 23:05:19.656 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b87039b1-0ad4-469d-a01c-770618591bb4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment was posted on a new product video"],"trustScore":0.8}
2025-10-13 23:05:19.663 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f4fbfe13-3dbb-42b3-9c4a-870933064550, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bd5efba3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a duplicate post request","The user is asking for thread merging","The comment is procedural in nature"],"trustScore":0.8}
2025-10-13 23:05:19.711 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b0210ff5-7b9c-4b55-b840-b13753b57c2f, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=526b75ee, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a promotional link","The link directs to a service selling followers","The website domain appears untrustworthy"],"trustScore":0.1}
2025-10-13 23:05:19.713 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f6a0f493-05ae-445e-a02f-fe4400052d76, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["JSON is a data interchange format","YAML is a data serialization language","Both JSON and YAML are used in software development"],"trustScore":0.8}
2025-10-13 23:05:19.744 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6625f772-0654-45f6-987b-f42ad7c173f9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ab00e62d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The model card lacks evaluation details"],"trustScore":0.7}
2025-10-13 23:05:19.753 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2f2b557b-5f40-428d-9494-07663e14fc1d, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 25%"],"trustScore":0.7}
2025-10-13 23:05:19.755 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=06c51f49-f8a2-428b-b9eb-f6a3fc19ee9f, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","The choice between tabs and spaces is subjective and varies by team/individual"],"trustScore":0.8}
2025-10-13 23:05:19.916 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=277f8c6d-90fa-4cce-863b-5b13596cfcf4, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is requesting a dataset link","This is a question about data sharing","The context is a paper discussion"],"trustScore":0.8}
2025-10-13 23:05:19.939 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b963e393-db2c-460f-9b86-13d24340e860, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 23:05:19.951 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19d654be-6563-4c9d-ac96-c5d60ec50380, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citation of sources","The comment appears in a forum context","The comment is related to a medical claim"],"trustScore":0.7}
2025-10-13 23:05:19.977 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a9ff59a2-bc76-47c0-a8af-0912a726a346, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The user claims the results are cherry-picked"],"trustScore":0.3}
2025-10-13 23:05:19.979 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdea544e-14be-4c04-9d17-1bc87024fed8, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement","The comment does not provide specific factual claims","The comment is a personal viewpoint"],"trustScore":0.7}
2025-10-13 23:05:19.985 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=75de2176-a96d-4174-b032-3d61b6220e4a, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=95b284eb, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["Comment requests removal of content","Comment contains 'off-topic ad' reference","Comment is directed at moderators"],"trustScore":0.3}
2025-10-13 23:05:19.988 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8230466c-a214-4f01-a5f0-c7f1cdc8e44c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses disagreement with another user's understanding of statistics"],"trustScore":0.3}
2025-10-13 23:05:20.004 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=236aecee-ddab-46f6-99ca-5424273ad97a, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' appears in the comment","The comment contains no substantive content beyond promotional messaging"],"trustScore":0.1}
2025-10-13 23:05:20.004 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62b74d65-deef-49c2-a40e-c07722d28ddd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The model card lacks evaluation details"],"trustScore":0.7}
2025-10-13 23:05:20.009 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cdd0779d-c0a8-4ced-9394-834f4a768528, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["This is a duplicate post request","The user is asking to merge similar threads","This is a common moderation action on Reddit"],"trustScore":0.8}
2025-10-13 23:05:20.028 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=03bb3a84-27cc-444e-aab5-2ba43fea1edf, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["This comment references community rules","The comment does not specify which rules were violated","The comment is a general statement about rule violation"],"trustScore":0.5}
2025-10-13 23:05:20.063 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c0cd360-879b-49ec-958d-b290e580c2d9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=45bb11f3, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["User expressed appreciation for a tutorial","Comment was posted in context of Docker networking guide","Comment contains positive sentiment"],"trustScore":0.8}
2025-10-13 23:05:20.073 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0014d772-1c46-4f6a-b12b-bc80b52656b7, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement"],"trustScore":0.7}
2025-10-13 23:05:20.104 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=643d7c3a-1214-4084-84dd-a50cbd3a009d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about Java virtual threads tutorial","Comment indicates tutorial was clearly explained","Comment shows viewer appreciation for educational content"],"trustScore":0.8}
2025-10-13 23:05:20.141 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b51c8516-5bff-4faa-9d09-1b50652da06a, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation","The context involves a guide about Docker","The comment contains no substantive claims about Docker"],"trustScore":0.8}
2025-10-13 23:05:20.150 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=caeab287-c0a5-4ab9-8a9c-3d1c584a204f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["User is requesting source code address","Video description appears to lack a link","Comment is a simple inquiry"],"trustScore":0.8}
2025-10-13 23:05:20.157 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d9ae8151-7d58-45a6-91dc-2ae926012fde, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests moderator removal","The comment is labeled as 'pure spam'","The comment is an off-topic advertisement"],"trustScore":0.1}
2025-10-13 23:05:20.158 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=070b6d14-126a-4aad-a74b-53ac7bc18b01, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a10338c7, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment states that a claim lacks evidence","The comment is responding to a bold performance claim","The comment expresses skepticism about evidence supporting a claim"],"trustScore":0.7}
2025-10-13 23:05:20.180 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bb00bdd7-c982-445e-9cc3-e9eedd6ccd37, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["Comment expresses positive feedback about Java virtual threads tutorial","Comment indicates tutorial was clearly explained","Comment shows viewer appreciation for educational content"],"trustScore":0.8}
2025-10-13 23:05:20.183 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b39fa1f3-781c-4ceb-bc6d-8d4654962e52, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c15a1fb8, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude","The comment describes a response as clear and concise","The comment acknowledges assistance with a config issue"],"trustScore":0.8}
2025-10-13 23:05:20.193 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=19ccfc8c-3229-4298-bc81-c7acbd779121, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User reports bot replies flooding a thread","Platform is Twitter","Context mentions suspicious activity"],"trustScore":0.7}
2025-10-13 23:05:20.199 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1f9de0b6-ff90-4828-9566-ccea63ed2af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper"],"trustScore":0.5}
2025-10-13 23:05:20.202 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=52d07cc9-1cef-49b5-a06a-90d267f7c4aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["Comment requests removal","Comment is off-topic","Comment contains no substantive content"],"trustScore":0.1}
2025-10-13 23:05:20.230 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=05d824d4-83f6-404a-bc10-b617332d2348, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 23:05:20.252 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9545cb66-774e-4537-9995-768fe7ca5472, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'"],"trustScore":0.5}
2025-10-13 23:05:20.259 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0ba93b4d-2927-4dda-821f-4ee669536098, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment requests citations for a health claim","The comment does not make any factual assertions itself","The comment is seeking verification of information"],"trustScore":0.7}
2025-10-13 23:05:20.286 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eeaa421d-6448-445c-b598-025575e5a5d8, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["Tabs and spaces are both used for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 23:05:20.286 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fa3b96cb-19f9-443d-be76-4e762ec67c6a, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=67bc6e0d, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["JSON is a data interchange format","YAML is a data serialization language","Both JSON and YAML are used in software development"],"trustScore":0.8}
2025-10-13 23:05:20.311 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=07dc37df-6e0e-4870-b1b7-e1c76e0772f4, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=84456f9b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["This comment states that something violates community rules","The comment does not specify what content is being referenced","The comment makes a general claim about rule violation"],"trustScore":0.3}
2025-10-13 23:05:20.312 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=76e8c239-3365-4431-a207-f6bd93f9c378, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 23:05:20.324 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8f25704b-2a89-441c-a23f-89914d159160, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9e89bdf, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["User is requesting source code address","Video description appears to lack link","Comment is a simple request for information"],"trustScore":0.8}
2025-10-13 23:05:20.324 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=480c4bb4-bd24-40ea-b9c3-1058bd0736ce, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses skepticism about data presentation","The comment suggests potential bias in chart selection","The comment compares Model A favorably in the presented data"],"trustScore":0.6}
2025-10-13 23:05:20.334 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=00d73cce-8e9c-484b-8a9c-29a27a9feac6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment offers a free gift without context","This is a common spam tactic on YouTube","Such comments often lead to phishing or scams"],"trustScore":0.1}
2025-10-13 23:05:20.374 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=16
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=17
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=18
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=19
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=20
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=21
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=22
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=23
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=20
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=6
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=32
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=33
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=34
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=35
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=36
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=37
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=38
2025-10-13 23:05:20.375 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=13
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=14
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=15
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=13
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=14
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=16
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=17
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=18
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=19
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=20
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=21
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=22
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=26
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=27
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=28
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=29
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=30
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=31
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=25
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=26
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=27
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=28
2025-10-13 23:05:20.376 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=29
2025-10-13 23:05:20.377 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=14
2025-10-13 23:05:20.377 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=15
2025-10-13 23:05:20.377 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=16
2025-10-13 23:05:20.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=23
2025-10-13 23:05:20.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=15
2025-10-13 23:05:20.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=39
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=24
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=25
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=26
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=27
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=21
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=7
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=32
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=33
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=34
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=30
2025-10-13 23:05:20.379 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=17
2025-10-13 23:05:20.402 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8ddd3064-7111-4b76-ac55-7d393b6ae2ff, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a promotional link","The link directs to a service selling followers","The domain name appears unprofessional"],"trustScore":0.1}
2025-10-13 23:05:20.414 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8757baf6-b7d0-4b24-b640-8b8994332770, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["Confidence intervals overlapping indicates no statistically significant difference between groups"],"trustScore":0.8}
2025-10-13 23:05:20.427 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6ed0d646-4885-4829-872c-84e728387ebc, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests removal by moderators.","The comment is identified as off-topic advertising.","The comment contains no substantive content."],"trustScore":0.1}
2025-10-13 23:05:20.431 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f23a95ea-e397-428c-81bc-9dea4af79366, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["Comment requests removal of off-topic ad","Comment is posted in thread about model interpretability","Comment does not contribute to thread topic"],"trustScore":0.3}
2025-10-13 23:05:20.441 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=81e715a6-8d50-41af-9979-37a925ff638e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%"],"trustScore":0.7}
2025-10-13 23:05:20.444 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ca2b61d-548c-4e54-8fb9-e780a290d678, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 23:05:20.463 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67f9d2ff-cbad-4598-b2ef-0bf9937ea6af, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses appreciation for benchmarking methodology","The comment does not contain verifiable factual claims","The comment is a subjective evaluation of content"],"trustScore":0.8}
2025-10-13 23:05:20.480 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95fdc418-ce31-4b0c-b279-547b2b6d4455, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' appears to be associated with artificial engagement","Purchased followers typically violate platform terms of service"],"trustScore":0.1}
2025-10-13 23:05:20.480 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5651855f-cf54-4b58-9a6c-a58104332082, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment was posted on a YouTube video about a new release walkthrough"],"trustScore":0.8}
2025-10-13 23:05:20.484 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4c1b56fe-5561-461e-8c2e-482f35b0fe7c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment requests moderator removal","The comment is labeled as 'pure spam'","The comment is an off-topic advertisement"],"trustScore":0.1}
2025-10-13 23:05:20.491 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=047bd9aa-1a72-47c3-a244-afea1e50ebef, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a7f81f33, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["User reports bot replies flooding a thread","Platform is Twitter","Context indicates suspicious activity"],"trustScore":0.7}
2025-10-13 23:05:20.492 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d36c2c30-ac4a-4e33-95bd-4ec730bfe752, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation.","The context is a guide about Docker.","The comment does not contain factual claims or opinions about Docker."],"trustScore":1.0}
2025-10-13 23:05:20.543 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=576d5948-13a4-4ad8-927a-09cd22eda1db, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The website domain 'spammy.site' suggests low-quality content","Purchased followers violate platform terms of service"],"trustScore":0.1}
2025-10-13 23:05:20.545 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b0b86aa6-09a6-4c9f-8007-8d6e84f3567e, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["Comment requests removal by moderators","Comment contains the word 'spam'","Comment lacks substantive content"],"trustScore":0.1}
2025-10-13 23:05:20.550 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=32b328b6-f782-4aca-b1ed-abfec4bb8f61, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=5367e6a5, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Confidence intervals overlapping indicates no statistically significant difference between groups"],"trustScore":0.9}
2025-10-13 23:05:20.552 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=62c8e179-90a1-40dd-b7da-3cf89f0d40a9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f7c81544, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.8}
2025-10-13 23:05:20.554 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=55d9b0ea-0e9c-4fc2-a777-a4814ce312c6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, result={"type":"opinion","confidence":0.7,"facts":["The comment requests proof for a claimed state-of-the-art achievement","The comment references a leaderboard screenshot as context","The comment expresses skepticism about an unverified claim"],"trustScore":0.6}
2025-10-13 23:05:20.617 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb361d89-44fc-47aa-b0fe-68c67b45b120, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper"],"trustScore":0.5}
2025-10-13 23:05:20.618 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=529d023c, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for content, The comment indicates learning occurred, The comment is positive in tone]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f7c81544, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, ]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=96a0805b, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The commenter states the video helped them pass an exam]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=529d023c, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for content, The comment indicates learning occurred, The comment is positive in tone]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=96a0805b, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[The commenter states the video helped them pass an exam]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 23:05:20.619 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ab00e62d, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The model card lacks evaluation details]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bd5efba3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[This is a duplicate post request, The user is asking for thread merging, The comment is procedural in nature]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses a positive opinion about work]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=8c755a59, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive sentiment about unspecified work]
2025-10-13 23:05:20.620 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=1579238, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests citation of sources for a medical claim.]
2025-10-13 23:05:20.621 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=aa177b64, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 25%]
2025-10-13 23:05:20.621 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b199fee4, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for a demo, The comment contains positive sentiment, The comment is a brief social media interaction]
2025-10-13 23:05:20.621 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d153d2dd, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[Comment requests subtitles for a technical lecture replay]
2025-10-13 23:05:20.621 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=526b75ee, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a promotional link, The link directs to a service selling followers, The website domain appears untrustworthy]
2025-10-13 23:05:20.622 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d54b596e, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is asking about dataset download location]
2025-10-13 23:05:20.622 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 23:05:20.622 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link]
2025-10-13 23:05:20.622 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link]
2025-10-13 23:05:20.622 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting a dataset link]
2025-10-13 23:05:20.622 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=47ae4eb2, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment requests timestamps for a long-form interview video]
2025-10-13 23:05:20.623 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a paper discussion context, The platform is a forum]
2025-10-13 23:05:20.623 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=47ae4eb2, platform=YouTube, type=opinion, conf=1.0, trust=1.0, facts=[The comment is requesting timestamps for a long-form interview video]
2025-10-13 23:05:20.623 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=67bc6e0d, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[JSON is a data interchange format, YAML is a data serialization language, Both JSON and YAML are used in software development]
2025-10-13 23:05:20.623 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=45bb11f3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for a tutorial, The comment indicates the tutorial was helpful, The comment is positive feedback]
2025-10-13 23:05:20.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=d529f800, platform=Twitter, type=opinion, conf=0.8, trust=0.3, facts=[The comment expresses disagreement with someone's understanding of statistics]
2025-10-13 23:05:20.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f8604760, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for benchmarking methodology]
2025-10-13 23:05:20.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.5, facts=[This comment consists of the word 'First!']
2025-10-13 23:05:20.630 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=28
2025-10-13 23:05:20.631 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment was posted on a new product video]
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=22
2025-10-13 23:05:20.631 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c6c5b504-43cd-47ca-b251-3a76743c4566, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","The comment lacks substantive content"],"trustScore":0.1}
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=23
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=24
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=40
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=41
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=42
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=43
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=16
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=24
2025-10-13 23:05:20.631 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, The choice between tabs and spaces is subjective and varies by team/individual]
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=35
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=36
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=37
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=38
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=39
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=40
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=41
2025-10-13 23:05:20.631 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=fe7e89fc, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[The comment is a request for presentation materials]
2025-10-13 23:05:20.631 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=31
2025-10-13 23:05:20.632 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=32
2025-10-13 23:05:20.632 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c064ad61, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This is a positive opinion about a Kubernetes tutorial]
2025-10-13 23:05:20.632 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=fe7e89fc, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment is requesting presentation materials from a conference talk]
2025-10-13 23:05:20.632 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c15a1fb8, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude, The comment describes the response as clear and concise]
2025-10-13 23:05:20.632 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=c064ad61, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, Kubernetes, ]
2025-10-13 23:05:20.632 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=cf7592ba, platform=Reddit, type=opinion, conf=0.9, trust=0.9, facts=[This is a moderator response, The comment expresses gratitude, The comment acknowledges clarification]
2025-10-13 23:05:20.633 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=cf7592ba, platform=Reddit, type=opinion, conf=0.9, trust=0.9, facts=[This is a moderator response, The comment expresses gratitude, The comment acknowledges clarification]
2025-10-13 23:05:20.633 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b0f15b0d, platform=Reddit, type=opinion, conf=0.8, trust=0.3, facts=[The user claims the results are cherry-picked]
2025-10-13 23:05:20.643 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e3c86ce4-3f2f-4c80-b18f-a0ff5253baf8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","The improvement is measurable"],"trustScore":0.7}
2025-10-13 23:05:20.643 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd42c12-58bb-4dff-ad4a-5473819273a3, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style preferences vary among developers","Some languages have official style guides recommending specific indentation"],"trustScore":0.8}
2025-10-13 23:05:20.655 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=16
2025-10-13 23:05:20.657 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6497c0ba-6b98-4d6f-b5b4-68894dadc5ad, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment appears on a YouTube video about a new product","The comment expresses no substantive content"],"trustScore":0.1}
2025-10-13 23:05:20.671 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=18
2025-10-13 23:05:20.671 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c11b6f22-ddde-4ba1-ac8c-a1ab881578df, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=aa177b64, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 25%"],"trustScore":0.7}
2025-10-13 23:05:20.674 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=44
2025-10-13 23:05:20.678 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=33
2025-10-13 23:05:20.694 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8863bc1c-103d-490b-8e22-1190f71f7099, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 23:05:20.721 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=20749219-d661-4de9-9a14-ae2b9274d3f7, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses disagreement with a previous statement","The comment does not provide specific factual claims","The comment is a personal opinion"],"trustScore":0.7}
2025-10-13 23:05:20.729 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=aaa1c27f-2468-4c02-b47e-c45cccebfdc9, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=2d8aeef, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses skepticism about data presentation","The comment suggests potential bias in chart selection","The comment compares Model A favorably in the presented data"],"trustScore":0.6}
2025-10-13 23:05:20.730 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3ea118c4-6591-40c9-af3d-2d2a01fd0977, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses gratitude for a detailed explanation.","The comment is a response to a guide about Docker.","The comment contains no substantive claims about Docker."],"trustScore":1.0}
2025-10-13 23:05:20.734 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=109c7cf2-d7ee-4c59-bb86-73b199b572cb, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service for purchasing followers","The domain 'spammy.site' appears to be associated with artificial engagement","Purchased followers violate platform terms of service"],"trustScore":0.1}
2025-10-13 23:05:20.734 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eaa74604-527f-435e-b879-212c2c26fe7b, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["This comment solicits cryptocurrency transfers","It promises to double any cryptocurrency sent","This is a common scam pattern on social media"],"trustScore":0.1}
2025-10-13 23:05:20.740 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6e1ce085-5e70-479e-8832-837a2fc58454, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["This comment solicits cryptocurrency transfers","It promises to double any cryptocurrency sent","This follows common giveaway scam patterns"],"trustScore":0.1}
2025-10-13 23:05:20.744 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3b8661fa-b478-41b0-acaa-3e49f7ceb54d, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment contains a clickable link","The comment promises a free gift","This pattern is commonly used in spam campaigns"],"trustScore":0.1}
2025-10-13 23:05:20.762 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2533d0d2-769f-4771-8d9a-69dc86773f32, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["Mislabelled axes can invalidate data interpretation","Proper axis labeling is essential for valid scientific claims","Graph interpretation depends on correct axis identification"],"trustScore":0.7}
2025-10-13 23:05:20.770 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b92ac8be-4c46-41d9-8a23-66cd86ea484c, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests a source for a 10x improvement claim","The comment does not make any factual assertions itself","The comment is seeking verification of another user's statement"],"trustScore":0.7}
2025-10-13 23:05:20.778 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1553cdd3-d380-4005-bf74-566a004148a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The user is asking about dataset download location","This is a question about research resources","The context indicates this is related to paper replication"],"trustScore":0.8}
2025-10-13 23:05:20.824 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fe9fdad8-07bf-47f9-93d4-e3422c7694c8, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["Comment contains a link promising free gifts","This pattern is commonly associated with spam campaigns","Such comments often lead to phishing or malware distribution"],"trustScore":0.1}
2025-10-13 23:05:20.844 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=24a751f6-aae2-4f6e-891a-af44f51d68fd, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement, The comment does not provide specific factual claims, The comment is a personal viewpoint]
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' appears in the comment, The comment contains no substantive content beyond promotional messaging]
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ab00e62d, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The model card lacks evaluation details]
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement]
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3695f2cb, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment offers a free gift without context, This is a common spam tactic on YouTube, Such comments often lead to phishing or scams]
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[Comment expresses positive feedback about Java virtual threads tutorial, Comment indicates tutorial was clearly explained, Comment shows viewer appreciation for educational content]
2025-10-13 23:05:20.866 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[Comment expresses positive feedback about Java virtual threads tutorial, Comment indicates tutorial was clearly explained, Comment shows viewer appreciation for educational content]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=249afa42, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests citations for a health claim, The comment does not make any factual assertions itself, The comment is seeking verification of information]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=2d8aeef, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment expresses skepticism about data presentation, The comment suggests potential bias in chart selection, The comment compares Model A favorably in the presented data]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bd5efba3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[This is a duplicate post request, The user is asking to merge similar threads, This is a common moderation action on Reddit]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=1579238, platform=Forum, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests citation of sources, The comment appears in a forum context, The comment is related to a medical claim]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests moderator removal, The comment is labeled as 'pure spam', The comment is an off-topic advertisement]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment claims there is an error in section 3 of the paper]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[Comment requests removal, Comment is off-topic, Comment contains no substantive content]
2025-10-13 23:05:20.867 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, The comment lacks substantive content]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests removal by moderators., The comment is identified as off-topic advertising., The comment contains no substantive content.]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=526b75ee, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a promotional link, The link directs to a service selling followers, The domain name appears unprofessional]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude for a detailed explanation, The context involves a guide about Docker, The comment contains no substantive claims about Docker]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c8d440fc, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is requesting a dataset link, This is a question about data sharing, The context is a paper discussion]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=67bc6e0d, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[JSON is a data interchange format, YAML is a data serialization language, Both JSON and YAML are used in software development]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d529f800, platform=Twitter, type=opinion, conf=0.8, trust=0.3, facts=[The comment expresses disagreement with another user's understanding of statistics]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=84456f9b, platform=Reddit, type=opinion, conf=0.8, trust=0.5, facts=[This comment references community rules, The comment does not specify which rules were violated, The comment is a general statement about rule violation]
2025-10-13 23:05:20.868 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=45bb11f3, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[User expressed appreciation for a tutorial, Comment was posted in context of Docker networking guide, Comment contains positive sentiment]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9e89bdf, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting source code address, Video description appears to lack a link, Comment is a simple inquiry]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a10338c7, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment states that a claim lacks evidence, The comment is responding to a bold performance claim, The comment expresses skepticism about evidence supporting a claim]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.5, facts=[This comment consists of the word 'First!']
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.95, trust=0.8, facts=[Tabs and spaces are both used for code indentation, Programming style guides have different preferences for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=84456f9b, platform=Reddit, type=opinion, conf=0.8, trust=0.3, facts=[This comment states that something violates community rules, The comment does not specify what content is being referenced, The comment makes a general claim about rule violation]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9e89bdf, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[User is requesting source code address, Video description appears to lack link, Comment is a simple request for information]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=95b284eb, platform=Forum, type=opinion, conf=0.9, trust=0.3, facts=[Comment requests removal of content, Comment contains 'off-topic ad' reference, Comment is directed at moderators]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=c15a1fb8, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses gratitude, The comment describes a response as clear and concise, The comment acknowledges assistance with a config issue]
2025-10-13 23:05:20.869 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a7f81f33, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[User reports bot replies flooding a thread, Platform is Twitter, Context mentions suspicious activity]
2025-10-13 23:05:20.870 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=95b284eb, platform=Forum, type=opinion, conf=0.9, trust=0.3, facts=[Comment requests removal of off-topic ad, Comment is posted in thread about model interpretability, Comment does not contribute to thread topic]
2025-10-13 23:05:20.870 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b0f15b0d, platform=Reddit, type=opinion, conf=0.8, trust=0.3, facts=[The user claims the results are cherry-picked]
2025-10-13 23:05:20.870 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=5367e6a5, platform=Forum, type=fact, conf=0.9, trust=0.8, facts=[Confidence intervals overlapping indicates no statistically significant difference between groups]
2025-10-13 23:05:20.870 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee8a4813-3889-41de-9d89-a57cb4a97bca, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment 'Source?' is a request for verification","The comment references a previous claim of 'big improvement'","The comment seeks additional information to evaluate a claim"],"trustScore":0.5}
2025-10-13 23:05:20.882 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=21
2025-10-13 23:05:20.883 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4fe72c93-90d1-43ee-8f56-2f3d41a02d71, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3695f2cb, platform=YouTube, result={"type":"opinion","confidence":0.95,"facts":["The comment offers a free gift without context","This pattern is commonly used in spam","No legitimate tutorial video typically offers unsolicited free gifts"],"trustScore":0.1}
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=22
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=29
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=30
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=45
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=46
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=47
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=48
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=49
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=50
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=17
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=42
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=43
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=34
2025-10-13 23:05:20.883 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=19
2025-10-13 23:05:20.887 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddc10887-50b1-4a4c-932a-6f5f7db45a59, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["This comment consists of the word 'First!'","The comment was posted on a YouTube video about a new release walkthrough","The comment does not contain substantive content about the video topic"],"trustScore":0.3}
2025-10-13 23:05:20.903 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=23
2025-10-13 23:05:20.904 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=44
2025-10-13 23:05:20.907 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41fbe011-5aad-45a1-80d3-7a1735c4f418, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of content","The comment states the content is off-topic","The comment is made in a thread about safety policies"],"trustScore":0.7}
2025-10-13 23:05:20.915 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=45
2025-10-13 23:05:20.920 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=51
2025-10-13 23:05:20.925 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4414aebe-ff58-4b73-9d10-6bee3c811ad1, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b71bc599, platform=Forum, result={"type":"opinion","confidence":0.9,"facts":["The comment requests removal of content","The comment states content is off-topic","The comment is made in a forum thread about safety policies"],"trustScore":0.7}
2025-10-13 23:05:20.937 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=892b3155-bd18-41a6-9dad-4f665701b633, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, result={"type":"opinion","confidence":0.95,"facts":["The comment promotes a service to buy followers","The website domain 'spammy.site' suggests spam activity","Buying followers violates platform terms of service"],"trustScore":0.1}
2025-10-13 23:05:20.940 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=31
2025-10-13 23:05:20.995 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c020b92-22d9-42dd-adf7-9c2595a64a4a, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses subjective feedback about presentation quality and example quantity","The comment does not contain verifiable factual claims about database indexing","The comment is a personal opinion about educational content delivery"],"trustScore":0.7}
2025-10-13 23:05:20.997 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4574467a-a88c-4c72-8337-3f4bc8e82199, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8462d113, platform=Reddit, result={"type":"opinion","confidence":0.95,"facts":["User posted content containing a slur","The comment violates community guidelines","Slurs constitute harmful language"],"trustScore":0.1}
2025-10-13 23:05:21.005 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb5fb054-21dd-41fc-8224-6c3257dba99f, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dce37358, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment warns users about a potential scam","The comment advises against clicking something","The context indicates this is in a suspicious giveaway thread"],"trustScore":0.8}
2025-10-13 23:05:21.025 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab75c19a-0bac-47ea-bd4d-a30c9afa8f7d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment consists of a single word 'Source?'","The comment is requesting verification of a claim made by OP","The comment does not contain substantive information itself"],"trustScore":0.5}
2025-10-13 23:05:21.039 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d0c219ef-d9fa-45b9-8b8d-d4be260bb70b, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment requests subtitles for a technical lecture replay.","Subtitles can improve accessibility for viewers with hearing impairments.","YouTube provides tools for creators to add subtitles to videos."],"trustScore":1.0}
2025-10-13 23:05:21.042 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=598ce2cf-7c6f-4024-bee6-8b46e3353f9d, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","The improvement is measurable"],"trustScore":0.7}
2025-10-13 23:05:21.057 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8c6c43d5-6e8f-4940-b012-1a351559afc4, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment states that a claim lacks evidence","The comment is responding to a bold performance claim","The comment expresses skepticism about evidence supporting a claim"],"trustScore":0.7}
2025-10-13 23:05:21.065 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=21967a31-aeba-4ffa-80cb-7f15d55218e4, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, result={"type":"opinion","confidence":0.95,"facts":["This comment solicits cryptocurrency transfers","It promises to double any cryptocurrency sent","This is a common scam pattern on social media"],"trustScore":0.1}
2025-10-13 23:05:21.088 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=23073508-96ba-49b3-974e-735e4ca82fdb, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment warns users about a potential scam","The comment advises against clicking something","The context indicates this is in a suspicious giveaway thread"],"trustScore":0.8}
2025-10-13 23:05:21.112 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%]
2025-10-13 23:05:21.112 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=f7c81544, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[, , ]
2025-10-13 23:05:21.112 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, The improvement is measurable]
2025-10-13 23:05:21.112 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' appears to be associated with artificial engagement, Purchased followers typically violate platform terms of service]
2025-10-13 23:05:21.112 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The website domain 'spammy.site' suggests low-quality content, Purchased followers violate platform terms of service]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The context mentions Model X vs Y comparison, The comment expresses skepticism about benchmark methodology]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, The comment lacks substantive content]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment requests moderator removal, The comment is labeled as 'pure spam', The comment is an off-topic advertisement]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=d29f683c, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[Comment requests removal by moderators, Comment contains the word 'spam', Comment lacks substantive content]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dabb0dea, platform=Twitter, type=opinion, conf=0.7, trust=0.6, facts=[The comment requests proof for a claimed state-of-the-art achievement, The comment references a leaderboard screenshot as context, The comment expresses skepticism about an unverified claim]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment claims there is an error in section 3 of the paper]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, The comment lacks substantive content]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=aa177b64, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 25%]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=1.0, facts=[The comment expresses gratitude for a detailed explanation., The context is a guide about Docker., The comment does not contain factual claims or opinions about Docker.]
2025-10-13 23:05:21.113 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=f8604760, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses appreciation for benchmarking methodology, The comment does not contain verifiable factual claims, The comment is a subjective evaluation of content]
2025-10-13 23:05:21.114 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[This comment consists of the word 'First!', The comment was posted on a YouTube video about a new release walkthrough]
2025-10-13 23:05:21.114 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style preferences vary among developers, Some languages have official style guides recommending specific indentation]
2025-10-13 23:05:21.114 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.1, facts=[This comment consists of the word 'First!', The comment appears on a YouTube video about a new product, The comment expresses no substantive content]
2025-10-13 23:05:21.114 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a7f81f33, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[User reports bot replies flooding a thread, Platform is Twitter, Context indicates suspicious activity]
2025-10-13 23:05:21.114 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=5367e6a5, platform=Forum, type=fact, conf=0.8, trust=0.9, facts=[Confidence intervals overlapping indicates no statistically significant difference between groups]
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=24
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=32
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=33
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=34
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=25
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=26
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=27
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=52
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=53
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=18
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=19
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=46
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=35
2025-10-13 23:05:21.131 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=36
2025-10-13 23:05:21.141 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fc4f1596-e747-438f-a467-f0f18497e4eb, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=249afa42, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment requests citations for a health claim","The comment does not make any factual claims itself","The comment appears in a health claim discussion context"],"trustScore":0.7}
2025-10-13 23:05:21.149 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=47
2025-10-13 23:05:21.161 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=28
2025-10-13 23:05:21.170 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=29
2025-10-13 23:05:21.186 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=35
2025-10-13 23:05:21.236 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=79dc8dd6-f120-4532-9f89-f71088eb6127, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.2,"facts":["The comment consists of a single word: 'Source?'","The comment is requesting verification of a claim made by OP","The comment does not contain substantive information itself"],"trustScore":0.5}
2025-10-13 23:05:21.328 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c3dd88ca-af31-413b-91cf-5f3703caf117, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4fcacd6b, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Comment contains personal attack","Comment lacks substantive argument","Comment uses derogatory language"],"trustScore":0.1}
2025-10-13 23:05:21.360 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b000f118-8c3a-4149-97c6-f821755a49c5, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial.","The comment uses informal Chinese language to convey approval.","The comment does not contain verifiable factual claims about Java virtual threads."],"trustScore":0.8}
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=518d7dd2, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment expresses disagreement with a previous statement, The comment does not provide specific factual claims, The comment is a personal opinion]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service for purchasing followers, The domain 'spammy.site' appears to be associated with artificial engagement, Purchased followers violate platform terms of service]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3695f2cb, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment offers a free gift without context, This pattern is commonly used in spam, No legitimate tutorial video typically offers unsolicited free gifts]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=355aed09, platform=Forum, type=opinion, conf=0.95, trust=0.1, facts=[The comment promotes a service to buy followers, The website domain 'spammy.site' suggests spam activity, Buying followers violates platform terms of service]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=2d8aeef, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[The comment expresses skepticism about data presentation, The comment suggests potential bias in chart selection, The comment compares Model A favorably in the presented data]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4432cdd, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[Mislabelled axes can invalidate data interpretation, Proper axis labeling is essential for valid scientific claims, Graph interpretation depends on correct axis identification]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment references a previous claim of 'big improvement', The comment seeks additional information to evaluate a claim]
2025-10-13 23:05:21.362 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b71bc599, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests removal of content, The comment states the content is off-topic, The comment is made in a thread about safety policies]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=b71bc599, platform=Forum, type=opinion, conf=0.9, trust=0.7, facts=[The comment requests removal of content, The comment states content is off-topic, The comment is made in a forum thread about safety policies]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[The comment contains a clickable link, The comment promises a free gift, This pattern is commonly used in spam campaigns]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6b59be10, platform=YouTube, type=opinion, conf=0.95, trust=0.1, facts=[Comment contains a link promising free gifts, This pattern is commonly associated with spam campaigns, Such comments often lead to phishing or malware distribution]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4ae5f89b, platform=Reddit, type=opinion, conf=0.9, trust=1.0, facts=[The comment expresses gratitude for a detailed explanation., The comment is a response to a guide about Docker., The comment contains no substantive claims about Docker.]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d54b596e, platform=Forum, type=opinion, conf=0.9, trust=0.8, facts=[The user is asking about dataset download location, This is a question about research resources, The context indicates this is related to paper replication]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a88e8e1f, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests a source for a 10x improvement claim, The comment does not make any factual assertions itself, The comment is seeking verification of another user's statement]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.3, facts=[This comment consists of the word 'First!', The comment was posted on a YouTube video about a new release walkthrough, The comment does not contain substantive content about the video topic]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c178f635, platform=Twitter, type=opinion, conf=0.95, trust=0.1, facts=[This comment solicits cryptocurrency transfers, It promises to double any cryptocurrency sent, This is a common scam pattern on social media]
2025-10-13 23:05:21.363 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c178f635, platform=Twitter, type=opinion, conf=0.95, trust=0.1, facts=[This comment solicits cryptocurrency transfers, It promises to double any cryptocurrency sent, This follows common giveaway scam patterns]
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=25
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=30
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=8
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=17
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=20
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=21
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=48
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=37
2025-10-13 23:05:21.378 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=20
2025-10-13 23:05:21.394 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=31
2025-10-13 23:05:21.409 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e6e2e644-f5a1-4022-a21d-0d9a85667ca3, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.9,"facts":["The comment 'This is misinformation' is a claim about vaccine information being false","The comment does not specify what vaccine information it refers to","The comment makes an unsubstantiated claim without providing evidence"],"trustScore":0.2}
2025-10-13 23:05:21.461 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ab6d490b-c0b7-417a-98a7-36d2f3a60b01, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The user expressed appreciation for a demo","The user thanked someone for the demo"],"trustScore":0.8}
2025-10-13 23:05:21.467 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=49411a9d-252b-47ce-9b75-b907bd79eb27, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["User expressed approval of content","User indicated intent to save content for future reference"],"trustScore":0.8}
2025-10-13 23:05:21.480 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6bb54e4e-24e8-45df-b897-1b2b674d8aa6, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The context mentions Model X vs Y comparison","The comment expresses skepticism about benchmark methodology"],"trustScore":0.4}
2025-10-13 23:05:21.482 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=32
2025-10-13 23:05:21.528 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=cb056b95-15f3-4e45-9a34-b575fa66efdc, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset link provided in the forum post is broken","The link does not resolve to a valid resource","Users cannot access the dataset through the provided link"],"trustScore":0.95}
2025-10-13 23:05:21.531 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1de40a0a-307c-40e1-8440-1c569e800939, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.3,"facts":["The comment consists of a single word: 'Source?'","The comment is requesting verification of a claim made by the original poster","The comment does not contain substantive content beyond requesting evidence"],"trustScore":0.5}
2025-10-13 23:05:21.531 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=656df53f-c7f0-4713-b803-897f60ac73d7, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=90f74847, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims Section 3 math is wrong","This is a critique of a paper summary","The statement is subjective without specific evidence"],"trustScore":0.3}
2025-10-13 23:05:21.573 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=22
2025-10-13 23:05:21.609 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=33
2025-10-13 23:05:21.615 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f7a76d79-9c99-4cf4-8efc-d2e1beb71adc, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","The comment references a comparison between Model X and Model Y","The comment implies potential bias in benchmark selection"],"trustScore":0.4}
2025-10-13 23:05:21.616 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, The improvement is measurable]
2025-10-13 23:05:21.616 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment consists of a single word 'Source?', The comment is requesting verification of a claim made by OP, The comment does not contain substantive information itself]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=249afa42, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment requests citations for a health claim, The comment does not make any factual claims itself, The comment appears in a health claim discussion context]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=eab53364, platform=Reddit, type=opinion, conf=0.2, trust=0.5, facts=[The comment consists of a single word: 'Source?', The comment is requesting verification of a claim made by OP, The comment does not contain substantive information itself]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial., The comment uses informal Chinese language to convey approval., The comment does not contain verifiable factual claims about Java virtual threads.]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dcd4c761, platform=YouTube, type=opinion, conf=0.8, trust=0.7, facts=[The comment expresses subjective feedback about presentation quality and example quantity, The comment does not contain verifiable factual claims about database indexing, The comment is a personal opinion about educational content delivery]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=d153d2dd, platform=YouTube, type=opinion, conf=0.9, trust=1.0, facts=[The comment requests subtitles for a technical lecture replay., Subtitles can improve accessibility for viewers with hearing impairments., YouTube provides tools for creators to add subtitles to videos.]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dce37358, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment warns users about a potential scam, The comment advises against clicking something, The context indicates this is in a suspicious giveaway thread]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=dce37358, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The comment warns users about a potential scam, The comment advises against clicking something, The context indicates this is in a suspicious giveaway thread]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4fcacd6b, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[Comment contains personal attack, Comment lacks substantive argument, Comment uses derogatory language]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=a10338c7, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment states that a claim lacks evidence, The comment is responding to a bold performance claim, The comment expresses skepticism about evidence supporting a claim]
2025-10-13 23:05:21.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c178f635, platform=Twitter, type=opinion, conf=0.95, trust=0.1, facts=[This comment solicits cryptocurrency transfers, It promises to double any cryptocurrency sent, This is a common scam pattern on social media]
2025-10-13 23:05:21.618 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8462d113, platform=Reddit, type=opinion, conf=0.95, trust=0.1, facts=[User posted content containing a slur, The comment violates community guidelines, Slurs constitute harmful language]
2025-10-13 23:05:21.634 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee6748fd-7b7b-4c5a-840a-3d4746ec5ed1, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims Section 3 math is wrong","This is a critique of a paper summary","The statement is subjective without specific evidence"],"trustScore":0.4}
2025-10-13 23:05:21.653 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=18
2025-10-13 23:05:21.664 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fd46784e-8426-47df-8f69-8f11669186bf, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses dismissive language"],"trustScore":0.1}
2025-10-13 23:05:21.707 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=19
2025-10-13 23:05:21.727 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=36
2025-10-13 23:05:21.727 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=54
2025-10-13 23:05:21.790 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=41f1e249-a1fe-4eff-8735-752f3fe3e36a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims the benchmark is cherry-picked","Cherry-picking refers to selectively choosing data to support a position","The context mentions Model X vs Y comparison"],"trustScore":0.4}
2025-10-13 23:05:21.796 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fc4a930b-d94d-40f3-b212-3b4d45472bd6, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","Improvement is measurable"],"trustScore":0.7}
2025-10-13 23:05:21.803 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5fd28a2b-705c-4655-8193-c38e21835af3, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 23:05:21.818 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=34
2025-10-13 23:05:21.818 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=21
2025-10-13 23:05:21.818 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=22
2025-10-13 23:05:21.829 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f25ec728-6a25-410a-bca4-602660b75957, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=79c5d488, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment 'Ad hominem. Please address the argument.' is a request to focus on logical reasoning rather than personal attacks","Ad hominem refers to a logical fallacy where an argument is rebutted by attacking the character of the person making it rather than addressing the substance of the argument","The comment does not contain verifiable factual claims about external reality"],"trustScore":0.7}
2025-10-13 23:05:21.836 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=35b9ae45-777c-4f59-b614-8a51f6c67bfa, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment 'Source?' is a request for verification","The comment does not make any factual claims itself","The comment responds to a claim of 'big improvement' made by OP"],"trustScore":0.5}
2025-10-13 23:05:21.859 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=37
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The context mentions Model X vs Y comparison, The comment expresses skepticism about benchmark methodology]
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, The comment references a comparison between Model X and Model Y, The comment implies potential bias in benchmark selection]
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=eab53364, platform=Reddit, type=opinion, conf=0.3, trust=0.5, facts=[The comment consists of a single word: 'Source?', The comment is requesting verification of a claim made by the original poster, The comment does not contain substantive content beyond requesting evidence]
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=bae34db9, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[User expressed approval of content, User indicated intent to save content for future reference]
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.9, trust=0.2, facts=[The comment 'This is misinformation' is a claim about vaccine information being false, The comment does not specify what vaccine information it refers to, The comment makes an unsubstantiated claim without providing evidence]
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=b199fee4, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[The user expressed appreciation for a demo, The user thanked someone for the demo]
2025-10-13 23:05:21.873 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=866e8221, platform=Forum, type=fact, conf=0.9, trust=0.95, facts=[The dataset link provided in the forum post is broken, The link does not resolve to a valid resource, Users cannot access the dataset through the provided link]
2025-10-13 23:05:21.874 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=90f74847, platform=Reddit, type=opinion, conf=0.7, trust=0.3, facts=[The comment claims Section 3 math is wrong, This is a critique of a paper summary, The statement is subjective without specific evidence]
2025-10-13 23:05:21.881 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ddf57981-197c-4c15-932c-13f850b5d634, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, result={"type":"fact","confidence":0.8,"facts":["Performance improved by 30%","Benchmark results are available","Improvement is measurable"],"trustScore":0.7}
2025-10-13 23:05:21.882 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=40bc0bf4-3875-457f-9928-9944714ce0e6, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment serves as a content moderation report"],"trustScore":0.7}
2025-10-13 23:05:21.899 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=23
2025-10-13 23:05:21.910 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fba9d2a9-68e2-4367-bab2-b39b28070714, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment describes the content as hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 23:05:21.935 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4bf23d27-5ab0-47c5-805b-20dbd66e84b6, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 23:05:21.957 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=26
2025-10-13 23:05:21.985 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3f9449b9-73af-4a48-8071-faf9827eb9f3, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims 'This benchmark is cherry-picked'","The context mentions 'Model X vs Y'","The statement is evaluative rather than purely descriptive"],"trustScore":0.4}
2025-10-13 23:05:22.034 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=38
2025-10-13 23:05:22.035 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=08a7d70d-ea51-4bf7-a29e-ddd4a9fe70e5, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment uses ad hominem attack","Ad hominem attacks avoid addressing substantive arguments","Ad hominem is a logical fallacy that targets the person rather than the argument"],"trustScore":0.2}
2025-10-13 23:05:22.063 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=27
2025-10-13 23:05:22.063 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=28
2025-10-13 23:05:22.097 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=5845db0b-52b3-4a1c-a9f2-1ebf455d17f0, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4b1e90eb, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["The graph lacks labeled axes.","Unlabeled axes make data interpretation unreliable.","Proper graphs require clear axis labels for context."],"trustScore":0.2}
2025-10-13 23:05:22.105 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=35
2025-10-13 23:05:22.106 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=2
2025-10-13 23:05:22.113 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ec7ec9a2-ad63-41ae-a969-2b0df2d9f5a6, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, result={"type":"opinion","confidence":0.95,"facts":["User posted content containing a slur","The comment violates community guidelines against hate speech","Slurs are prohibited on this platform"],"trustScore":0.9}
2025-10-13 23:05:22.119 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses dismissive language]
2025-10-13 23:05:22.119 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, Improvement is measurable]
2025-10-13 23:05:22.120 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:22.120 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims the benchmark is cherry-picked, Cherry-picking refers to selectively choosing data to support a position, The context mentions Model X vs Y comparison]
2025-10-13 23:05:22.120 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=eab53364, platform=Reddit, type=opinion, conf=0.7, trust=0.5, facts=[The comment 'Source?' is a request for verification, The comment does not make any factual claims itself, The comment responds to a claim of 'big improvement' made by OP]
2025-10-13 23:05:22.120 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=79c5d488, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The comment 'Ad hominem. Please address the argument.' is a request to focus on logical reasoning rather than personal attacks, Ad hominem refers to a logical fallacy where an argument is rebutted by attacking the character of the person making it rather than addressing the substance of the argument, The comment does not contain verifiable factual claims about external reality]
2025-10-13 23:05:22.120 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=90f74847, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims Section 3 math is wrong, This is a critique of a paper summary, The statement is subjective without specific evidence]
2025-10-13 23:05:22.125 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a5552c12-b916-4e8d-b3d5-5a6b5a89eae2, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ce786d9f, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset does not include license information","License information is typically required for data sharing and reuse","Missing license info creates uncertainty about usage rights"],"trustScore":0.85}
2025-10-13 23:05:22.145 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=29
2025-10-13 23:05:22.146 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=25
2025-10-13 23:05:22.152 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c4f5dc0f-6979-4644-bc27-17d45aee9e75, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses negative sentiment","The comment lacks constructive feedback","The comment provides no specific criticism"],"trustScore":0.2}
2025-10-13 23:05:22.201 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=30
2025-10-13 23:05:22.201 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=26
2025-10-13 23:05:22.275 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=95c8a7c6-0dea-4b41-862c-408f1a11fe73, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment violates civil discourse norms","The comment occurred in a code review context"],"trustScore":0.1}
2025-10-13 23:05:22.280 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=39
2025-10-13 23:05:22.308 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=3
2025-10-13 23:05:22.350 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=55
2025-10-13 23:05:22.359 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=3d69ffee-47c6-40dc-a2b1-8041392d26fd, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=83b22e3c, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment violates civil discourse norms","The comment occurred in a code review context"],"trustScore":0.1}
2025-10-13 23:05:22.359 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e60d6b18-79cc-456a-8143-e2ad276d123e, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.2}
2025-10-13 23:05:22.368 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c951a2fe, platform=Forum, type=fact, conf=0.8, trust=0.7, facts=[Performance improved by 30%, Benchmark results are available, Improvement is measurable]
2025-10-13 23:05:22.368 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:22.368 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=22aa5e6b, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims 'This benchmark is cherry-picked', The context mentions 'Model X vs Y', The statement is evaluative rather than purely descriptive]
2025-10-13 23:05:22.368 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=79c5d488, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment uses ad hominem attack, Ad hominem attacks avoid addressing substantive arguments, Ad hominem is a logical fallacy that targets the person rather than the argument]
2025-10-13 23:05:22.369 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4b1e90eb, platform=Forum, type=misinformation, conf=0.8, trust=0.2, facts=[The graph lacks labeled axes., Unlabeled axes make data interpretation unreliable., Proper graphs require clear axis labels for context.]
2025-10-13 23:05:22.369 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment serves as a content moderation report]
2025-10-13 23:05:22.369 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 23:05:22.391 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=23
2025-10-13 23:05:22.391 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=24
2025-10-13 23:05:22.440 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=b36cc0a3-d5b3-40ce-b341-bf3a655ba495, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment describes the content as containing hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 23:05:22.445 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=25
2025-10-13 23:05:22.481 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=76e36ff8-706c-4bfd-aca3-98b0f15eabe4, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9546f9b5, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["Axis scaling can distort data visualization","Misleading scaling can misrepresent performance trends","Proper scaling should maintain proportional relationships"],"trustScore":0.3}
2025-10-13 23:05:22.513 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=8a7422c4-386c-4648-9518-117a3c83149d, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains personal insults","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 23:05:22.525 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=27
2025-10-13 23:05:22.603 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=20
2025-10-13 23:05:22.603 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=28
2025-10-13 23:05:22.607 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e72bdadd-2d8a-4352-a607-97bd15c4837c, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.2}
2025-10-13 23:05:22.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety]
2025-10-13 23:05:22.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=ce786d9f, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset does not include license information, License information is typically required for data sharing and reuse, Missing license info creates uncertainty about usage rights]
2025-10-13 23:05:22.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=83b22e3c, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment violates civil discourse norms, The comment occurred in a code review context]
2025-10-13 23:05:22.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=83b22e3c, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment violates civil discourse norms, The comment occurred in a code review context]
2025-10-13 23:05:22.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8462d113, platform=Reddit, type=opinion, conf=0.95, trust=0.9, facts=[User posted content containing a slur, The comment violates community guidelines against hate speech, Slurs are prohibited on this platform]
2025-10-13 23:05:22.624 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=6245232a, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment expresses negative sentiment, The comment lacks constructive feedback, The comment provides no specific criticism]
2025-10-13 23:05:22.686 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=29
2025-10-13 23:05:22.702 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c38417d-6cf7-4b41-a39c-c68eead23b6c, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment indicates the reported content contains hate speech","The comment serves as a content moderation report"],"trustScore":0.7}
2025-10-13 23:05:22.718 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2b81cd5f-0f42-4ec6-86b5-e8498b537e8a, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX",""],"trustScore":0.7}
2025-10-13 23:05:22.725 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=40
2025-10-13 23:05:22.758 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=8 offset=31
2025-10-13 23:05:22.790 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bdd8791b-4d99-4540-bad3-934ab668ad4a, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX",""],"trustScore":0.7}
2025-10-13 23:05:22.855 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=21
2025-10-13 23:05:22.864 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7d201761-1070-4533-b2eb-ecf4d7e5527f, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["Misleading axis scaling can distort data visualization","Proper chart scaling should maintain proportional relationships","Truncated axes can exaggerate small differences"],"trustScore":0.3}
2025-10-13 23:05:22.871 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d0f1d71, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains personal insults, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:22.871 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=9546f9b5, platform=Forum, type=misinformation, conf=0.8, trust=0.3, facts=[Axis scaling can distort data visualization, Misleading scaling can misrepresent performance trends, Proper scaling should maintain proportional relationships]
2025-10-13 23:05:22.871 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety]
2025-10-13 23:05:22.871 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as containing hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 23:05:22.890 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0973ef42-5216-42be-bc00-5e25cc3c05ae, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 23:05:22.948 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=30
2025-10-13 23:05:22.964 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=38
2025-10-13 23:05:22.977 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=26b4190d-dc44-42ed-a84f-04ef195b10b1, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety"],"trustScore":0.2}
2025-10-13 23:05:23.002 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ef0d9ecf-c1bb-429d-9655-014e479bc9e8, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["Vaccines undergo rigorous testing before approval","Vaccines have proven effective at preventing serious illness","Major health organizations endorse vaccine safety and efficacy"],"trustScore":0.15}
2025-10-13 23:05:23.015 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=eb7868a8-1660-42d0-9524-6d787cc9acbd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset does not include license information","License information is typically included in dataset documentation","Missing license information creates uncertainty about usage rights"],"trustScore":0.85}
2025-10-13 23:05:23.035 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=39
2025-10-13 23:05:23.065 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4e9c5a0b-746d-4311-9f31-5d11e6fffaac, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment 'First!' is a common internet expression"],"trustScore":0.8}
2025-10-13 23:05:23.110 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=41
2025-10-13 23:05:23.119 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=9546f9b5, platform=Forum, type=misinformation, conf=0.8, trust=0.3, facts=[Misleading axis scaling can distort data visualization, Proper chart scaling should maintain proportional relationships, Truncated axes can exaggerate small differences]
2025-10-13 23:05:23.119 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment indicates the reported content contains hate speech, The comment serves as a content moderation report]
2025-10-13 23:05:23.119 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, ]
2025-10-13 23:05:23.119 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, ]
2025-10-13 23:05:23.137 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=40
2025-10-13 23:05:23.151 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7d076ede-5a66-4b96-9f0e-ec7217e9e0a4, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8d27383f, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.7}
2025-10-13 23:05:23.154 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=769f8b0f-6fe5-4f43-a449-def450a3db00, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 23:05:23.156 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2daec662-6315-4137-93d1-830159d8ed90, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.85,"facts":["The comment claims something is misinformation without specifying what","The comment lacks specific claims to verify","The comment makes a general accusation without evidence"],"trustScore":0.2}
2025-10-13 23:05:23.222 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=22
2025-10-13 23:05:23.245 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=23
2025-10-13 23:05:23.257 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f76b1eac-7602-404e-ad08-fccd2b774df9, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["XX","",""],"trustScore":0.7}
2025-10-13 23:05:23.259 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bede6ab1-38ea-4442-8982-669feb0873e0, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=6245232a, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment expresses negative sentiment","The comment lacks constructive feedback","The comment provides no specific criticism"],"trustScore":0.2}
2025-10-13 23:05:23.280 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=24
2025-10-13 23:05:23.356 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=49
2025-10-13 23:05:23.362 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=a4bdb647-5b07-4c2b-8b00-216a6168c7c7, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, result={"type":"misinformation","confidence":0.9,"facts":["The comment 'This is misinformation' makes an unsubstantiated claim about vaccine information","The comment provides no specific information to evaluate as misinformation","Vaccine safety is supported by extensive scientific research and regulatory oversight"],"trustScore":0.2}
2025-10-13 23:05:23.367 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety]
2025-10-13 23:05:23.367 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.15, facts=[Vaccines undergo rigorous testing before approval, Vaccines have proven effective at preventing serious illness, Major health organizations endorse vaccine safety and efficacy]
2025-10-13 23:05:23.367 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=ce786d9f, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset does not include license information, License information is typically included in dataset documentation, Missing license information creates uncertainty about usage rights]
2025-10-13 23:05:23.367 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=7d706f91, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment 'First!' is a common internet expression]
2025-10-13 23:05:23.367 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:23.395 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=36
2025-10-13 23:05:23.416 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=fe0cf4fa-81db-4d61-bc19-51ffd640921b, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4432cdd, platform=Reddit, result={"type":"fact","confidence":0.9,"facts":["Mislabelled axes can invalidate data interpretation in plots","Axes labels are essential for accurate data representation in scientific visualization","Incorrect axis labeling can lead to misinterpretation of throughput vs latency relationships"],"trustScore":0.95}
2025-10-13 23:05:23.466 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=24
2025-10-13 23:05:23.466 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=41
2025-10-13 23:05:23.504 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=42
2025-10-13 23:05:23.525 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=26
2025-10-13 23:05:23.607 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=2 offset=25
2025-10-13 23:05:23.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=8d27383f, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, , ]
2025-10-13 23:05:23.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.85, trust=0.2, facts=[The comment claims something is misinformation without specifying what, The comment lacks specific claims to verify, The comment makes a general accusation without evidence]
2025-10-13 23:05:23.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=3b6e9205, platform=Forum, type=misinformation, conf=0.9, trust=0.2, facts=[The comment 'This is misinformation' makes an unsubstantiated claim about vaccine information, The comment provides no specific information to evaluate as misinformation, Vaccine safety is supported by extensive scientific research and regulatory oversight]
2025-10-13 23:05:23.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:23.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=4e8e8b25, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[XX, , ]
2025-10-13 23:05:23.617 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=6245232a, platform=Reddit, type=opinion, conf=0.8, trust=0.2, facts=[The comment expresses negative sentiment, The comment lacks constructive feedback, The comment provides no specific criticism]
2025-10-13 23:05:23.659 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=37
2025-10-13 23:05:23.863 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=4432cdd, platform=Reddit, type=fact, conf=0.9, trust=0.95, facts=[Mislabelled axes can invalidate data interpretation in plots, Axes labels are essential for accurate data representation in scientific visualization, Incorrect axis labeling can lead to misinterpretation of throughput vs latency relationships]
2025-10-13 23:05:23.991 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e74fab65-51ce-4c95-963d-d875ac434b80, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=866e8221, platform=Forum, result={"type":"fact","confidence":0.9,"facts":["The dataset link provided in the forum post is broken","The user has reported repro steps for the broken link issue","The link failure prevents access to the referenced dataset"],"trustScore":0.85}
2025-10-13 23:05:24.237 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=866e8221, platform=Forum, type=fact, conf=0.9, trust=0.85, facts=[The dataset link provided in the forum post is broken, The user has reported repro steps for the broken link issue, The link failure prevents access to the referenced dataset]
2025-10-13 23:05:24.237 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=27
2025-10-13 23:05:24.501 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=91a32e0c-a479-40b3-8207-e0490da9924c, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a88e8e1f, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment is requesting evidence for a 10x improvement claim"],"trustScore":0.9}
2025-10-13 23:05:24.752 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=50
2025-10-13 23:05:24.754 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=a88e8e1f, platform=Reddit, type=opinion, conf=0.8, trust=0.9, facts=[The comment is requesting evidence for a 10x improvement claim]
2025-10-13 23:05:24.957 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6b55d4c8-3604-49d1-a1b5-5ba6a8acb7d9, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 23:05:25.052 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=21119b93-4bbb-46c0-8aec-ee92eab96c60, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dabb0dea, platform=Twitter, result={"type":"opinion","confidence":0.7,"facts":["The comment questions the validity of a claimed state-of-the-art achievement","The comment requests proof for the claimed achievement","The comment references a leaderboard screenshot as context"],"trustScore":0.6}
2025-10-13 23:05:25.126 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7ec52b6f-eaa7-401a-939c-c38c3eaed0da, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment reports hate speech in replies","The comment indicates a thread is descending into insults","The comment is making an observation about platform content"],"trustScore":0.7}
2025-10-13 23:05:25.205 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=56
2025-10-13 23:05:25.206 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.8, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a subjective assessment of mathematical accuracy]
2025-10-13 23:05:25.297 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=57
2025-10-13 23:05:25.307 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=875c4059-3206-4cea-859e-4fd5a2a8d427, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a subjective assessment of mathematical accuracy"],"trustScore":0.4}
2025-10-13 23:05:25.371 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=58
2025-10-13 23:05:25.452 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dabb0dea, platform=Twitter, type=opinion, conf=0.7, trust=0.6, facts=[The comment questions the validity of a claimed state-of-the-art achievement, The comment requests proof for the claimed achievement, The comment references a leaderboard screenshot as context]
2025-10-13 23:05:25.452 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=e4b6047f, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[The comment reports hate speech in replies, The comment indicates a thread is descending into insults, The comment is making an observation about platform content]
2025-10-13 23:05:25.545 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=12443bfd-9796-4fb6-8dd9-29ed6ff4d235, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=e4b6047f, platform=Twitter, result={"type":"opinion","confidence":0.8,"facts":["The comment reports hate speech in replies","The comment indicates a thread is descending into insults","The comment is a report about problematic content"],"trustScore":0.7}
2025-10-13 23:05:25.552 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=59
2025-10-13 23:05:25.593 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=ee031476-f227-4284-ae0e-8bb25385ecfe, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["The comment claims there is an error in section 3 of the paper","The comment expresses disagreement with mathematical content","The comment makes a critical assessment without providing specific corrections"],"trustScore":0.4}
2025-10-13 23:05:25.698 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a subjective assessment of mathematical accuracy]
2025-10-13 23:05:25.790 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=60
2025-10-13 23:05:25.839 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=61
2025-10-13 23:05:25.923 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=67e65cf1-393c-49dd-b482-5853217e3baf, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review etiquette"],"trustScore":0.1}
2025-10-13 23:05:25.945 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=e4b6047f, platform=Twitter, type=opinion, conf=0.8, trust=0.7, facts=[The comment reports hate speech in replies, The comment indicates a thread is descending into insults, The comment is a report about problematic content]
2025-10-13 23:05:25.945 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=6c6528bd, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[The comment claims there is an error in section 3 of the paper, The comment expresses disagreement with mathematical content, The comment makes a critical assessment without providing specific corrections]
2025-10-13 23:05:26.070 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=39041652-0308-4595-bfe2-acc295652e46, taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["The comment expresses positive feedback about a Java virtual threads tutorial","The comment indicates the tutorial was explained clearly","The comment shows viewer appreciation for educational content"],"trustScore":0.8}
2025-10-13 23:05:26.084 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=e6c9340e-08e0-4c8b-a9a5-38bd2bb007aa, taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 23:05:26.170 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=43
2025-10-13 23:05:26.191 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks constructive feedback, The comment violates professional code review etiquette]
2025-10-13 23:05:26.251 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=88d15321-4968-41da-9e6f-e94ea18e547e, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks constructive feedback","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 23:05:26.315 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=38
2025-10-13 23:05:26.331 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=44
2025-10-13 23:05:26.375 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=adad4d4a-7e25-4ad7-90aa-1ee70f566785, taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 23:05:26.437 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-f3b476c2-3320-4283-a5ce-f3b0346ec94f, commentId=4b2d7c08, platform=YouTube, type=opinion, conf=0.9, trust=0.8, facts=[The comment expresses positive feedback about a Java virtual threads tutorial, The comment indicates the tutorial was explained clearly, The comment shows viewer appreciation for educational content]
2025-10-13 23:05:26.437 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6b64a25c-b1f6-4a73-9fc0-ef8c642ef997, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive, The comment violates professional code review norms]
2025-10-13 23:05:26.500 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=45
2025-10-13 23:05:26.600 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6a691020-1be8-4682-bdc8-ff09cdf1db2c, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment is not constructive feedback","The comment violates professional code review norms"],"trustScore":0.1}
2025-10-13 23:05:26.621 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=46
2025-10-13 23:05:26.684 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks constructive feedback, The comment violates professional code review norms]
2025-10-13 23:05:26.684 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-55b90b69-d4b7-46fd-8b00-c124d8da5b40, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive, The comment violates professional code review norms]
2025-10-13 23:05:26.847 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=47
2025-10-13 23:05:26.929 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=f9b07824, platform=Reddit, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment is not constructive feedback, The comment violates professional code review norms]
2025-10-13 23:05:27.019 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7dd90614-dad7-40ee-a18b-8aeeedd5eb72, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The comment reports that someone used a slur","The comment describes the content as hate speech","The comment is making an allegation about another user's behavior"],"trustScore":0.7}
2025-10-13 23:05:27.187 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=d7a78c5d-c89d-48df-b880-e21fba6a1244, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them","These schemes typically result in complete loss of funds"],"trustScore":0.1}
2025-10-13 23:05:27.246 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=34a9aa92-4694-4a12-8c2a-06abd46c9570, taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["Tabs and spaces are both methods for code indentation","Programming style guides have different preferences for tabs vs spaces","This is a subjective preference in software development"],"trustScore":0.8}
2025-10-13 23:05:27.264 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=0 offset=31
2025-10-13 23:05:27.264 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c494b7bd, platform=Reddit, type=opinion, conf=0.9, trust=0.7, facts=[The comment reports that someone used a slur, The comment describes the content as hate speech, The comment is making an allegation about another user's behavior]
2025-10-13 23:05:27.433 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=48
2025-10-13 23:05:27.492 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=51
2025-10-13 23:05:27.510 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=4bde9add, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[Tabs and spaces are both methods for code indentation, Programming style guides have different preferences for tabs vs spaces, This is a subjective preference in software development]
2025-10-13 23:05:27.510 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-29d5c1be-3224-4130-bb97-8332fb66aca5, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Scammers promise to double cryptocurrency sent to them, These schemes typically result in complete loss of funds]
2025-10-13 23:05:27.692 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=9ed099bb-325a-46ba-8cf3-a376788d372e, taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This is a common cryptocurrency giveaway scam","Scammers promise to double cryptocurrency sent to them","These schemes result in permanent loss of funds for victims"],"trustScore":0.1}
2025-10-13 23:05:27.937 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-a35df7fe-28bf-448c-a906-b3c41e68effd, commentId=c178f635, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This is a common cryptocurrency giveaway scam, Scammers promise to double cryptocurrency sent to them, These schemes result in permanent loss of funds for victims]
2025-10-13 23:05:27.937 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=10 offset=49
2025-10-13 23:05:28.113 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f299fe5f-b773-4aca-b018-6b228da535cd, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["The comment contains a personal attack","The comment lacks substantive argumentation","The comment uses derogatory language"],"trustScore":0.1}
2025-10-13 23:05:28.357 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=3 offset=25
2025-10-13 23:05:28.357 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4fcacd6b, platform=Twitter, type=opinion, conf=0.9, trust=0.1, facts=[The comment contains a personal attack, The comment lacks substantive argumentation, The comment uses derogatory language]
2025-10-13 23:05:29.280 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=caa3f017-5703-4660-a1e5-449ab1c21817, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bae34db9, platform=Twitter, result={"type":"opinion","confidence":0.9,"facts":["User expressed approval of content","User indicated intent to save content for later reference"],"trustScore":0.8}
2025-10-13 23:05:29.523 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=0f02944d-62f8-445d-8914-c9b87f2a50c1, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dcd4c761, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["",""],"trustScore":0.7}
2025-10-13 23:05:29.525 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=bae34db9, platform=Twitter, type=opinion, conf=0.9, trust=0.8, facts=[User expressed approval of content, User indicated intent to save content for later reference]
2025-10-13 23:05:29.525 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=62
2025-10-13 23:05:29.768 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=9
2025-10-13 23:05:29.770 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=dcd4c761, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, ]
2025-10-13 23:05:30.117 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=7296e25d-7a58-449e-9d52-9747cf5343f3, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, result={"type":"misinformation","confidence":0.8,"facts":["The graph lacks labeled axes","Unlabeled axes make data interpretation unreliable","Proper graphs require clear axis labels for context"],"trustScore":0.2}
2025-10-13 23:05:30.253 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=4dcd23a1-5438-4b97-b670-ef46e0788c82, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, result={"type":"opinion","confidence":0.9,"facts":["","",""],"trustScore":0.7}
2025-10-13 23:05:30.364 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=4b1e90eb, platform=Forum, type=misinformation, conf=0.8, trust=0.2, facts=[The graph lacks labeled axes, Unlabeled axes make data interpretation unreliable, Proper graphs require clear axis labels for context]
2025-10-13 23:05:30.365 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=63
2025-10-13 23:05:30.499 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=39
2025-10-13 23:05:30.610 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=8d27383f, platform=YouTube, type=opinion, conf=0.9, trust=0.7, facts=[, , ]
2025-10-13 23:05:31.351 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2ac90b37-dfec-45a3-aee3-e871fc08b588, taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=afceae1f, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This comment promises to double cryptocurrency sent by users","Such promises are commonly associated with cryptocurrency scams","No legitimate service guarantees instant doubling of cryptocurrency investments"],"trustScore":0.1}
2025-10-13 23:05:31.598 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=10
2025-10-13 23:05:31.602 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-6ee45b51-d3d3-4761-8757-c88ccd26b41e, commentId=afceae1f, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This comment promises to double cryptocurrency sent by users, Such promises are commonly associated with cryptocurrency scams, No legitimate service guarantees instant doubling of cryptocurrency investments]
2025-10-13 23:05:32.327 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=269c2dfc-0aa5-4e14-aa19-4951ebbf1d17, taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, result={"type":"misinformation","confidence":0.9,"facts":["This comment promises to double cryptocurrency sent to an unspecified recipient","Unsolicited cryptocurrency doubling offers are commonly associated with scams","No legitimate financial service guarantees instant doubling of cryptocurrency investments"],"trustScore":0.1}
2025-10-13 23:05:32.577 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=11
2025-10-13 23:05:32.591 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-8b9b1fa3-a73f-4333-97cb-57c0b1d209ee, commentId=afceae1f, platform=Twitter, type=misinformation, conf=0.9, trust=0.1, facts=[This comment promises to double cryptocurrency sent to an unspecified recipient, Unsolicited cryptocurrency doubling offers are commonly associated with scams, No legitimate financial service guarantees instant doubling of cryptocurrency investments]
2025-10-13 23:08:28.826 [tomcat-handler-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - trace= tenant= user= Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-10-13 23:08:28.826 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Initializing Servlet 'dispatcherServlet'
2025-10-13 23:08:28.827 [tomcat-handler-1] INFO  o.s.web.servlet.DispatcherServlet - trace= tenant= user= Completed initialization in 1 ms
2025-10-13 23:08:29.139 [tomcat-handler-1] INFO  c.e.c.Interceptors.TimingInterceptor - trace=1ab205b5-7ddb-4ecf-9e04-14b0c2333c1d tenant= user= HTTP OK method=POST uri=/analyze/batch status=202 tookMs=296 handler=SendToKafkaController.batch
2025-10-13 23:08:38.828 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=c96e468e-2721-4bce-8a7f-c9acba144d05, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=802e7830, platform=Reddit, result={"type":"opinion","confidence":0.9,"facts":["The commenter moved to Canada","The commenter experienced discussion-heavy classes in Canada","The commenter now works overseas with lecture-only classes"],"trustScore":0.8}
2025-10-13 23:08:39.041 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=57b60b9b-7dba-4977-b852-21cb41e6bb73, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=a215eb37, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["The student received a B grade","The professor stated the work was 'A-level' quality","The professor has a pattern of not giving A grades"],"trustScore":0.7}
2025-10-13 23:08:39.071 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=28
2025-10-13 23:08:39.165 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=802e7830, platform=Reddit, type=opinion, conf=0.9, trust=0.8, facts=[The commenter moved to Canada, The commenter experienced discussion-heavy classes in Canada, The commenter now works overseas with lecture-only classes]
2025-10-13 23:08:39.285 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=64
2025-10-13 23:08:39.411 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=a215eb37, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[The student received a B grade, The professor stated the work was 'A-level' quality, The professor has a pattern of not giving A grades]
2025-10-13 23:08:39.957 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=677bf604-c35d-4661-9d9c-c942453599ae, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=c6cbc002, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["Canadian students in US grad schools often meet first-year requirements","Technical skill comparisons between Canadian and US students exist","Some Canadian students feel their technical skills are stronger than US peers"],"trustScore":0.6}
2025-10-13 23:08:40.202 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=11 offset=29
2025-10-13 23:08:40.400 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=c6cbc002, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[Canadian students in US grad schools often meet first-year requirements, Technical skill comparisons between Canadian and US students exist, Some Canadian students feel their technical skills are stronger than US peers]
2025-10-13 23:08:40.920 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=2eccc11c-a1ee-4bed-89b4-86e8b7e869d2, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=63d1aa29, platform=Reddit, result={"type":"fact","confidence":0.8,"facts":["Engineering classes in Ontario sometimes have pre-curve averages around 50%","Grade curving is used to adjust averages to approximately 70%","This practice is common in Ontario engineering programs"],"trustScore":0.7}
2025-10-13 23:08:41.167 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=4
2025-10-13 23:08:41.392 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=63d1aa29, platform=Reddit, type=fact, conf=0.8, trust=0.7, facts=[Engineering classes in Ontario sometimes have pre-curve averages around 50%, Grade curving is used to adjust averages to approximately 70%, This practice is common in Ontario engineering programs]
2025-10-13 23:08:41.489 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=bdd191ba-3437-4c70-a2d5-f9fe1f22caa0, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=44f3875, platform=Reddit, result={"type":"fact","confidence":0.9,"facts":["There are 155 recognized universities in Canada","Provincial accreditation and quality assurance processes for universities are rigorous","Ontario has specific examples of university accreditation systems"],"trustScore":0.85}
2025-10-13 23:08:41.751 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=5
2025-10-13 23:08:41.751 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=44f3875, platform=Reddit, type=fact, conf=0.9, trust=0.85, facts=[There are 155 recognized universities in Canada, Provincial accreditation and quality assurance processes for universities are rigorous, Ontario has specific examples of university accreditation systems]
2025-10-13 23:08:41.883 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=71f73b20-f62d-47c7-bfd6-69afe70063b9, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=8f7c8b62, platform=Reddit, result={"type":"fact","confidence":0.8,"facts":["In some East Asian countries, grading scales may consider scores below 75% as failing","Cultural expectations around academic performance vary globally","East Asian education systems often emphasize high academic standards"],"trustScore":0.7}
2025-10-13 23:08:41.968 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=704f8b37-6f55-44b9-ad01-bab97b5c7a73, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=a89b25d8, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["Lebanon uses a 20-point grading scale in some universities","MIT is known for rigorous academic standards","Canadian universities have standardized grading systems"],"trustScore":0.6}
2025-10-13 23:08:42.128 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=6 offset=40
2025-10-13 23:08:42.129 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=8f7c8b62, platform=Reddit, type=fact, conf=0.8, trust=0.7, facts=[In some East Asian countries, grading scales may consider scores below 75% as failing, Cultural expectations around academic performance vary globally, East Asian education systems often emphasize high academic standards]
2025-10-13 23:08:42.220 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=1 offset=52
2025-10-13 23:08:42.373 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=a89b25d8, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[Lebanon uses a 20-point grading scale in some universities, MIT is known for rigorous academic standards, Canadian universities have standardized grading systems]
2025-10-13 23:08:42.822 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=47f07a1d-140c-4032-b56d-e8e325d03dff, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=d2e799a9, platform=Reddit, result={"type":"opinion","confidence":0.7,"facts":["Student protest occurred over grading policies","Allegation of grading inconsistency between professors exists","Department has not officially confirmed grading disparity"],"trustScore":0.4}
2025-10-13 23:08:43.069 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=12
2025-10-13 23:08:43.069 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=d2e799a9, platform=Reddit, type=opinion, conf=0.7, trust=0.4, facts=[Student protest occurred over grading policies, Allegation of grading inconsistency between professors exists, Department has not officially confirmed grading disparity]
2025-10-13 23:08:43.672 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=6ab3bd00-aebc-44c0-b913-d9a941037b3a, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=8ffa6c82, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["Humanities courses often use essay-based assessments","Grading practices vary between professors and institutions","Objective assignments may have different grading distributions than subjective ones"],"trustScore":0.6}
2025-10-13 23:08:43.916 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=5 offset=65
2025-10-13 23:08:44.059 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=8ffa6c82, platform=Reddit, type=opinion, conf=0.8, trust=0.6, facts=[Humanities courses often use essay-based assessments, Grading practices vary between professors and institutions, Objective assignments may have different grading distributions than subjective ones]
2025-10-13 23:08:44.514 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=603564e6-328d-4d45-a55c-497bfd34f9fd, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=cc3348db, platform=Reddit, result={"type":"fact","confidence":0.8,"facts":["The passing grade for Calculus was 40%","An intern was panicking about failing Calculus","This describes a department or course-level passing threshold"],"trustScore":0.7}
2025-10-13 23:08:44.761 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=4 offset=13
2025-10-13 23:08:44.761 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=cc3348db, platform=Reddit, type=fact, conf=0.8, trust=0.7, facts=[The passing grade for Calculus was 40%, An intern was panicking about failing Calculus, This describes a department or course-level passing threshold]
2025-10-13 23:08:45.033 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=1c38ea74-9e87-43b9-ae25-71134f239f1d, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=20eb8559, platform=Reddit, result={"type":"opinion","confidence":0.8,"facts":["Canadian universities historically follow British academic traditions","Grade inflation has been documented in Canadian universities","Workload reduction has occurred in some Canadian universities"],"trustScore":0.7}
2025-10-13 23:08:45.278 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=7 offset=6
2025-10-13 23:08:45.279 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=20eb8559, platform=Reddit, type=opinion, conf=0.8, trust=0.7, facts=[Canadian universities historically follow British academic traditions, Grade inflation has been documented in Canadian universities, Workload reduction has occurred in some Canadian universities]
2025-10-13 23:08:46.795 [vf-] INFO  c.e.l.i.m.k.c.MLRequestListener - trace= tenant= user= [LLM] OK eventId=f5b3431c-7aec-447d-9fa1-b09dd7e5cb1d, taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=7beedc58, platform=Reddit, result={"type":"fact","confidence":0.85,"facts":["UBC history classes in the 2010s had large class sizes","Average grades in UBC history classes during the 2010s were between 68-73%","A+ grades were rarely given in UBC history classes during the 2010s"],"trustScore":0.8}
2025-10-13 23:08:47.040 [kafka-producer-network-thread | producer-1] INFO  c.e.l.i.m.k.producer.ResultProducer - trace= tenant= user= [RES] published topic=ef.results.v1 partition=9 offset=42
2025-10-13 23:08:47.040 [kafka-2] INFO  c.e.l.i.m.k.c.ResultDebugListener - trace= tenant= user= [RESULT !!!!! TESTING ONLY] taskId=task-b1b7f1b8-9f9e-4b2a-9f20-7c9f21a3b7a2, commentId=7beedc58, platform=Reddit, type=fact, conf=0.85, trust=0.8, facts=[UBC history classes in the 2010s had large class sizes, Average grades in UBC history classes during the 2010s were between 68-73%, A+ grades were rarely given in UBC history classes during the 2010s]
2025-10-13 23:12:37.849 [kafka-2] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Revoke previously assigned partitions ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11
2025-10-13 23:12:37.849 [kafka-1] INFO  o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Revoke previously assigned partitions ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11
2025-10-13 23:12:37.850 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: partitions revoked: [ef.requests.v1-0, ef.requests.v1-1, ef.requests.v1-2, ef.requests.v1-3, ef.requests.v1-4, ef.requests.v1-5, ef.requests.v1-6, ef.requests.v1-7, ef.requests.v1-8, ef.requests.v1-9, ef.requests.v1-10, ef.requests.v1-11]
2025-10-13 23:12:37.850 [kafka-2] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= ef-results-debug: partitions revoked: [ef.results.v1-0, ef.results.v1-1, ef.results.v1-2, ef.results.v1-3, ef.results.v1-4, ef.results.v1-5, ef.results.v1-6, ef.results.v1-7, ef.results.v1-8, ef.results.v1-9, ef.results.v1-10, ef.results.v1-11]
2025-10-13 23:12:37.850 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Member consumer-echofilter-group-1-ae61dfcf-481b-4c63-9474-0c4366e97029 sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 23:12:37.850 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Member consumer-ef-results-debug-2-9b696116-614a-4c89-9540-d0dded2e4ffc sending LeaveGroup request to coordinator 81.70.198.98:9092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-10-13 23:12:37.850 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.850 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.850 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.850 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.850 [kafka-1] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 23:12:37.850 [kafka-2] INFO  o.a.k.c.c.i.ClassicKafkaConsumer - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Unsubscribed all topics or patterns and assigned partitions
2025-10-13 23:12:37.851 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.851 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.851 [kafka-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-echofilter-group-1, groupId=echofilter-group] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 23:12:37.851 [kafka-2] INFO  o.a.k.c.c.i.ConsumerCoordinator - trace= tenant= user= [Consumer clientId=consumer-ef-results-debug-2, groupId=ef-results-debug] Request joining group due to: consumer pro-actively leaving the group
2025-10-13 23:12:38.342 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 23:12:38.342 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 23:12:38.342 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 23:12:38.342 [kafka-2] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 23:12:38.344 [kafka-2] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-ef-results-debug-2 unregistered
2025-10-13 23:12:38.344 [kafka-2] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= ef-results-debug: Consumer stopped
2025-10-13 23:12:38.560 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 23:12:38.560 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 23:12:38.560 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 23:12:38.560 [kafka-1] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 23:12:38.562 [kafka-1] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.consumer for consumer-echofilter-group-1 unregistered
2025-10-13 23:12:38.562 [kafka-1] INFO  o.s.k.l.KafkaMessageListenerContainer - trace= tenant= user= echofilter-group: Consumer stopped
2025-10-13 23:12:38.563 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Commencing graceful shutdown. Waiting for active requests to complete
2025-10-13 23:12:38.572 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - trace= tenant= user= Graceful shutdown complete
2025-10-13 23:12:38.582 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - trace= tenant= user= [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-10-13 23:12:38.584 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics scheduler closed
2025-10-13 23:12:38.584 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-13 23:12:38.584 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-13 23:12:38.584 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - trace= tenant= user= Metrics reporters closed
2025-10-13 23:12:38.584 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - trace= tenant= user= App info kafka.producer for producer-1 unregistered
